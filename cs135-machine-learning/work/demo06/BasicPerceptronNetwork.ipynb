{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dirty-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "enormous-painting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AtRisk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>115</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>255</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>185</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>175</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35</td>\n",
       "      <td>255</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43</td>\n",
       "      <td>196</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26</td>\n",
       "      <td>105</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Weight  Height  Smoking  AtRisk\n",
       "0   89     115     5.8        0       1\n",
       "1   23     255     6.0        1       1\n",
       "2   18     185     5.7        0       0\n",
       "3   24     175     6.0        0       0\n",
       "4   95      95     5.5        0       1\n",
       "5   35     255     6.2        0       0\n",
       "6   43     196     5.8        1       1\n",
       "7   26     105     5.4        0       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv('patientData.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "secondary-benchmark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 89. , 115. ,   5.8,   0. ],\n",
       "       [ 23. , 255. ,   6. ,   1. ],\n",
       "       [ 18. , 185. ,   5.7,   0. ],\n",
       "       [ 24. , 175. ,   6. ,   0. ],\n",
       "       [ 95. ,  95. ,   5.5,   0. ],\n",
       "       [ 35. , 255. ,   6.2,   0. ],\n",
       "       [ 43. , 196. ,   5.8,   1. ],\n",
       "       [ 26. , 105. ,   5.4,   0. ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_n = data.iloc[:,:-1].values\n",
    "y_n = data.iloc[:,-1].values\n",
    "x_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ancient-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize each column in the x-data to [0, 1]\n",
    "def normalize_min_max_data(x_data):\n",
    "    return (x_data - x_data.min(0)) / x_data.ptp(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "graphic-luxembourg",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92207792, 0.125     , 0.5       , 0.        ],\n",
       "       [0.06493506, 1.        , 0.75      , 1.        ],\n",
       "       [0.        , 0.5625    , 0.375     , 0.        ],\n",
       "       [0.07792208, 0.5       , 0.75      , 0.        ],\n",
       "       [1.        , 0.        , 0.125     , 0.        ],\n",
       "       [0.22077922, 1.        , 1.        , 0.        ],\n",
       "       [0.32467532, 0.63125   , 0.5       , 1.        ],\n",
       "       [0.1038961 , 0.0625    , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_n = normalize_min_max_data(x_n)\n",
    "x_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "incomplete-henry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9726011139048933\n"
     ]
    }
   ],
   "source": [
    "# initial random weights\n",
    "features = len(x_n[0])\n",
    "np.random.seed(13)\n",
    "input_weights = np.random.rand(features)\n",
    "bias_weight = np.random.rand()\n",
    "\n",
    "# learning rate and number of training iterations for gradient descent\n",
    "# (each can be modified; try making learning_rate 100 instead and\n",
    "# see what happens; what about increasing/decreasing epochs?)\n",
    "learning_rate = 0.1\n",
    "epochs = 10_000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "suited-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some simple helper functions for the various components of\n",
    "# the network, and to allow us to do gradient descent\n",
    "def linear_sum(x, w, b):\n",
    "    return np.dot(x, w) + b\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "thick-calculation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89393067, 1.        ],\n",
       "       [0.94503891, 1.        ],\n",
       "       [0.80460408, 0.        ],\n",
       "       [0.85448016, 0.        ],\n",
       "       [0.86451859, 1.        ],\n",
       "       [0.90079787, 0.        ],\n",
       "       [0.94007908, 1.        ],\n",
       "       [0.74426353, 0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the output the network, and compare it to the known\n",
    "# y-values: we want our outputs to be as close to the y-values\n",
    "# as possible (initially, we are probably far from close to the\n",
    "# negative-class (0) outputs, given random positive weights)\n",
    "\n",
    "# NOTE: all the transpose (.T) is doing here is re-arranging data\n",
    "# from rows to columns for readability, nothing fancy mathematically\n",
    "initial_output = sigmoid(linear_sum(x_n, input_weights, bias_weight))\n",
    "np.vstack((initial_output, y_n)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "appointed-butler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0: MSE = 0.347388\n",
      "Epoch   999: MSE = 0.010076\n",
      "Epoch  1999: MSE = 0.004786\n",
      "Epoch  2999: MSE = 0.003102\n",
      "Epoch  3999: MSE = 0.002284\n",
      "Epoch  4999: MSE = 0.001804\n",
      "Epoch  5999: MSE = 0.001489\n",
      "Epoch  6999: MSE = 0.001266\n",
      "Epoch  7999: MSE = 0.001101\n",
      "Epoch  8999: MSE = 0.000974\n",
      "Epoch  9999: MSE = 0.000872\n"
     ]
    }
   ],
   "source": [
    "# here we train the network; the math that explain why this code\n",
    "# works is given in the accompanying PDF showing the derivation\n",
    "for epoch in range(epochs):\n",
    "    # vector of linear sums, one per data-point\n",
    "    linear = linear_sum(x_n, input_weights, bias_weight)\n",
    "    \n",
    "    # vector of logistic outputs, one per data-point\n",
    "    output = sigmoid(linear)\n",
    "    \n",
    "    # vector of errors, one per data-point\n",
    "    basic_error = y_n - output\n",
    "    \n",
    "    # overall MSE (to be minimized)\n",
    "    mse = (basic_error**2).mean(axis=None)\n",
    "    if (epoch == 0) or ((epoch + 1) % 1000 == 0):\n",
    "        print(\"Epoch {0:5d}: MSE = {1:.6f}\".format(epoch, mse))\n",
    "    \n",
    "    # derivatives of the logistic at each data-point\n",
    "    prediction_derivative = sigmoid_derivative(linear)\n",
    "    \n",
    "    # intermediate product of basic error and derivative terms\n",
    "    output_delta = basic_error * prediction_derivative \n",
    "    \n",
    "    # update the non-bias weights, factoring in the contribution of \n",
    "    # each corresponding feature-value; the use of the transpose (.T)\n",
    "    # and dot-product (np.dot) is just a nicer way to express this\n",
    "    # than writing a loop over each data point and accumulating that way\n",
    "    weight_updates = np.dot(x_n.T, output_delta)\n",
    "    input_weights += learning_rate * weight_updates\n",
    "    \n",
    "    # update bias according to all the delta-values on data (since\n",
    "    # bias \"input\" is always assumed == 1, no need for dot-product)\n",
    "    bias_weight += learning_rate * np.sum(output_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accepting-hindu",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96163494, 1.        ],\n",
       "       [0.96417037, 1.        ],\n",
       "       [0.01086803, 0.        ],\n",
       "       [0.02304013, 0.        ],\n",
       "       [0.98062401, 1.        ],\n",
       "       [0.0348307 , 0.        ],\n",
       "       [0.9968816 , 1.        ],\n",
       "       [0.04444612, 0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our final network output should be much closer than when we started,\n",
    "# with output values that are *close* to 0/1 as appropriate\n",
    "final_output = sigmoid(linear_sum(x_n, input_weights, bias_weight))\n",
    "np.vstack((final_output, y_n)).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

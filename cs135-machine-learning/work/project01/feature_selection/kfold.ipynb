{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ready-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "from numpy.random import default_rng\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(suppress=True, precision=2)\n",
    "plt.style.use('seaborn') # pretty matplotlib plots\n",
    "sns.set(font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "broken-bicycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 784)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load 3 feature version of x arrays\n",
    "x_train = np.loadtxt('./data_sneaker_vs_sandal/x_train.csv', delimiter=',', skiprows=1)\n",
    "x_test = np.loadtxt('./data_sneaker_vs_sandal/x_test.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "y_train = np.loadtxt('./data_sneaker_vs_sandal/y_train.csv', delimiter=',', skiprows=1)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "regulation-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_flip = np.flip(x_train.reshape(12000,28,28), axis = 2)\n",
    "x_test_flip = np.flip(x_test.reshape(2000,28,28), axis = 2)\n",
    "x_train_ft_flip = np.append(x_train, x_train_flip.reshape(12000,784),axis=1)\n",
    "x_test_ft_flip =  np.append(x_test, x_test_flip.reshape(2000,784),axis=1)\n",
    "y_train_ft_flip = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "commercial-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression(solver='liblinear')\n",
    "# model.fit(x_train_ft_flip, y_train_ft_flip)\n",
    "\n",
    "# prob_train = model.predict_proba(x_train_ft_flip)\n",
    "# acc_train = model.score(x_train_ft_flip, y_train_ft_flip)\n",
    "# train_log_loss = log_loss(y_train_ft_flip,prob_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "celtic-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_va, y_tr, y_va = train_test_split(x_train_ft_flip, y_train_ft_flip, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dedicated-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_grid = np.logspace(-9, 6, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "graduate-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = list()\n",
    "train_loss_list = list()\n",
    "train_acc_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "medium-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in C_grid:\n",
    "    model = LogisticRegression(solver='liblinear', C=C,max_iter=100000)\n",
    "    model.fit(x_train_ft_flip, y_train_ft_flip)\n",
    "    model_list.append(model)\n",
    "    \n",
    "    prob_train = model.predict_proba(x_train_ft_flip)\n",
    "    acc_train = model.score(x_train_ft_flip, y_train_ft_flip)\n",
    "\n",
    "    train_log_loss = log_loss(y_train_ft_flip,prob_train)\n",
    "    train_loss_list.append(train_log_loss)\n",
    "   \n",
    "    train_acc_list.append(acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "employed-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_train_loss = min(train_loss_list)\n",
    "min_train_loss_index = train_loss_list.index(min_train_loss)\n",
    "best_C =  C_grid[min_train_loss_index]\n",
    "best_acc = train_acc_list[min_train_loss_index]\n",
    "best_model = model_list[min_train_loss_index]\n",
    "yproba1_test = best_model.predict_proba(x_test_ft_flip)[:, 1] \n",
    "np.savetxt('yproba1_test.txt', yproba1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = list()\n",
    "tr_loss_list = list()\n",
    "va_loss_list = list()\n",
    "tr_acc_list = list()\n",
    "va_acc_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "joined-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in C_grid:\n",
    "    model = LogisticRegression(solver='liblinear', C=C,max_iter=100000)\n",
    "    model.fit(x_tr, y_tr)\n",
    "    model_list.append(model)\n",
    "    \n",
    "    prob_tr = model.predict_proba(x_tr)\n",
    "    prob_va = model.predict_proba(x_va)\n",
    "\n",
    "    acc_tr = model.score(x_tr, y_tr)\n",
    "    acc_va = model.score(x_va, y_va)\n",
    "\n",
    "    tr_log_loss = log_loss(y_tr,prob_tr)\n",
    "    va_log_loss = log_loss(y_va,prob_va)\n",
    "    \n",
    "    tr_loss_list.append(tr_log_loss)\n",
    "    va_loss_list.append(va_log_loss)\n",
    "    \n",
    "    tr_acc_list.append(acc_tr)\n",
    "    va_acc_list.append(acc_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "distributed-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_va_loss = min(va_loss_list)\n",
    "min_va_loss_index = va_loss_list.index(min_va_loss)\n",
    "best_C =  C_grid[min_va_loss_index]\n",
    "best_acc = va_acc_list[min_va_loss_index]\n",
    "best_model = model_list[min_va_loss_index]\n",
    "yproba1_test = best_model.predict_proba(x_test)[:, 1] \n",
    "np.savetxt('yproba1_test.txt', yproba1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "thick-alcohol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.31622776601683794, max_iter=100000, solver='liblinear')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "stupid-stocks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9842708333333333\n",
      "Test accuracy:  0.9445833333333333\n",
      "Train accuracy:  0.9857291666666667\n",
      "Test accuracy:  0.93375\n",
      "Train accuracy:  0.9848958333333333\n",
      "Test accuracy:  0.9458333333333333\n",
      "Train accuracy:  0.9847916666666666\n",
      "Test accuracy:  0.9391666666666667\n",
      "Train accuracy:  0.9841666666666666\n",
      "Test accuracy:  0.9483333333333334\n",
      "\n",
      "Average train accuracy:  0.9841666666666666\n",
      "Average test accuracy:  0.9483333333333334\n"
     ]
    }
   ],
   "source": [
    "# cross validation \n",
    "k = 5\n",
    "kfold = KFold(n_splits=k)\n",
    "tr_scores = []\n",
    "va_scores = []\n",
    "\n",
    "for train_idx, test_idx in kfold.split(x_train):\n",
    "    x_tr, x_va = x_train[train_idx,:], x_train[test_idx,:]\n",
    "    y_tr, y_va = y_train[train_idx], y_train[test_idx]\n",
    "    \n",
    "    model.fit(x_tr, y_tr)\n",
    "    pred_tr = model.predict(x_tr)\n",
    "    pred_va = model.predict(x_va)\n",
    "\n",
    "    acc_tr = accuracy_score(pred_tr, y_tr)\n",
    "    acc_va = accuracy_score(pred_va, y_va)\n",
    "    print(\"Train accuracy: \", acc_tr)\n",
    "    print(\"Test accuracy: \", acc_va)\n",
    "    \n",
    "    tr_scores.append(acc_tr)\n",
    "    va_scores.append(acc_va)\n",
    "    \n",
    "print(\"\\nAverage train accuracy: \", np.average(acc_tr))\n",
    "print(\"Average test accuracy: \", np.average(acc_va))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_train = minmax_scale(x_train_ft_flip)\n",
    "model = LogisticRegression(solver='liblinear', C=0.031, max_iter=100000)\n",
    "model.fit(X_scaled_train, y_train_ft_flip)\n",
    "pred_train = model.predict(X_scaled_train)\n",
    "acc_train = accuracy_score(pred_train, y_train_ft_flip)\n",
    "print(\"Train accuracy: \", acc_train)\n",
    "\n",
    "yproba1_test = model.predict_proba(x_test)[:, 1] \n",
    "np.savetxt('yproba1_test.txt', yproba1_test)\n",
    "# plt.imshow(np.reshape(x_train_ft_flip[12001], (28,28)), cmap=plt.cm.gray, vmin=0.0, vmax=1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "formed-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unnecessary-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn') # pretty matplotlib plots\n",
    "\n",
    "x_train_df = pd.read_csv('../data/data_reviews/x_train.csv')\n",
    "y_train_df = pd.read_csv('../data/data_reviews/y_train.csv')\n",
    "x_test_df = pd.read_csv('../data/data_reviews/x_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wanted-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_df['text'] \n",
    "x_test = x_test_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "israeli-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_i = np.where(x_train_df['website_name']=='amazon')\n",
    "imdb_i = np.where(x_train_df['website_name']=='imdb')\n",
    "yelp_i =  np.where(x_train_df['website_name']=='yelp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-registration",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "social-census",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autocorrect in /Users/mac/opt/anaconda3/envs/ml135_env/lib/python3.8/site-packages (2.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "conscious-melbourne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'absolute'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autocorrect import Speller\n",
    "spell = Speller()\n",
    "spell('absoluel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "nuclear-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "becoming-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = pd.read_csv('../data/data_reviews/modified_stopword.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-jordan",
   "metadata": {},
   "source": [
    "### Build your own tokenizer ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "formal-quarterly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/mac/.local/lib/python3.8/site-packages (3.6.2)\n",
      "Requirement already satisfied: click in /Users/mac/opt/anaconda3/envs/ml135_env/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /Users/mac/opt/anaconda3/envs/ml135_env/lib/python3.8/site-packages (from nltk) (4.60.0)\n",
      "Requirement already satisfied: joblib in /Users/mac/opt/anaconda3/envs/ml135_env/lib/python3.8/site-packages (from nltk) (1.0.0)\n",
      "Requirement already satisfied: regex in /Users/mac/opt/anaconda3/envs/ml135_env/lib/python3.8/site-packages (from nltk) (2021.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "logical-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "porterstemmer = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ongoing-empire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "busi\n",
      "bu\n",
      "busi\n",
      "busi\n"
     ]
    }
   ],
   "source": [
    "# same stem \n",
    "print(porterstemmer.stem('business'))\n",
    "print(porterstemmer.stem('bus'))\n",
    "print(porterstemmer.stem('businesses'))\n",
    "print(porterstemmer.stem('busy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-survey",
   "metadata": {},
   "source": [
    "# STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "oriental-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "# def decontracted(phrase):\n",
    "#     # specific\n",
    "#     phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "#     phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "#     # general\n",
    "#     phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "#     phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "#     phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "#     phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "#     phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "#     phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "#     phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "#     phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "#     return phrase\n",
    "\n",
    "def stemming_tokenizer(str_input):\n",
    "#     words = decontracted(str_input)\n",
    "    words = re.sub(r\"[^A-Za-z\\-]\", \" \", str_input).lower().split()\n",
    "    \n",
    "    # autocorrect\n",
    "    test_names = words\n",
    "    test_names_len = len(words)\n",
    "    words = [spell(test_names[i]) for i in range(test_names_len)]\n",
    "\n",
    "    # prune words\n",
    "#     def prune_food(w):\n",
    "#         if w == 'bones' or w == 'bone' or w == 'fish' or w == 'worms' or w == 'worm':\n",
    "#             w = 'food'\n",
    "#         return w\n",
    "    \n",
    "#     words = [prune_food(word) for word in words]\n",
    "    \n",
    "    # stemming \n",
    "    porter_stemmer = PorterStemmer()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    \n",
    "    #remove non important words\n",
    "    non_important = ['film', 'movie','apple', 'juice']\n",
    "    words = [w for w in words if w not in non_important]\n",
    "    \n",
    "    stop_words = common_words['words']\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-broadway",
   "metadata": {},
   "source": [
    "**Note: tense, persons**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-precipitation",
   "metadata": {},
   "source": [
    "## TF/IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adverse-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "complicated-grant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3429"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectorizer = TfidfVectorizer(tokenizer=stemming_tokenizer, use_idf = True)\n",
    "x = tf_vectorizer.fit_transform(x_train)\n",
    "x_te = tf_vectorizer.transform(x_test)\n",
    "features = tf_vectorizer.get_feature_names()\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-building",
   "metadata": {},
   "source": [
    "# NeuroNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "educated-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from MLPClassifierWithSolverLBFGS import MLPClassifierLBFGS\n",
    "\n",
    "from viz_tools_for_binary_classifier import plot_pretty_probabilities_for_clf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "statutory-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x.toarray()\n",
    "y = y_train_df['is_positive_sentiment'].to_numpy()\n",
    "feat_num = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-bennett",
   "metadata": {},
   "source": [
    "### Problem 2: MLP size [2] with activation Logistic and L-BFGS solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "loving-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-cornwall",
   "metadata": {},
   "source": [
    "### iteration - best at 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "spatial-assembly",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For 1 hidden layers :  10\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  17.269521463693707\n",
      "Average test loss:  17.269521463693707\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  20\n",
      "\n",
      "Average train accuracy:  0.84875\n",
      "Average test accuracy:  0.76125\n",
      "\n",
      "Average train loss:  9.253547825360604\n",
      "Average test loss:  12.318879222860742\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  30\n",
      "\n",
      "Average train accuracy:  0.93125\n",
      "Average test accuracy:  0.7775\n",
      "\n",
      "Average train loss:  3.439522797709811\n",
      "Average test loss:  8.908219698053164\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  40\n",
      "\n",
      "Average train accuracy:  0.9825\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.9714087499219944\n",
      "Average test loss:  8.663565367604205\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  50\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.75875\n",
      "\n",
      "Average train loss:  0.4101489691863531\n",
      "Average test loss:  9.124083718865398\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  60\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.2806280579570441\n",
      "Average test loss:  9.037734445718952\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  70\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.22306293088379917\n",
      "Average test loss:  9.296780599330315\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  80\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.21586751905099075\n",
      "Average test loss:  9.138477874186975\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  90\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.21586751905099075\n",
      "Average test loss:  9.282396772142214\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  100\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.21586751905099075\n",
      "Average test loss:  9.354357220616619\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  110\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.21586735246819277\n",
      "Average test loss:  9.253616457473363\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  120\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.21586751905099075\n",
      "Average test loss:  9.124094046998872\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  130\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.21586751905099075\n",
      "Average test loss:  9.26800794747017\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  140\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.21586751905099075\n",
      "Average test loss:  9.03774344119004\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  150\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.21586768563378866\n",
      "Average test loss:  9.268011279126132\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  160\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.20867194063538433\n",
      "Average test loss:  9.196055161804471\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  170\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.20867177405258638\n",
      "Average test loss:  9.138486203326872\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  180\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.22306526304297056\n",
      "Average test loss:  9.268006281642192\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  190\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.1726963807165238\n",
      "Average test loss:  9.354351889967086\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  200\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.14391356730570434\n",
      "Average test loss:  9.224831811651766\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  210\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.10073959706367208\n",
      "Average test loss:  9.181662005979684\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  220\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.10073943048087412\n",
      "Average test loss:  9.181657008495746\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  230\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.06476070548885239\n",
      "Average test loss:  8.980176481706017\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  240\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.04317363707643731\n",
      "Average test loss:  9.023350951696445\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  250\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.04317347049363934\n",
      "Average test loss:  9.052133598524465\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  260\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.04317347049363934\n",
      "Average test loss:  9.109698559014914\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  270\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.04317347049363934\n",
      "Average test loss:  9.18165734166134\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  280\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.04317347049363934\n",
      "Average test loss:  9.167266184830128\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  290\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.04317347049363934\n",
      "Average test loss:  9.196049164823744\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  300\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.04317347049363934\n",
      "Average test loss:  9.152874028502128\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_range = 20\n",
    "model_list = []\n",
    "aver_train_score = []\n",
    "aver_test_score = []\n",
    "aver_train_loss = []\n",
    "aver_test_loss = []\n",
    "\n",
    "for i in range(30):\n",
    "    k = 3\n",
    "    kfold = KFold(n_splits=k)\n",
    "    \n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "\n",
    "    model = MLPClassifier(hidden_layer_sizes=(1,8), \n",
    "                    activation='logistic',\n",
    "                    solver='lbfgs',\n",
    "                    alpha=0.0001,\n",
    "                    max_iter=10*(i+1), tol=1e-6,\n",
    "                    random_state=1 )\n",
    "    for train_idx, test_idx in kfold.split(X):\n",
    "        X_train, X_test = X[train_idx,:], X[test_idx,:]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = model.predict_proba(X_train)\n",
    "        pred_test = model.predict_proba(X_test)\n",
    "\n",
    "        # Score\n",
    "        score_train = model.score(X_train, y_train)\n",
    "        score_test = model.score(X_test, y_test)\n",
    "#         print(\"Train score: \", score_train)\n",
    "#         print(\"Test score: \", score_test)\n",
    "        train_scores.append(score_train)\n",
    "        test_scores.append(score_test)\n",
    "        \n",
    "        # Log loss\n",
    "        log_loss_train = sklearn.metrics.log_loss(y_train,pred_train)\n",
    "        log_loss_test = sklearn.metrics.log_loss(y_test,pred_test)\n",
    "    \n",
    "#         print(\"Train loss: \", log_loss_train)\n",
    "#         print(\"Test loss: \", log_loss_test)\n",
    "        train_loss.append(log_loss_train)\n",
    "        test_loss.append(log_loss_test)\n",
    "        \n",
    "#         with warnings.catch_warnings(record=True) as warn_list:\n",
    "#             print('finished LBFGS run :loss %.3f' % (\n",
    "#              model.loss_))\n",
    "        \n",
    "    print(\"\\nFor 1 hidden layers : \", 10*(i+1))\n",
    "    print(\"\\nAverage train accuracy: \", np.average(score_train))\n",
    "    print(\"Average test accuracy: \", np.average(score_test))\n",
    "    print(\"\\nAverage train loss: \", np.average(train_loss))\n",
    "    print(\"Average test loss: \", np.average(test_loss))\n",
    "    \n",
    "    print('------------------------------------------------\\n')\n",
    "    \n",
    "#     model_list.append(model)\n",
    "#     aver_train_score.append(np.average(score_train))\n",
    "#     aver_test_score.append(np.average(score_test))\n",
    "#     aver_train_loss.append(np.average(train_loss))\n",
    "#     aver_test_loss.append(np.average(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-setup",
   "metadata": {},
   "source": [
    "### Best neuron number - i (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "civilian-reputation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7089257613158457\n",
      "Average test loss:  0.7097506054152346\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.695142752836606\n",
      "Average test loss:  0.6967997604490588\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6895954773445615\n",
      "Average test loss:  0.692465935878969\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.501875\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6857397669098647\n",
      "Average test loss:  0.6905991564728088\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.834375\n",
      "Average test accuracy:  0.62875\n",
      "\n",
      "Average train loss:  0.6802510591970244\n",
      "Average test loss:  0.6886349604468679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.916875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.670058233326874\n",
      "Average test loss:  0.6850964587650434\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6505174470316154\n",
      "Average test loss:  0.6782406017227735\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6158477951960681\n",
      "Average test loss:  0.6658218014743144\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5635931698780713\n",
      "Average test loss:  0.646653672002342\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.4978635348219702\n",
      "Average test loss:  0.6221131791412996\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.4276697177107341\n",
      "Average test loss:  0.595926089620225\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.36326319044005234\n",
      "Average test loss:  0.5726124012170594\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.30918585657247627\n",
      "Average test loss:  0.5545302869167038\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2651172509862172\n",
      "Average test loss:  0.5415679303912753\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2292424633603982\n",
      "Average test loss:  0.5333249249912734\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.19987350894069736\n",
      "Average test loss:  0.5287224333308699\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.17562257458609223\n",
      "Average test loss:  0.5272332908470369\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.15541809290240577\n",
      "Average test loss:  0.5281181729906463\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.1384318092440395\n",
      "Average test loss:  0.5308722327780355\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.1240212841454688\n",
      "Average test loss:  0.5350599097330219\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.11171701525447364\n",
      "Average test loss:  0.5407677670607393\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.10113259152622821\n",
      "Average test loss:  0.5472486087218872\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.09196798168580189\n",
      "Average test loss:  0.5546761733545966\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.08398514142091355\n",
      "Average test loss:  0.5625255349845119\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07699924541113447\n",
      "Average test loss:  0.5710967840524631\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07084343440806294\n",
      "Average test loss:  0.5801579796669251\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06537908925069641\n",
      "Average test loss:  0.5894747047881929\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06050265973741937\n",
      "Average test loss:  0.5991574469919314\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.056125725188382485\n",
      "Average test loss:  0.6089705268770755\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.05216531556528109\n",
      "Average test loss:  0.6190224254491486\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_range = 20\n",
    "model_list = []\n",
    "aver_train_score = []\n",
    "aver_test_score = []\n",
    "aver_train_loss = []\n",
    "aver_test_loss = []\n",
    "\n",
    "\n",
    "# for t in range(10):\n",
    "#     for i in range(10):\n",
    "for iteration in range(30):\n",
    "    k = 3\n",
    "    kfold = KFold(n_splits=k)\n",
    "\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "\n",
    "    model = MLPClassifier(hidden_layer_sizes=(8,4), \n",
    "                    activation='logistic',\n",
    "                    solver='adam',\n",
    "                    alpha=0.0001,\n",
    "                    max_iter=(iteration+1)*10, tol=1e-6,\n",
    "                    random_state=1)\n",
    "    for train_idx, test_idx in kfold.split(X):\n",
    "        X_train, X_test = X[train_idx,:], X[test_idx,:]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = model.predict_proba(X_train)\n",
    "        pred_test = model.predict_proba(X_test)\n",
    "\n",
    "        # Score\n",
    "        score_train = model.score(X_train, y_train)\n",
    "        score_test = model.score(X_test, y_test)\n",
    "#         print(\"Train score: \", score_train)\n",
    "#         print(\"Test score: \", score_test)\n",
    "        train_scores.append(score_train)\n",
    "        test_scores.append(score_test)\n",
    "\n",
    "        # Log loss\n",
    "        log_loss_train = sklearn.metrics.log_loss(y_train,pred_train)\n",
    "        log_loss_test = sklearn.metrics.log_loss(y_test,pred_test)\n",
    "\n",
    "#         print(\"Train loss: \", log_loss_train)\n",
    "#         print(\"Test loss: \", log_loss_test)\n",
    "        train_loss.append(log_loss_train)\n",
    "        test_loss.append(log_loss_test)\n",
    "\n",
    "\n",
    "#         with warnings.catch_warnings(record=True) as warn_list:\n",
    "#             print('finished LBFGS run :loss %.3f' % (\n",
    "#              model.loss_))\n",
    "\n",
    "\n",
    "    print(\"For layers: \", 8)\n",
    "    print(\"For neurons: \", 4)\n",
    "    print(\"For iteration \", iteration)\n",
    "    print(\"\\nAverage train accuracy: \", np.average(score_train))\n",
    "    print(\"Average test accuracy: \", np.average(score_test))\n",
    "    print(\"\\nAverage train loss: \", np.average(train_loss))\n",
    "    print(\"Average test loss: \", np.average(test_loss))\n",
    "\n",
    "    print('------------------------------------------------\\n')\n",
    "\n",
    "    model_list.append(model)\n",
    "    aver_train_score.append(np.average(score_train))\n",
    "    aver_test_score.append(np.average(score_test))\n",
    "    aver_train_loss.append(np.average(train_loss))\n",
    "    aver_test_loss.append(np.average(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-motor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-console",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-kingston",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-salad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-madness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-cheat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-champagne",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-assist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "duplicate-aspect",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7005294554338972\n",
      "Average test loss:  0.7005398440372136\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6957233108161484\n",
      "Average test loss:  0.6957286117000571\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6938723701812856\n",
      "Average test loss:  0.693883888794815\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6932433797865557\n",
      "Average test loss:  0.6932881942626573\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.69292300016579\n",
      "Average test loss:  0.6930888303354078\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6924003417996186\n",
      "Average test loss:  0.692881927822655\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9075\n",
      "Average test accuracy:  0.69375\n",
      "\n",
      "Average train loss:  0.6914279546658816\n",
      "Average test loss:  0.6925268317815814\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.898125\n",
      "Average test accuracy:  0.70625\n",
      "\n",
      "Average train loss:  0.6897618722151027\n",
      "Average test loss:  0.6919196575699932\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.909375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.6869672351753842\n",
      "Average test loss:  0.690895148935784\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.92875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.6823511369927587\n",
      "Average test loss:  0.6891886068765808\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.6749840532410255\n",
      "Average test loss:  0.6864384350942926\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.6639569432431491\n",
      "Average test loss:  0.6822807715354978\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.6488145976005503\n",
      "Average test loss:  0.6765337211421296\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.6297032270606883\n",
      "Average test loss:  0.6692171276294471\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.6072270572948039\n",
      "Average test loss:  0.6605884067418885\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.75875\n",
      "\n",
      "Average train loss:  0.5820891932481121\n",
      "Average test loss:  0.6509172135787094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.5551574441561433\n",
      "Average test loss:  0.6405452030638608\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.5272252900463144\n",
      "Average test loss:  0.6298759610508388\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.49901532355267547\n",
      "Average test loss:  0.6190780497105758\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.4711622182797246\n",
      "Average test loss:  0.6085702170866506\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.96625\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.44406246496604923\n",
      "Average test loss:  0.5984979845804712\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.4180045011844388\n",
      "Average test loss:  0.5890039745113681\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3931430714549789\n",
      "Average test loss:  0.5801864718146271\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.36959168101468975\n",
      "Average test loss:  0.5721099725666168\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3473941929727913\n",
      "Average test loss:  0.5646620615157288\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.32654758069161316\n",
      "Average test loss:  0.5580838862457184\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.30702694446868944\n",
      "Average test loss:  0.5521766739357026\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.28878074680872695\n",
      "Average test loss:  0.5471768788986817\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.271752116819798\n",
      "Average test loss:  0.5428452551930484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.25587699027953237\n",
      "Average test loss:  0.5391414055850984\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7017459810458083\n",
      "Average test loss:  0.7017874629299974\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6950656967741399\n",
      "Average test loss:  0.695161069251197\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6930698117287917\n",
      "Average test loss:  0.6933490401044473\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6918711257360842\n",
      "Average test loss:  0.6927308190840703\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.735\n",
      "Average test accuracy:  0.56625\n",
      "\n",
      "Average train loss:  0.689915393155277\n",
      "Average test loss:  0.6920038510804752\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6869099155121708\n",
      "Average test loss:  0.6909341116385498\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.89\n",
      "Average test accuracy:  0.6725\n",
      "\n",
      "Average train loss:  0.6828395097499823\n",
      "Average test loss:  0.6894863434883324\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.8675\n",
      "Average test accuracy:  0.6225\n",
      "\n",
      "Average train loss:  0.6776511699907527\n",
      "Average test loss:  0.6876431186887094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.86875\n",
      "Average test accuracy:  0.62375\n",
      "\n",
      "Average train loss:  0.6711284758114199\n",
      "Average test loss:  0.6853083616460499\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.880625\n",
      "Average test accuracy:  0.6325\n",
      "\n",
      "Average train loss:  0.6629037288957935\n",
      "Average test loss:  0.6823552386081749\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.896875\n",
      "Average test accuracy:  0.66625\n",
      "\n",
      "Average train loss:  0.6524341714786962\n",
      "Average test loss:  0.6785421836183242\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.91\n",
      "Average test accuracy:  0.6875\n",
      "\n",
      "Average train loss:  0.63909927554148\n",
      "Average test loss:  0.6736597119148057\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.7125\n",
      "\n",
      "Average train loss:  0.6223565535916874\n",
      "Average test loss:  0.6674206546959397\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.94125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.6018944734243061\n",
      "Average test loss:  0.6597922203883599\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.5778989480746972\n",
      "Average test loss:  0.650789772219996\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.5510996751894053\n",
      "Average test loss:  0.6408158740067246\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5220648590196489\n",
      "Average test loss:  0.6300876375511023\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.958125\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.4916647894442859\n",
      "Average test loss:  0.6189473927298889\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.46068949368686374\n",
      "Average test loss:  0.6077818776415354\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.4299076979933048\n",
      "Average test loss:  0.5968313935374918\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3999180332202758\n",
      "Average test loss:  0.5863922649896106\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.3711625436335508\n",
      "Average test loss:  0.5767344613683999\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.34400494851247077\n",
      "Average test loss:  0.568030904477045\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3185927569633206\n",
      "Average test loss:  0.5602229990889959\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2950033008494264\n",
      "Average test loss:  0.553694640334892\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.27318703552587215\n",
      "Average test loss:  0.5479846786911868\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.25311106210337697\n",
      "Average test loss:  0.5433360138546028\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.23467783147248256\n",
      "Average test loss:  0.5395091827202345\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.21779856704212094\n",
      "Average test loss:  0.5368094097895747\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.20234579841839098\n",
      "Average test loss:  0.534645924991742\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6982820562332842\n",
      "Average test loss:  0.6983915288591721\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6933338488376656\n",
      "Average test loss:  0.6936944301470566\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6918869168294853\n",
      "Average test loss:  0.6927501754864592\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.915\n",
      "Average test accuracy:  0.68125\n",
      "\n",
      "Average train loss:  0.6903597288351895\n",
      "Average test loss:  0.6921791637516207\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6878417159809903\n",
      "Average test loss:  0.6912919817475394\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.94375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.6839442896931308\n",
      "Average test loss:  0.6899135041970706\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6783100673958469\n",
      "Average test loss:  0.6879005622217803\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6704440726968119\n",
      "Average test loss:  0.6850680495423931\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.6596857019150905\n",
      "Average test loss:  0.6811624364034614\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.6453238585426988\n",
      "Average test loss:  0.6759301367521999\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.6266430574580806\n",
      "Average test loss:  0.6690618978057348\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.6034038414721389\n",
      "Average test loss:  0.6605098459485128\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.575675283402601\n",
      "Average test loss:  0.6502343946307992\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.5441206850060811\n",
      "Average test loss:  0.6386249589127551\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.5097629024264306\n",
      "Average test loss:  0.6260881869619405\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.4739570696645874\n",
      "Average test loss:  0.6131862312315367\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.4379017393609253\n",
      "Average test loss:  0.6003241774937309\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.4026712525737594\n",
      "Average test loss:  0.5881587851326255\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3690593910592603\n",
      "Average test loss:  0.5769475248677269\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.966875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.3375474011442637\n",
      "Average test loss:  0.5669392739989525\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.308420398900793\n",
      "Average test loss:  0.5581006196182613\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2817824131896938\n",
      "Average test loss:  0.5508302785342779\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.25759252158008245\n",
      "Average test loss:  0.5446990102418523\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.23574101584949983\n",
      "Average test loss:  0.5403214923063983\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.21605198114217436\n",
      "Average test loss:  0.5365816435510261\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.19833110771618276\n",
      "Average test loss:  0.5343190335711073\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.18237904473975544\n",
      "Average test loss:  0.532996199095119\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.16801550945904922\n",
      "Average test loss:  0.5326528628516788\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.15507521725063114\n",
      "Average test loss:  0.5330682437107455\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.14339220397774657\n",
      "Average test loss:  0.5343860218341836\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6986740284939855\n",
      "Average test loss:  0.699062002573962\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6926601111020734\n",
      "Average test loss:  0.6934756881901977\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6911365585324938\n",
      "Average test loss:  0.6924997868607283\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.796875\n",
      "Average test accuracy:  0.545\n",
      "\n",
      "Average train loss:  0.6898589158097317\n",
      "Average test loss:  0.6920123269596131\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.876875\n",
      "Average test accuracy:  0.6125\n",
      "\n",
      "Average train loss:  0.6880255740096466\n",
      "Average test loss:  0.6913705794921472\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.875\n",
      "Average test accuracy:  0.6125\n",
      "\n",
      "Average train loss:  0.6852987454137739\n",
      "Average test loss:  0.6904197045514966\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.88625\n",
      "Average test accuracy:  0.6325\n",
      "\n",
      "Average train loss:  0.6812983585040261\n",
      "Average test loss:  0.6890203017576191\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.8875\n",
      "Average test accuracy:  0.63875\n",
      "\n",
      "Average train loss:  0.675523736709729\n",
      "Average test loss:  0.6869990221927567\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.890625\n",
      "Average test accuracy:  0.6525\n",
      "\n",
      "Average train loss:  0.6673803238449144\n",
      "Average test loss:  0.6841455234945321\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9\n",
      "Average test accuracy:  0.6675\n",
      "\n",
      "Average train loss:  0.6560762517402328\n",
      "Average test loss:  0.680172174248535\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.9075\n",
      "Average test accuracy:  0.68625\n",
      "\n",
      "Average train loss:  0.6407889967459997\n",
      "Average test loss:  0.6747683691504983\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.925625\n",
      "Average test accuracy:  0.70375\n",
      "\n",
      "Average train loss:  0.620790759864598\n",
      "Average test loss:  0.6676858536746971\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.5958386650293223\n",
      "Average test loss:  0.6588075922817508\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.936875\n",
      "Average test accuracy:  0.71375\n",
      "\n",
      "Average train loss:  0.5662987919546167\n",
      "Average test loss:  0.648473502478819\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.715\n",
      "\n",
      "Average train loss:  0.5328540630739459\n",
      "Average test loss:  0.636696865462314\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.4968642882138932\n",
      "Average test loss:  0.6242371400995038\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.955\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.4597279550049671\n",
      "Average test loss:  0.6114153818790556\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.4226693528047611\n",
      "Average test loss:  0.5989760494360666\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.386833898037686\n",
      "Average test loss:  0.5871416578227912\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3530025487112778\n",
      "Average test loss:  0.5767072899340123\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.3216007337893912\n",
      "Average test loss:  0.5673384063619504\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.29283679087837394\n",
      "Average test loss:  0.5592409133905049\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2667592043104434\n",
      "Average test loss:  0.5526714986845548\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.24323779399081077\n",
      "Average test loss:  0.5478213014932719\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2221030075099432\n",
      "Average test loss:  0.5439568455392559\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2031551260412645\n",
      "Average test loss:  0.5413957689920994\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1861794331503629\n",
      "Average test loss:  0.5401143506561344\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.17096430142398342\n",
      "Average test loss:  0.5395081400131999\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.15731488613829006\n",
      "Average test loss:  0.5400562060423595\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.14505596240792154\n",
      "Average test loss:  0.5414270933752853\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6938432282308608\n",
      "Average test loss:  0.694123309774367\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6921018743823355\n",
      "Average test loss:  0.6927993649999218\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.81125\n",
      "Average test accuracy:  0.635\n",
      "\n",
      "Average train loss:  0.6910264554060855\n",
      "Average test loss:  0.6924142995773112\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.818125\n",
      "Average test accuracy:  0.63875\n",
      "\n",
      "Average train loss:  0.6892008984017487\n",
      "Average test loss:  0.6917796099301766\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6862044992439621\n",
      "Average test loss:  0.6907301429493766\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6815282037035914\n",
      "Average test loss:  0.6890838261228991\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.6744819306563681\n",
      "Average test loss:  0.6865897663912608\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6641303944189053\n",
      "Average test loss:  0.6828960096056682\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6492329687519879\n",
      "Average test loss:  0.6775412207779942\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6285818359919378\n",
      "Average test loss:  0.6700819764020854\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.6013680461880332\n",
      "Average test loss:  0.6602201255756038\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.5678290494160384\n",
      "Average test loss:  0.6479996167294857\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.529037464560802\n",
      "Average test loss:  0.6340023136572438\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.4870103992022674\n",
      "Average test loss:  0.6190040092377497\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.443750867663482\n",
      "Average test loss:  0.6038287383660198\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.40116535429253136\n",
      "Average test loss:  0.5892785034231237\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3608515305740792\n",
      "Average test loss:  0.5760887700835728\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.32370866170944934\n",
      "Average test loss:  0.5645433725085479\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.29015582714944455\n",
      "Average test loss:  0.5550832233122124\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.26022590768329623\n",
      "Average test loss:  0.5476572058460555\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.23375816384356082\n",
      "Average test loss:  0.5417785815201223\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.21046457550792133\n",
      "Average test loss:  0.5377748719782566\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.18999817337592773\n",
      "Average test loss:  0.5355434545871322\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.17202357508027136\n",
      "Average test loss:  0.5343991155491205\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.15621539094008677\n",
      "Average test loss:  0.5347337765576106\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.14226886593137203\n",
      "Average test loss:  0.5360509968905758\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1299616027696747\n",
      "Average test loss:  0.5381172866990679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.11904767845325637\n",
      "Average test loss:  0.5413307880736378\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.10933963573098743\n",
      "Average test loss:  0.5451206269134198\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.10068541356261018\n",
      "Average test loss:  0.549574690461608\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6964048028479414\n",
      "Average test loss:  0.6966777699440069\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6923326919951288\n",
      "Average test loss:  0.6929862688497708\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.7775\n",
      "Average test accuracy:  0.53125\n",
      "\n",
      "Average train loss:  0.6912471772431396\n",
      "Average test loss:  0.6924927370157518\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6897215761348813\n",
      "Average test loss:  0.6919582926864004\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.910625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.6871974179098609\n",
      "Average test loss:  0.6910737186519365\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6831486839848226\n",
      "Average test loss:  0.6896495576035346\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6768517784479685\n",
      "Average test loss:  0.6874230770614186\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6672326660526983\n",
      "Average test loss:  0.6839974035488998\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.945625\n",
      "Average test accuracy:  0.7575\n",
      "\n",
      "Average train loss:  0.6529648279500696\n",
      "Average test loss:  0.6788893747576928\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.6327032749361551\n",
      "Average test loss:  0.6715786731154388\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.6053901834517518\n",
      "Average test loss:  0.6616836024675469\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.5709294485911997\n",
      "Average test loss:  0.6492181246814406\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.5301925059988134\n",
      "Average test loss:  0.6345265030831562\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.4853497129354524\n",
      "Average test loss:  0.618615074379905\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.4390258676620357\n",
      "Average test loss:  0.6024460753414312\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3936629378912811\n",
      "Average test loss:  0.5872606718302374\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.35110654965749366\n",
      "Average test loss:  0.5734111912236011\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.31236111611079515\n",
      "Average test loss:  0.5617897867697278\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.27783094956571824\n",
      "Average test loss:  0.5523267462097475\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.24747772937207135\n",
      "Average test loss:  0.5451326112822642\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.22099276219272235\n",
      "Average test loss:  0.5401306829865541\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.19795816613144948\n",
      "Average test loss:  0.5370187531829643\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1779282240326069\n",
      "Average test loss:  0.5353493054081694\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.16049765112159634\n",
      "Average test loss:  0.5352702623728484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.14530008445038115\n",
      "Average test loss:  0.5362642028309876\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1319859404459862\n",
      "Average test loss:  0.5386961673478461\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.12028917079409833\n",
      "Average test loss:  0.5416551750865083\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.1099719964290729\n",
      "Average test loss:  0.5456999465176495\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.10084091989401811\n",
      "Average test loss:  0.5503061042669896\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.09272365631325992\n",
      "Average test loss:  0.555578185074637\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6929797147110236\n",
      "Average test loss:  0.6930898307985885\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.664375\n",
      "Average test accuracy:  0.54375\n",
      "\n",
      "Average train loss:  0.6924934791982884\n",
      "Average test loss:  0.6929206361020065\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.92375\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.6912289983673326\n",
      "Average test loss:  0.6924812258374996\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.839375\n",
      "Average test accuracy:  0.58625\n",
      "\n",
      "Average train loss:  0.6886416249218875\n",
      "Average test loss:  0.691586013314215\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.9275\n",
      "Average test accuracy:  0.71375\n",
      "\n",
      "Average train loss:  0.684213041642975\n",
      "Average test loss:  0.6900314836915928\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.89875\n",
      "Average test accuracy:  0.67875\n",
      "\n",
      "Average train loss:  0.6771274136766583\n",
      "Average test loss:  0.6875598165776058\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.925625\n",
      "Average test accuracy:  0.70375\n",
      "\n",
      "Average train loss:  0.6661108829993664\n",
      "Average test loss:  0.6836606662102672\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.93375\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.6495883299827555\n",
      "Average test loss:  0.6777351409421994\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.6259169508235074\n",
      "Average test loss:  0.6692882012634634\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.5943225357931794\n",
      "Average test loss:  0.6579145528248338\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.5553238390360403\n",
      "Average test loss:  0.6439580932277528\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.5107242681706176\n",
      "Average test loss:  0.6280383377281703\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.4630676058423208\n",
      "Average test loss:  0.611556792721477\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.41530641000658575\n",
      "Average test loss:  0.5952147760253896\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.36969133785757274\n",
      "Average test loss:  0.5805453353372098\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3278242398080642\n",
      "Average test loss:  0.5674872310962206\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.29034919865859327\n",
      "Average test loss:  0.5569845315361489\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.25740482870815884\n",
      "Average test loss:  0.548776880873706\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.22868661580177077\n",
      "Average test loss:  0.543222794414231\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.20382183382667993\n",
      "Average test loss:  0.5393448835435452\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.1822977766833859\n",
      "Average test loss:  0.5371432851268564\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1636749111627489\n",
      "Average test loss:  0.5368929311258459\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.14750863328583178\n",
      "Average test loss:  0.5378231810763763\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13344113542734112\n",
      "Average test loss:  0.5401143345652949\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.12115317211227151\n",
      "Average test loss:  0.5431816579452332\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.11036835398861149\n",
      "Average test loss:  0.5471737223327502\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.10087070645129083\n",
      "Average test loss:  0.5519614315541534\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09247968937871615\n",
      "Average test loss:  0.557477029753625\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08502696866697247\n",
      "Average test loss:  0.5638562570381361\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07837757793806072\n",
      "Average test loss:  0.5701891374163082\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.800625\n",
      "Average test accuracy:  0.58375\n",
      "\n",
      "Average train loss:  0.6930901370677017\n",
      "Average test loss:  0.6931268885349545\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6926216158853378\n",
      "Average test loss:  0.6929645332385221\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.64625\n",
      "Average test accuracy:  0.505\n",
      "\n",
      "Average train loss:  0.6911212078408489\n",
      "Average test loss:  0.6924434322289633\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.901875\n",
      "Average test accuracy:  0.6925\n",
      "\n",
      "Average train loss:  0.6880430519126118\n",
      "Average test loss:  0.6913673268939052\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.9225\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.6828876487966227\n",
      "Average test loss:  0.6895595594037323\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.6747140000898016\n",
      "Average test loss:  0.6866650798216716\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.6620564960245211\n",
      "Average test loss:  0.6821667837314602\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.6430880964394845\n",
      "Average test loss:  0.6753896258774462\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6161724034268318\n",
      "Average test loss:  0.6656732586294344\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5807804585694664\n",
      "Average test loss:  0.6529133218684288\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5376609987578084\n",
      "Average test loss:  0.6374463228023766\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.4894282027264771\n",
      "Average test loss:  0.6202619612525828\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.43935320486563206\n",
      "Average test loss:  0.6028160136257288\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.3902578096466172\n",
      "Average test loss:  0.5861236187190438\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.3444151893514725\n",
      "Average test loss:  0.5717771572817993\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.96625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3031140849410245\n",
      "Average test loss:  0.5593039765604797\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2667935597171171\n",
      "Average test loss:  0.5498189553078786\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.23533426057580256\n",
      "Average test loss:  0.5429488355799076\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.20826162815836857\n",
      "Average test loss:  0.5385422301073496\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.18502327821538844\n",
      "Average test loss:  0.5360065873927433\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.165084479472444\n",
      "Average test loss:  0.5353686802291548\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.14796436077522782\n",
      "Average test loss:  0.5363838149836735\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13318972517284602\n",
      "Average test loss:  0.5386486315681557\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.12039974178985417\n",
      "Average test loss:  0.5420023003891986\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.10926405416275321\n",
      "Average test loss:  0.5463237458493145\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.09951880778024162\n",
      "Average test loss:  0.551409147711771\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09094420312154239\n",
      "Average test loss:  0.5573425822258377\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08338553455203818\n",
      "Average test loss:  0.5636054020163095\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07667712118452148\n",
      "Average test loss:  0.5706616965493121\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07070242983197365\n",
      "Average test loss:  0.5780118333740777\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6929778347439598\n",
      "Average test loss:  0.6930999782567108\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.534375\n",
      "Average test accuracy:  0.505\n",
      "\n",
      "Average train loss:  0.6925772016029755\n",
      "Average test loss:  0.6929475387882033\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.75125\n",
      "Average test accuracy:  0.57\n",
      "\n",
      "Average train loss:  0.69161735765431\n",
      "Average test loss:  0.6926137042448272\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.928125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.6895449607057098\n",
      "Average test loss:  0.6918914503737801\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.82625\n",
      "Average test accuracy:  0.63375\n",
      "\n",
      "Average train loss:  0.6858161242625607\n",
      "Average test loss:  0.690592612065951\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6796164632127343\n",
      "Average test loss:  0.6884026913795759\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.6696190153145111\n",
      "Average test loss:  0.68485465319065\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.653966375064886\n",
      "Average test loss:  0.6792580569194694\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.94375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6309345036120498\n",
      "Average test loss:  0.6709558530833145\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.598993076262492\n",
      "Average test loss:  0.659371716053828\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5583244151895369\n",
      "Average test loss:  0.6446111994885575\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.510532277985857\n",
      "Average test loss:  0.6273789719117889\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.955\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.4585202717218349\n",
      "Average test loss:  0.6088884777869147\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.40620903686580245\n",
      "Average test loss:  0.5908602150315977\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.356711224708051\n",
      "Average test loss:  0.5747033258684325\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.3119099797013527\n",
      "Average test loss:  0.5610023768144287\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2725705049698665\n",
      "Average test loss:  0.5502453478957562\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.23869054945503895\n",
      "Average test loss:  0.5426202883713771\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.20981634604141045\n",
      "Average test loss:  0.5374921522924682\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.18528621487649855\n",
      "Average test loss:  0.5347720946291451\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1644389124612353\n",
      "Average test loss:  0.5338792074238539\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.146666131402761\n",
      "Average test loss:  0.5348327077316362\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.13146001301330087\n",
      "Average test loss:  0.5373499957785218\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.11838218713900062\n",
      "Average test loss:  0.5410288686788337\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1070612458923822\n",
      "Average test loss:  0.5455526096106053\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09722280174569105\n",
      "Average test loss:  0.5509321307571353\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08862477011692077\n",
      "Average test loss:  0.5569626128050368\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.08106005568275841\n",
      "Average test loss:  0.5638196237420695\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07439027683781392\n",
      "Average test loss:  0.5708415721921557\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06846519451494977\n",
      "Average test loss:  0.5788478604783175\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6930369284691963\n",
      "Average test loss:  0.6931110772933748\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6925324962062143\n",
      "Average test loss:  0.6929377018015809\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.929375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.6909471210606455\n",
      "Average test loss:  0.6923846661261398\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.89375\n",
      "Average test accuracy:  0.69875\n",
      "\n",
      "Average train loss:  0.6875260585655746\n",
      "Average test loss:  0.6911933572152603\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6814511492183977\n",
      "Average test loss:  0.6890626460031104\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6714796848680984\n",
      "Average test loss:  0.6855442503856799\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.938125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6558890064467903\n",
      "Average test loss:  0.6800019364668254\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6325978353218327\n",
      "Average test loss:  0.6716850775122762\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.59997448967002\n",
      "Average test loss:  0.659959016021726\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.5576736715113841\n",
      "Average test loss:  0.6447147063455506\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5079727569591254\n",
      "Average test loss:  0.6269148853649393\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.955\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.45470405956056087\n",
      "Average test loss:  0.6081776639591542\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.40172884298359324\n",
      "Average test loss:  0.5899988125525943\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.35218126559449375\n",
      "Average test loss:  0.5737465759089183\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.30769466313170996\n",
      "Average test loss:  0.5602349638428851\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.966875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.26882436654843866\n",
      "Average test loss:  0.5499588150449976\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.2354822170219997\n",
      "Average test loss:  0.5424386802384362\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2071041636719179\n",
      "Average test loss:  0.5375453073901654\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1830231771339238\n",
      "Average test loss:  0.5351651880183966\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1625482780740425\n",
      "Average test loss:  0.5344479588814192\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1450745065655965\n",
      "Average test loss:  0.5353843584310206\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1301095086715979\n",
      "Average test loss:  0.537817155940724\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.11722155901757343\n",
      "Average test loss:  0.5418276177130923\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.1060552795298808\n",
      "Average test loss:  0.5462637943952403\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09634115811848813\n",
      "Average test loss:  0.5519044904627709\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08782791447318061\n",
      "Average test loss:  0.5580427632810703\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.08035190370292196\n",
      "Average test loss:  0.5647163761832056\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07373538819276214\n",
      "Average test loss:  0.5720619869046862\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06786139495857312\n",
      "Average test loss:  0.5799984058731843\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.0626243745551729\n",
      "Average test loss:  0.587931067783158\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7788961165185567\n",
      "Average test loss:  0.7792437597581422\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7521293142926392\n",
      "Average test loss:  0.7527860514929426\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7329588033959674\n",
      "Average test loss:  0.733838106152707\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7192320599585892\n",
      "Average test loss:  0.7202458766932772\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7093451614041859\n",
      "Average test loss:  0.7104512675072865\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7020174526915349\n",
      "Average test loss:  0.7032672123344068\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6965055902498737\n",
      "Average test loss:  0.698101765269661\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6921574384248331\n",
      "Average test loss:  0.6944990712090484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6882819102263884\n",
      "Average test loss:  0.691977006703781\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.68415240684979\n",
      "Average test loss:  0.6899854461656556\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.92875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.679087534773427\n",
      "Average test loss:  0.688002273587568\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9125\n",
      "Average test accuracy:  0.70625\n",
      "\n",
      "Average train loss:  0.6724403310348771\n",
      "Average test loss:  0.6856057918561232\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.889375\n",
      "Average test accuracy:  0.66625\n",
      "\n",
      "Average train loss:  0.6634474776242041\n",
      "Average test loss:  0.6823901117645205\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.89875\n",
      "Average test accuracy:  0.67\n",
      "\n",
      "Average train loss:  0.6512990984772872\n",
      "Average test loss:  0.6779862446320614\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.914375\n",
      "Average test accuracy:  0.68875\n",
      "\n",
      "Average train loss:  0.6352650737716753\n",
      "Average test loss:  0.672101132181499\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.928125\n",
      "Average test accuracy:  0.70625\n",
      "\n",
      "Average train loss:  0.6149960673258129\n",
      "Average test loss:  0.6645623125287562\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.94125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.5904491148271646\n",
      "Average test loss:  0.6553128848826386\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.5621955103888115\n",
      "Average test loss:  0.6445679109181522\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.5312884724365005\n",
      "Average test loss:  0.6327359194236751\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.4989673968032726\n",
      "Average test loss:  0.6203725534515917\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.76\n",
      "\n",
      "Average train loss:  0.4663963309057997\n",
      "Average test loss:  0.608082801565245\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.966875\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.4344596766479147\n",
      "Average test loss:  0.5961387769747506\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.4038934549325061\n",
      "Average test loss:  0.5849316486746331\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3750589802217883\n",
      "Average test loss:  0.5746457684577821\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.34818214573652156\n",
      "Average test loss:  0.5654556779972681\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.32332842665643496\n",
      "Average test loss:  0.5575058806918888\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.30046798704918315\n",
      "Average test loss:  0.5506223509898452\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.27949118628084896\n",
      "Average test loss:  0.5447255458078113\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.26028104938083735\n",
      "Average test loss:  0.5400106121371638\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2427042791201696\n",
      "Average test loss:  0.5361494240058431\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7437614764037438\n",
      "Average test loss:  0.7443730138488481\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7168074957276623\n",
      "Average test loss:  0.7180312509393275\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7017100413505245\n",
      "Average test loss:  0.7035534951257792\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6938158043281035\n",
      "Average test loss:  0.696350996229798\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6895869098517645\n",
      "Average test loss:  0.6929651738743624\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6868232206386855\n",
      "Average test loss:  0.691295973002947\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.503125\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6841994231909375\n",
      "Average test loss:  0.6901269738737511\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.8375\n",
      "Average test accuracy:  0.555\n",
      "\n",
      "Average train loss:  0.6810366107074716\n",
      "Average test loss:  0.6889048022271494\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9175\n",
      "Average test accuracy:  0.67375\n",
      "\n",
      "Average train loss:  0.6769173742497596\n",
      "Average test loss:  0.6873973673831285\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.715\n",
      "\n",
      "Average train loss:  0.6714161355681205\n",
      "Average test loss:  0.685387981346253\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.6640474300745657\n",
      "Average test loss:  0.6826886057245719\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.6542612932949078\n",
      "Average test loss:  0.6790845839466932\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6414692051505043\n",
      "Average test loss:  0.6743471926975152\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.6251391011095233\n",
      "Average test loss:  0.6682513888495144\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.6050307995566055\n",
      "Average test loss:  0.6607185735692426\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.5811619351156173\n",
      "Average test loss:  0.6517178224419076\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.5538928275211267\n",
      "Average test loss:  0.6414859375931338\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.5237837951181072\n",
      "Average test loss:  0.6302187324051207\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.4914850648445466\n",
      "Average test loss:  0.6181618981037723\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.4577612264499697\n",
      "Average test loss:  0.6058526453868831\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.4235691342279462\n",
      "Average test loss:  0.5936989527618861\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.38976942840413287\n",
      "Average test loss:  0.5820838124270532\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3571064674200591\n",
      "Average test loss:  0.5714040175634446\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.32624770150496546\n",
      "Average test loss:  0.5618827073652305\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.2975763432992545\n",
      "Average test loss:  0.5537124104478836\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2713491465134715\n",
      "Average test loss:  0.5470613001775827\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.24757754828001466\n",
      "Average test loss:  0.541764493824909\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.22617601058496617\n",
      "Average test loss:  0.5380077763778655\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.20698075145899322\n",
      "Average test loss:  0.5353970551740058\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1897945045414361\n",
      "Average test loss:  0.5341276808805666\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.916875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.6922817250022589\n",
      "Average test loss:  0.6928471358560424\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.81375\n",
      "Average test accuracy:  0.58375\n",
      "\n",
      "Average train loss:  0.6910137372232507\n",
      "Average test loss:  0.6924131052023011\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.77875\n",
      "Average test accuracy:  0.55125\n",
      "\n",
      "Average train loss:  0.6888954916318727\n",
      "Average test loss:  0.6916919979691123\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.75625\n",
      "Average test accuracy:  0.5425\n",
      "\n",
      "Average train loss:  0.6853505963076393\n",
      "Average test loss:  0.6904932801693012\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.805625\n",
      "Average test accuracy:  0.56\n",
      "\n",
      "Average train loss:  0.6797081032289837\n",
      "Average test loss:  0.6885764903941792\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.854375\n",
      "Average test accuracy:  0.59375\n",
      "\n",
      "Average train loss:  0.6708752738482241\n",
      "Average test loss:  0.6855601932179357\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.88\n",
      "Average test accuracy:  0.62125\n",
      "\n",
      "Average train loss:  0.6569185843059602\n",
      "Average test loss:  0.6807900026152858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.895\n",
      "Average test accuracy:  0.66375\n",
      "\n",
      "Average train loss:  0.6352934024808912\n",
      "Average test loss:  0.6734106330382971\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.916875\n",
      "Average test accuracy:  0.6975\n",
      "\n",
      "Average train loss:  0.604293340404834\n",
      "Average test loss:  0.662706317637423\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.7075\n",
      "\n",
      "Average train loss:  0.564189964662581\n",
      "Average test loss:  0.6487841455908118\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.94125\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.5177953342016209\n",
      "Average test loss:  0.6327100099912206\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.4689371576411358\n",
      "Average test loss:  0.6158534556694361\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.4210821315838653\n",
      "Average test loss:  0.5997027486077594\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.376362037014796\n",
      "Average test loss:  0.5852028926728763\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.3358340963043775\n",
      "Average test loss:  0.5729611092706771\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.29972138479208216\n",
      "Average test loss:  0.5623977672711454\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.2679208247116415\n",
      "Average test loss:  0.554379430965365\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.24009534174836222\n",
      "Average test loss:  0.5482062993740039\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.21579199344060748\n",
      "Average test loss:  0.5440908931052074\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.19456394110602984\n",
      "Average test loss:  0.5414819452960428\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1759928585942989\n",
      "Average test loss:  0.5401968030554025\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.15971037065064925\n",
      "Average test loss:  0.5402886142177026\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1453794104117636\n",
      "Average test loss:  0.5416539700203254\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.13273194570196198\n",
      "Average test loss:  0.5439692599502036\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.12152242188523694\n",
      "Average test loss:  0.5469923352641252\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.11155939417031313\n",
      "Average test loss:  0.5509228769992933\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.1026748936248572\n",
      "Average test loss:  0.555559611197146\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09472019530301158\n",
      "Average test loss:  0.5606222026370726\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.08758249716186232\n",
      "Average test loss:  0.5661974064416803\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.08115531146854328\n",
      "Average test loss:  0.5722382986303655\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.916875\n",
      "Average test accuracy:  0.6925\n",
      "\n",
      "Average train loss:  0.6924046889276657\n",
      "Average test loss:  0.692885977764683\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.6775\n",
      "Average test accuracy:  0.5575\n",
      "\n",
      "Average train loss:  0.6908881291910388\n",
      "Average test loss:  0.6923648632040376\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.88625\n",
      "Average test accuracy:  0.69125\n",
      "\n",
      "Average train loss:  0.6876006639932943\n",
      "Average test loss:  0.6912275464931845\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.8825\n",
      "Average test accuracy:  0.685\n",
      "\n",
      "Average train loss:  0.6816404154009112\n",
      "Average test loss:  0.6891623845236231\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.89\n",
      "Average test accuracy:  0.69\n",
      "\n",
      "Average train loss:  0.6719819244894915\n",
      "Average test loss:  0.6857896927304016\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.908125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.6572038093692164\n",
      "Average test loss:  0.6805844588005749\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.6358299391705545\n",
      "Average test loss:  0.6730018314821112\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.606554335959384\n",
      "Average test loss:  0.6625045316556387\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.940625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.569170743075241\n",
      "Average test loss:  0.649004658465442\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5255692589843916\n",
      "Average test loss:  0.6332169331313201\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.4789304283829423\n",
      "Average test loss:  0.6163487945496685\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.4322644423384121\n",
      "Average test loss:  0.5997366732844651\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.3877766946131705\n",
      "Average test loss:  0.5841425871521856\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.3468415147548174\n",
      "Average test loss:  0.5705285656595946\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.3100434976207121\n",
      "Average test loss:  0.5589925061544911\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.27737477456001347\n",
      "Average test loss:  0.5495853726765535\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.24857068374411773\n",
      "Average test loss:  0.5421856832637265\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.22325696677051435\n",
      "Average test loss:  0.536762179073408\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.20100948495449975\n",
      "Average test loss:  0.5331783160829424\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1814359837404517\n",
      "Average test loss:  0.5310989844897138\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.16415019743258244\n",
      "Average test loss:  0.5303092178435387\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.14886584300680825\n",
      "Average test loss:  0.5310373401838522\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.13531676250844413\n",
      "Average test loss:  0.5327161826487979\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.12326082219064939\n",
      "Average test loss:  0.5355528702933022\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.11253987801018084\n",
      "Average test loss:  0.5391492123466478\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.10296945526346213\n",
      "Average test loss:  0.5436191167656058\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.09442928004068964\n",
      "Average test loss:  0.5489108319249096\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.086788895339358\n",
      "Average test loss:  0.5548038471880751\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.07993691453435427\n",
      "Average test loss:  0.5612203145464508\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.07377567842875436\n",
      "Average test loss:  0.5680823958925448\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6923522299652065\n",
      "Average test loss:  0.6929335953529759\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.853125\n",
      "Average test accuracy:  0.65875\n",
      "\n",
      "Average train loss:  0.6908792480518442\n",
      "Average test loss:  0.692364597399727\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.90875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.6884168109352539\n",
      "Average test loss:  0.6915118411937256\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.861875\n",
      "Average test accuracy:  0.66\n",
      "\n",
      "Average train loss:  0.6840398216169555\n",
      "Average test loss:  0.6899952842143112\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.835\n",
      "Average test accuracy:  0.65\n",
      "\n",
      "Average train loss:  0.6764077555189111\n",
      "Average test loss:  0.6873516664117654\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.885\n",
      "Average test accuracy:  0.68125\n",
      "\n",
      "Average train loss:  0.6635401909786985\n",
      "Average test loss:  0.6828409834746361\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.90875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.6423634505050989\n",
      "Average test loss:  0.675344902942354\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.6098691835205204\n",
      "Average test loss:  0.663747425822757\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.5653547819219032\n",
      "Average test loss:  0.6477425824414996\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9475\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.5117082513450368\n",
      "Average test loss:  0.6284470082036612\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.4539348562585783\n",
      "Average test loss:  0.6078809840620365\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3974380287585045\n",
      "Average test loss:  0.5882920340454747\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3458231935996907\n",
      "Average test loss:  0.5713126809370576\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.3006142419672271\n",
      "Average test loss:  0.5576209285772478\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.26188304633254456\n",
      "Average test loss:  0.5472193571841989\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.22905130744810234\n",
      "Average test loss:  0.5398095391120646\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.20131073001768787\n",
      "Average test loss:  0.5352773578077292\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.17786747223210211\n",
      "Average test loss:  0.532879874413591\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.15797981286173915\n",
      "Average test loss:  0.5324990863053721\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.14100627237806015\n",
      "Average test loss:  0.5338175954280749\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.1264683937296285\n",
      "Average test loss:  0.5363780629507007\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.11391982659476696\n",
      "Average test loss:  0.5404977054927506\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.1030446275651189\n",
      "Average test loss:  0.5452621376677417\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.09356234814746293\n",
      "Average test loss:  0.551038229789708\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0852488792829122\n",
      "Average test loss:  0.5575662620449839\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07793026059878523\n",
      "Average test loss:  0.5645999142145969\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.07145390553962408\n",
      "Average test loss:  0.5722357146463305\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.06569453026196931\n",
      "Average test loss:  0.5802846217263785\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.060554428706590446\n",
      "Average test loss:  0.5886883562672193\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.055951446352681254\n",
      "Average test loss:  0.5972621052519062\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.528125\n",
      "Average test accuracy:  0.50125\n",
      "\n",
      "Average train loss:  0.6927891109908088\n",
      "Average test loss:  0.6930214311155126\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.619375\n",
      "Average test accuracy:  0.50375\n",
      "\n",
      "Average train loss:  0.6920537257661908\n",
      "Average test loss:  0.6927676328031923\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.88625\n",
      "Average test accuracy:  0.66125\n",
      "\n",
      "Average train loss:  0.6902976763336929\n",
      "Average test loss:  0.692158457235858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.8725\n",
      "Average test accuracy:  0.615\n",
      "\n",
      "Average train loss:  0.6865533363315138\n",
      "Average test loss:  0.6908652986223579\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.901875\n",
      "Average test accuracy:  0.68125\n",
      "\n",
      "Average train loss:  0.6791219687311764\n",
      "Average test loss:  0.6882812414089039\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.92125\n",
      "Average test accuracy:  0.7025\n",
      "\n",
      "Average train loss:  0.6653205828835779\n",
      "Average test loss:  0.6834661556570522\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.70875\n",
      "\n",
      "Average train loss:  0.641535755620378\n",
      "Average test loss:  0.6751548022569099\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.71125\n",
      "\n",
      "Average train loss:  0.6052339174579131\n",
      "Average test loss:  0.6624141703938612\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.5575946183672851\n",
      "Average test loss:  0.6456768739507291\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5017968161227148\n",
      "Average test loss:  0.6259874441631971\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.4433440108035051\n",
      "Average test loss:  0.6058664419769487\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.3868125508989447\n",
      "Average test loss:  0.5871939185056426\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.7575\n",
      "\n",
      "Average train loss:  0.3352531255360736\n",
      "Average test loss:  0.5708495340679928\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.290105335683057\n",
      "Average test loss:  0.5580705036940844\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.251519201995095\n",
      "Average test loss:  0.5487986773851482\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2189432202074939\n",
      "Average test loss:  0.5425103916545986\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.19157856783235025\n",
      "Average test loss:  0.5388573543465355\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.16856497756966984\n",
      "Average test loss:  0.5375007671154864\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1491237570634786\n",
      "Average test loss:  0.5382435440766196\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.9825\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.132654430481851\n",
      "Average test loss:  0.5407500802092707\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.11859854845063582\n",
      "Average test loss:  0.5446074204259396\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.10654167151701778\n",
      "Average test loss:  0.5492807053644196\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09612298406197838\n",
      "Average test loss:  0.5551373918762248\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.08708393016560222\n",
      "Average test loss:  0.5618760310641057\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07919108888386472\n",
      "Average test loss:  0.5691817995057047\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07226317204613715\n",
      "Average test loss:  0.5771264407138476\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.06616497472182305\n",
      "Average test loss:  0.5857297864749248\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06076473515256046\n",
      "Average test loss:  0.5941120191446867\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.05596390405715542\n",
      "Average test loss:  0.6033242907934026\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.05168883697646331\n",
      "Average test loss:  0.6124225430088641\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7308634594537943\n",
      "Average test loss:  0.7313004233078257\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7004767884512991\n",
      "Average test loss:  0.7013527078948606\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6921298022046095\n",
      "Average test loss:  0.6935976882344764\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6896129258894644\n",
      "Average test loss:  0.6919528700678678\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.793125\n",
      "Average test accuracy:  0.59375\n",
      "\n",
      "Average train loss:  0.6873954814951376\n",
      "Average test loss:  0.69109632149636\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.929375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.6838742871612994\n",
      "Average test loss:  0.689864176510392\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6778706095128619\n",
      "Average test loss:  0.6877622371836782\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.6679402638855964\n",
      "Average test loss:  0.6842594236555527\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.6521301121446194\n",
      "Average test loss:  0.678620021870218\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.6279431534952682\n",
      "Average test loss:  0.6698951756540389\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.5927990764998826\n",
      "Average test loss:  0.6571688735373936\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.5459433737751646\n",
      "Average test loss:  0.6400567198776551\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.49015923261121513\n",
      "Average test loss:  0.6198240357580106\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.4307588380917798\n",
      "Average test loss:  0.5987679501058846\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3732460028516498\n",
      "Average test loss:  0.5788869669263783\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.32126972802357173\n",
      "Average test loss:  0.5623883300627109\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.27631025079022026\n",
      "Average test loss:  0.5494794379095903\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2384019842402064\n",
      "Average test loss:  0.540496213188472\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.20677065775640321\n",
      "Average test loss:  0.5346839799002557\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1804367188545942\n",
      "Average test loss:  0.5320050065078581\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.15847859413981868\n",
      "Average test loss:  0.5316853796927771\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1400511358075259\n",
      "Average test loss:  0.5332597417759256\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.12449880855216892\n",
      "Average test loss:  0.536565561579243\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.11128543396356244\n",
      "Average test loss:  0.5410737954721291\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.099987904473213\n",
      "Average test loss:  0.5469786506655973\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.09024975288353554\n",
      "Average test loss:  0.5534103168680917\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.0818152497323013\n",
      "Average test loss:  0.5608185624373913\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07445131635485433\n",
      "Average test loss:  0.5687965919531592\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.06799794303909129\n",
      "Average test loss:  0.5773018457270308\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.06230671655037717\n",
      "Average test loss:  0.5860714943331847\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.92125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.6920682610200773\n",
      "Average test loss:  0.6927677462092086\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.863125\n",
      "Average test accuracy:  0.6225\n",
      "\n",
      "Average train loss:  0.690290641193723\n",
      "Average test loss:  0.6921571115917574\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.92\n",
      "Average test accuracy:  0.70375\n",
      "\n",
      "Average train loss:  0.6868481262554247\n",
      "Average test loss:  0.6909738538428671\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.7125\n",
      "\n",
      "Average train loss:  0.6804716084097291\n",
      "Average test loss:  0.688777347382663\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.931875\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.6693670145897036\n",
      "Average test loss:  0.6849517634497633\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.6510856679517119\n",
      "Average test loss:  0.6786176649673074\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.622973687707681\n",
      "Average test loss:  0.6687707736172404\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.5834548210887268\n",
      "Average test loss:  0.6548996446157788\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5334403220611893\n",
      "Average test loss:  0.637370887419185\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.47606689812071773\n",
      "Average test loss:  0.6173220602328672\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.41635865226252555\n",
      "Average test loss:  0.596966692906388\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.958125\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3592571982294445\n",
      "Average test loss:  0.578588744555339\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3079966569414639\n",
      "Average test loss:  0.5630107817998217\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.2637413010957936\n",
      "Average test loss:  0.5513403413916558\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.22651893773922094\n",
      "Average test loss:  0.5434110109398956\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.19559255237153253\n",
      "Average test loss:  0.5386576638611799\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.16992328110439295\n",
      "Average test loss:  0.5368757636208253\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.14859731984306757\n",
      "Average test loss:  0.5374141594019574\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.13078193821206563\n",
      "Average test loss:  0.5395142673246439\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.11580461563654026\n",
      "Average test loss:  0.5438905530511633\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10312244157713184\n",
      "Average test loss:  0.5489828487198446\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.09230279492593153\n",
      "Average test loss:  0.5554084946687071\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08301473269534451\n",
      "Average test loss:  0.5630075457815394\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07499868216442145\n",
      "Average test loss:  0.5708817249141419\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.06802550448277865\n",
      "Average test loss:  0.5796478431721713\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.06194403980670352\n",
      "Average test loss:  0.5890110909616514\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.05659597834221159\n",
      "Average test loss:  0.5986292805133989\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.05187737106761825\n",
      "Average test loss:  0.6083719030562347\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.04769687718210344\n",
      "Average test loss:  0.6186801146704295\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.04397439999605429\n",
      "Average test loss:  0.6292389888122791\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6926604754171723\n",
      "Average test loss:  0.6930500985475887\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.805\n",
      "Average test accuracy:  0.64\n",
      "\n",
      "Average train loss:  0.691398396535393\n",
      "Average test loss:  0.6925428707866099\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.93375\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.6884324193758719\n",
      "Average test loss:  0.6915152029127564\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6819241598312842\n",
      "Average test loss:  0.6892529216046831\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6699078793581292\n",
      "Average test loss:  0.6850640109287509\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.6494854530555093\n",
      "Average test loss:  0.677937497839801\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.616908155488254\n",
      "Average test loss:  0.6665098573316502\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.5701121975319285\n",
      "Average test loss:  0.6500019724251566\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5106885587795854\n",
      "Average test loss:  0.629282392250326\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.44441274426948096\n",
      "Average test loss:  0.6067239249951492\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.3788468872661957\n",
      "Average test loss:  0.5851280030341992\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.31975782903878686\n",
      "Average test loss:  0.5670697075201794\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.2696196728528657\n",
      "Average test loss:  0.5541152738119006\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.22836417648171872\n",
      "Average test loss:  0.5454035079776741\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1948343166971629\n",
      "Average test loss:  0.5403376064117865\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.16758698293817845\n",
      "Average test loss:  0.5388790997379416\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1453641547392817\n",
      "Average test loss:  0.539954872171937\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.12706604607393268\n",
      "Average test loss:  0.5433368197585813\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1118774455815875\n",
      "Average test loss:  0.5484492070079358\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.09915862804107252\n",
      "Average test loss:  0.5544310881865466\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08841082044022018\n",
      "Average test loss:  0.5619386652171304\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.07926652209864658\n",
      "Average test loss:  0.5704922669000628\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.0714079434268625\n",
      "Average test loss:  0.5792739079441823\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.06461941007552462\n",
      "Average test loss:  0.5887871041905028\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.058717931883099074\n",
      "Average test loss:  0.599298399086748\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.053554646002374695\n",
      "Average test loss:  0.6093349261434214\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04902174013497748\n",
      "Average test loss:  0.6204662839957167\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.045016524845078516\n",
      "Average test loss:  0.6312288850052304\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.041458721988131275\n",
      "Average test loss:  0.6423977239420698\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.038286989988193965\n",
      "Average test loss:  0.6537930399906527\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7004326236095583\n",
      "Average test loss:  0.7007251271443365\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6924834247542414\n",
      "Average test loss:  0.6931272734253925\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.55\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6912258896908718\n",
      "Average test loss:  0.6924911577649047\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.89625\n",
      "Average test accuracy:  0.62375\n",
      "\n",
      "Average train loss:  0.6893419124578264\n",
      "Average test loss:  0.6918295895396932\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.916875\n",
      "Average test accuracy:  0.695\n",
      "\n",
      "Average train loss:  0.6857123471928926\n",
      "Average test loss:  0.6905592735137969\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.923125\n",
      "Average test accuracy:  0.70625\n",
      "\n",
      "Average train loss:  0.6791213856701805\n",
      "Average test loss:  0.6882486910349046\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.916875\n",
      "Average test accuracy:  0.7\n",
      "\n",
      "Average train loss:  0.6677723873914657\n",
      "Average test loss:  0.6842791413385715\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.70875\n",
      "\n",
      "Average train loss:  0.6488452982610827\n",
      "Average test loss:  0.677605792224274\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.6181585400891328\n",
      "Average test loss:  0.6666805749186406\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.571595031619014\n",
      "Average test loss:  0.650239300158613\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.5091548951099346\n",
      "Average test loss:  0.628183590242444\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.4379252649345699\n",
      "Average test loss:  0.603700484818559\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.3680883611453148\n",
      "Average test loss:  0.5807915801910427\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.30661924808187385\n",
      "Average test loss:  0.56270334478826\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.25589333166723915\n",
      "Average test loss:  0.5495909507483407\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.21522830484591912\n",
      "Average test loss:  0.5420937031201573\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.18283614731237155\n",
      "Average test loss:  0.5384469428012172\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.15691443529679028\n",
      "Average test loss:  0.5384537347787198\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.13595970148548528\n",
      "Average test loss:  0.5409296729862423\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.11886595709818236\n",
      "Average test loss:  0.5457547488710869\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1047373062087899\n",
      "Average test loss:  0.5517158899020932\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.09294473481647121\n",
      "Average test loss:  0.5590081153152253\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08300894003400423\n",
      "Average test loss:  0.5670219666735128\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07455489808968048\n",
      "Average test loss:  0.5763599814868406\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06729400106893298\n",
      "Average test loss:  0.5860394422782226\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.06103374423025007\n",
      "Average test loss:  0.5959858074417519\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.0555841605723589\n",
      "Average test loss:  0.6066338246799884\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.05081798093285642\n",
      "Average test loss:  0.6175368111096746\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.04663507796116767\n",
      "Average test loss:  0.628483034222994\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.042937737598607\n",
      "Average test loss:  0.6395075857175109\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7059416207266623\n",
      "Average test loss:  0.7067622210128094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6948718065692082\n",
      "Average test loss:  0.6966000699192271\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6897345389688004\n",
      "Average test loss:  0.6926266820242963\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6862713292361197\n",
      "Average test loss:  0.6908443460955268\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.7025\n",
      "Average test accuracy:  0.5575\n",
      "\n",
      "Average train loss:  0.6821753038271986\n",
      "Average test loss:  0.6893092430088551\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.890625\n",
      "Average test accuracy:  0.69\n",
      "\n",
      "Average train loss:  0.6760642401505977\n",
      "Average test loss:  0.6871525665147687\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.918125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.6666811854438954\n",
      "Average test loss:  0.6838595007251179\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.9325\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.652643021806371\n",
      "Average test loss:  0.6788728874203148\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.6326908024839981\n",
      "Average test loss:  0.6716925224605544\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.945625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6062812900030862\n",
      "Average test loss:  0.6620463997769053\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5739925648451765\n",
      "Average test loss:  0.6501291275532424\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.5375150295041659\n",
      "Average test loss:  0.6365764537422842\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.955\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.49899848751377857\n",
      "Average test loss:  0.6222391631949911\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.4604642993626513\n",
      "Average test loss:  0.6080931551565221\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.4233865681016713\n",
      "Average test loss:  0.5946402246107672\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.966875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.38868356006213395\n",
      "Average test loss:  0.5823106517449058\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.356752735287931\n",
      "Average test loss:  0.5714140975797617\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.32770517958333506\n",
      "Average test loss:  0.5620462317899885\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3014114251537196\n",
      "Average test loss:  0.5541238592752205\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.27768300341384106\n",
      "Average test loss:  0.5474866348097615\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.2562984356948505\n",
      "Average test loss:  0.5421943100026487\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.23701847425219535\n",
      "Average test loss:  0.5381096645850728\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.9825\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.21961983761687023\n",
      "Average test loss:  0.5351388939860837\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.20390355753697306\n",
      "Average test loss:  0.5331203108399595\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.18967089404696488\n",
      "Average test loss:  0.5320063261674451\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.17675332759158344\n",
      "Average test loss:  0.5316028196800028\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.16500499768005947\n",
      "Average test loss:  0.5320013339851847\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.15429868698958593\n",
      "Average test loss:  0.5331338775579202\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.14451435815057517\n",
      "Average test loss:  0.5347604942754319\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.13556137777864072\n",
      "Average test loss:  0.5369161382896946\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7546487018803093\n",
      "Average test loss:  0.7549807926604489\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7256978283039343\n",
      "Average test loss:  0.7260915157412354\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7083654003844663\n",
      "Average test loss:  0.7087197826715218\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6989265065180247\n",
      "Average test loss:  0.6993828703187326\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6939703743647416\n",
      "Average test loss:  0.6949406922349572\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6905063276376624\n",
      "Average test loss:  0.6926878152178526\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6863260805326997\n",
      "Average test loss:  0.6908580852158382\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.903125\n",
      "Average test accuracy:  0.65625\n",
      "\n",
      "Average train loss:  0.6797081837247981\n",
      "Average test loss:  0.6883736046117007\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.6691701147644021\n",
      "Average test loss:  0.6845348233977688\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.6532362557512424\n",
      "Average test loss:  0.6787212307141867\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.929375\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.6306928721247543\n",
      "Average test loss:  0.6704203747600186\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.940625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.6009573473347629\n",
      "Average test loss:  0.6593043676407261\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.56473882154102\n",
      "Average test loss:  0.6455687963223654\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.955\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5238501482498841\n",
      "Average test loss:  0.6299422552611587\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.48072168335103244\n",
      "Average test loss:  0.6134788892985056\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.43767936954603676\n",
      "Average test loss:  0.5972639876942311\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3965256651028252\n",
      "Average test loss:  0.582130974392903\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.35834919262630077\n",
      "Average test loss:  0.5687328588045442\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.32366343610015086\n",
      "Average test loss:  0.5572871636219335\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.29258584920501934\n",
      "Average test loss:  0.547957488490717\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2649519762676227\n",
      "Average test loss:  0.5405250510494807\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.240476157317651\n",
      "Average test loss:  0.5350175469185618\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.21883041056611263\n",
      "Average test loss:  0.5311456215756571\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.19966273973812454\n",
      "Average test loss:  0.5287816206529214\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.18269473517248033\n",
      "Average test loss:  0.5277206826292784\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.16761560889698654\n",
      "Average test loss:  0.5278195648403142\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.15419947813744847\n",
      "Average test loss:  0.5290315840197093\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.1422227515330874\n",
      "Average test loss:  0.5310154756172465\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.131498911855338\n",
      "Average test loss:  0.5338264900355397\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.12185719921710614\n",
      "Average test loss:  0.5373078104216306\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7048522839283166\n",
      "Average test loss:  0.7050999175389924\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6952865832974543\n",
      "Average test loss:  0.6956541995155052\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6924135165947337\n",
      "Average test loss:  0.6931441629087893\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6909438485863536\n",
      "Average test loss:  0.6923871213132644\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.918125\n",
      "Average test accuracy:  0.70875\n",
      "\n",
      "Average train loss:  0.6891285520789493\n",
      "Average test loss:  0.6917393853977077\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.784375\n",
      "Average test accuracy:  0.5625\n",
      "\n",
      "Average train loss:  0.6861772631136618\n",
      "Average test loss:  0.6907288180003593\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.81625\n",
      "Average test accuracy:  0.5775\n",
      "\n",
      "Average train loss:  0.681115488749325\n",
      "Average test loss:  0.6889844917785687\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.88\n",
      "Average test accuracy:  0.63\n",
      "\n",
      "Average train loss:  0.6719669454619561\n",
      "Average test loss:  0.6858040264030124\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.90625\n",
      "Average test accuracy:  0.68875\n",
      "\n",
      "Average train loss:  0.6552501559427486\n",
      "Average test loss:  0.6799411977207535\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.6262342105661133\n",
      "Average test loss:  0.669566762679306\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.94375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.5817987607850582\n",
      "Average test loss:  0.6535313160012826\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5250152429016534\n",
      "Average test loss:  0.632891254022247\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.955\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.4636380415384636\n",
      "Average test loss:  0.6107794921104938\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.4045693468806844\n",
      "Average test loss:  0.5899547040123388\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3516592391221755\n",
      "Average test loss:  0.5721629410187689\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3060734564397008\n",
      "Average test loss:  0.5581603555474728\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.26749145127355417\n",
      "Average test loss:  0.5477033980624674\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.23501062712580922\n",
      "Average test loss:  0.5401963706936904\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.2076430811665665\n",
      "Average test loss:  0.5355825635572837\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.18450809711552574\n",
      "Average test loss:  0.5332405788739364\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.16482188220875402\n",
      "Average test loss:  0.5329258321200232\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.14798022657229393\n",
      "Average test loss:  0.5339117682100475\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.13347753574893176\n",
      "Average test loss:  0.5365644079174089\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.12089888593382236\n",
      "Average test loss:  0.5401385786622828\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.1099271009291382\n",
      "Average test loss:  0.544675011039204\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.10031000178346143\n",
      "Average test loss:  0.5502036955785187\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0918401690792197\n",
      "Average test loss:  0.5562207281428084\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.08434138350082408\n",
      "Average test loss:  0.5629819372890857\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0776777591107889\n",
      "Average test loss:  0.5699959642290054\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07173030009937237\n",
      "Average test loss:  0.5775898371250622\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7118447194401526\n",
      "Average test loss:  0.7126390159810759\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6936837847065207\n",
      "Average test loss:  0.6958939886383738\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.687096368174693\n",
      "Average test loss:  0.6912238037416786\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.925625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.682799461710656\n",
      "Average test loss:  0.689461163062214\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.8875\n",
      "Average test accuracy:  0.6875\n",
      "\n",
      "Average train loss:  0.6775147327010308\n",
      "Average test loss:  0.6876682421610024\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.885\n",
      "Average test accuracy:  0.665\n",
      "\n",
      "Average train loss:  0.6698813981136066\n",
      "Average test loss:  0.6850808620636538\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.903125\n",
      "Average test accuracy:  0.6925\n",
      "\n",
      "Average train loss:  0.6586110599287012\n",
      "Average test loss:  0.6811980980801161\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.921875\n",
      "Average test accuracy:  0.70375\n",
      "\n",
      "Average train loss:  0.6419613370867826\n",
      "Average test loss:  0.6754240827670092\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9325\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.6181069636283115\n",
      "Average test loss:  0.667035535074756\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.940625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.5856029815955036\n",
      "Average test loss:  0.6554318426314815\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.5445114455398716\n",
      "Average test loss:  0.6407466203770573\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.4969366490064326\n",
      "Average test loss:  0.6236818581974036\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.4463006090668407\n",
      "Average test loss:  0.6056392325671026\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.39615498649572906\n",
      "Average test loss:  0.588234385675552\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.3492310099392793\n",
      "Average test loss:  0.5725793771020009\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3070074081943446\n",
      "Average test loss:  0.5594888903576835\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.26998443808514666\n",
      "Average test loss:  0.5490982314034647\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.23795500227039276\n",
      "Average test loss:  0.5414667305852392\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.21045632128906752\n",
      "Average test loss:  0.5364335260728347\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.18692007471712177\n",
      "Average test loss:  0.5333368825297201\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.166712929166459\n",
      "Average test loss:  0.5322786144008594\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.14934334751389242\n",
      "Average test loss:  0.5329122473228779\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.13432859533974809\n",
      "Average test loss:  0.5348788363122222\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.12131010618519233\n",
      "Average test loss:  0.5380336880469923\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.10996198793045747\n",
      "Average test loss:  0.5421080944046484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.1000198908481143\n",
      "Average test loss:  0.547143307249927\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.09128138326125251\n",
      "Average test loss:  0.5529578572978372\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.08355507542766875\n",
      "Average test loss:  0.5593248229308583\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.07670368376658376\n",
      "Average test loss:  0.5662704948455999\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07060132272645599\n",
      "Average test loss:  0.5736804481371368\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7048233482501418\n",
      "Average test loss:  0.7051214753969552\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6927001112203265\n",
      "Average test loss:  0.6938448009321797\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.509375\n",
      "Average test accuracy:  0.5025\n",
      "\n",
      "Average train loss:  0.6892893426890256\n",
      "Average test loss:  0.6917947425030242\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.82625\n",
      "Average test accuracy:  0.5975\n",
      "\n",
      "Average train loss:  0.6861299127897212\n",
      "Average test loss:  0.6906955743647885\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.855\n",
      "Average test accuracy:  0.62\n",
      "\n",
      "Average train loss:  0.6812380559476926\n",
      "Average test loss:  0.6890195386754462\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.8775\n",
      "Average test accuracy:  0.6375\n",
      "\n",
      "Average train loss:  0.6735407858508412\n",
      "Average test loss:  0.6863796371963028\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.89875\n",
      "Average test accuracy:  0.675\n",
      "\n",
      "Average train loss:  0.6614422220171039\n",
      "Average test loss:  0.6821886239375289\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.9125\n",
      "Average test accuracy:  0.69375\n",
      "\n",
      "Average train loss:  0.6424352439455752\n",
      "Average test loss:  0.6756013717646675\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.931875\n",
      "Average test accuracy:  0.71375\n",
      "\n",
      "Average train loss:  0.6137710488584808\n",
      "Average test loss:  0.6654634007044805\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.5736534591543191\n",
      "Average test loss:  0.6513103342766097\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5232618597968869\n",
      "Average test loss:  0.6333920844173666\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.4668559257223924\n",
      "Average test loss:  0.6134765996729451\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.40961980551940463\n",
      "Average test loss:  0.5937298751252953\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.3559063659973308\n",
      "Average test loss:  0.5759755396382887\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3081289907200581\n",
      "Average test loss:  0.5615857123028523\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2669538577562551\n",
      "Average test loss:  0.5501638776905754\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.23207061732011647\n",
      "Average test loss:  0.5423981975778234\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2027792791298317\n",
      "Average test loss:  0.537598918902645\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.17814492264550388\n",
      "Average test loss:  0.5351616414762668\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.15737025625119483\n",
      "Average test loss:  0.5350435001466579\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.1397845560563491\n",
      "Average test loss:  0.5366316591477815\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.12481269265120909\n",
      "Average test loss:  0.5398074849302914\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.111987988593242\n",
      "Average test loss:  0.5442958960807897\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.1009306114710305\n",
      "Average test loss:  0.5493928193220932\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.09133791383481338\n",
      "Average test loss:  0.5557049859458875\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.08297849956727706\n",
      "Average test loss:  0.5626380289548771\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07564227244984088\n",
      "Average test loss:  0.5702555724954267\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.06918801815863362\n",
      "Average test loss:  0.5782562024104229\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06346984133912315\n",
      "Average test loss:  0.5867817843630284\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.058395231466275066\n",
      "Average test loss:  0.5956062758828683\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6927279093935952\n",
      "Average test loss:  0.693013099838625\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.581875\n",
      "Average test accuracy:  0.5025\n",
      "\n",
      "Average train loss:  0.6918444331355359\n",
      "Average test loss:  0.6927037712801587\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.635625\n",
      "Average test accuracy:  0.505\n",
      "\n",
      "Average train loss:  0.6895952690198136\n",
      "Average test loss:  0.691936341987449\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.7475\n",
      "Average test accuracy:  0.52875\n",
      "\n",
      "Average train loss:  0.6846042986226633\n",
      "Average test loss:  0.6902383105660173\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.913125\n",
      "Average test accuracy:  0.6975\n",
      "\n",
      "Average train loss:  0.6750418239510919\n",
      "Average test loss:  0.6869046243634968\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9325\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.6583151125099214\n",
      "Average test loss:  0.6810743131595093\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.6307992216029333\n",
      "Average test loss:  0.6714321869468503\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5895928279779388\n",
      "Average test loss:  0.6568546076055775\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.945625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.5350664764494305\n",
      "Average test loss:  0.6375707153226823\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.47120036226990963\n",
      "Average test loss:  0.6154314697047477\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.4057001437626218\n",
      "Average test loss:  0.5930082236387798\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3453398799218697\n",
      "Average test loss:  0.5736400733378036\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.2933140399765714\n",
      "Average test loss:  0.5587133259310312\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.24999439146307437\n",
      "Average test loss:  0.5475832415645278\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.21438079624312678\n",
      "Average test loss:  0.5406413127480119\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.18519934065441448\n",
      "Average test loss:  0.5371116932748378\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.16118487429945508\n",
      "Average test loss:  0.5361452648593507\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.14128841497677\n",
      "Average test loss:  0.5375585698780961\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.12468803858541173\n",
      "Average test loss:  0.5406233276630604\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.11070824404258235\n",
      "Average test loss:  0.545204988178444\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.09886543674772859\n",
      "Average test loss:  0.5512127784032489\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.08874037332120673\n",
      "Average test loss:  0.5581298299208627\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.08002743624630047\n",
      "Average test loss:  0.565894845708613\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.07248304614377199\n",
      "Average test loss:  0.5741574504410273\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.06589987257541295\n",
      "Average test loss:  0.5828200080054761\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.06013892428464817\n",
      "Average test loss:  0.5922448196791545\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.055065784256751925\n",
      "Average test loss:  0.6020649045984033\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.05057440277808619\n",
      "Average test loss:  0.6119294094412715\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.715\n",
      "\n",
      "Average train loss:  0.04658669138136939\n",
      "Average test loss:  0.6219371825812977\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.043039444113135206\n",
      "Average test loss:  0.6323193791346992\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7421089726476987\n",
      "Average test loss:  0.7423534344472783\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7042392944456649\n",
      "Average test loss:  0.7047066082866377\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6933888115641756\n",
      "Average test loss:  0.6943835114663169\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6903865027732222\n",
      "Average test loss:  0.6922967636001642\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.705\n",
      "\n",
      "Average train loss:  0.6879748141464086\n",
      "Average test loss:  0.691339633774728\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.92125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.68427932372584\n",
      "Average test loss:  0.6900248321510087\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.91\n",
      "Average test accuracy:  0.71375\n",
      "\n",
      "Average train loss:  0.6780585634199667\n",
      "Average test loss:  0.6878074953431587\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.6675700727703214\n",
      "Average test loss:  0.6840500319579674\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.940625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.6502244406432284\n",
      "Average test loss:  0.6777984461646757\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6225761497856718\n",
      "Average test loss:  0.6677688117317947\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.5812579938385051\n",
      "Average test loss:  0.652732369478391\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.525509467639646\n",
      "Average test loss:  0.6324730858233547\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.958125\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.45949892430299893\n",
      "Average test loss:  0.6089877517542533\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3913858819677733\n",
      "Average test loss:  0.585349275288742\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.32864986771798016\n",
      "Average test loss:  0.5653645615700597\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.27526478618630784\n",
      "Average test loss:  0.5502031202101914\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2316370852301867\n",
      "Average test loss:  0.5403262635607691\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.19655053628603547\n",
      "Average test loss:  0.535116423868378\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.16834150998661898\n",
      "Average test loss:  0.533432458567136\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.14555430391750387\n",
      "Average test loss:  0.5345850338680985\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.12695858913210653\n",
      "Average test loss:  0.5381598522964833\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.11162844040050812\n",
      "Average test loss:  0.543366535740194\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.09886831771904592\n",
      "Average test loss:  0.5500106058979243\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.08813269576958994\n",
      "Average test loss:  0.5576921572392435\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.07902609531516579\n",
      "Average test loss:  0.5663185077729861\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.07122743123060866\n",
      "Average test loss:  0.5754675111226754\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.06449241637152757\n",
      "Average test loss:  0.5853361179473259\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.058648187298241096\n",
      "Average test loss:  0.5956262232701747\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.053538220006173254\n",
      "Average test loss:  0.6061951833833961\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.049057522544869205\n",
      "Average test loss:  0.6171052764415742\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6933356956486962\n",
      "Average test loss:  0.6940943997252162\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.930625\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.6901009295590083\n",
      "Average test loss:  0.6921040752449246\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.765625\n",
      "Average test accuracy:  0.5975\n",
      "\n",
      "Average train loss:  0.6871762049223987\n",
      "Average test loss:  0.6910923011010706\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.7975\n",
      "Average test accuracy:  0.62125\n",
      "\n",
      "Average train loss:  0.6820334551000057\n",
      "Average test loss:  0.6893083560171821\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.885625\n",
      "Average test accuracy:  0.68375\n",
      "\n",
      "Average train loss:  0.6728951891215523\n",
      "Average test loss:  0.6861003598159585\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9325\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.6568720051444732\n",
      "Average test loss:  0.6804297117915343\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6298683229900356\n",
      "Average test loss:  0.6708282472439867\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5877005164302809\n",
      "Average test loss:  0.6558011239215741\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.5299730148089593\n",
      "Average test loss:  0.6354172386420913\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.46253661651697303\n",
      "Average test loss:  0.6120484752658345\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3943608550220043\n",
      "Average test loss:  0.5892354123354872\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3324258765722556\n",
      "Average test loss:  0.5701832833406105\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.27968848560405263\n",
      "Average test loss:  0.5556599376389284\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.23630973258650134\n",
      "Average test loss:  0.5462484240935964\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.20108986168972323\n",
      "Average test loss:  0.5408991983659456\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1725558372609167\n",
      "Average test loss:  0.5389261970967208\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.14931229195100945\n",
      "Average test loss:  0.5396596744423986\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.13023282106385323\n",
      "Average test loss:  0.5426515949027596\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.11442551831996615\n",
      "Average test loss:  0.5476060348708335\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.10122385007587892\n",
      "Average test loss:  0.5540662609298747\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.0900929447472079\n",
      "Average test loss:  0.5615831614314537\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.0806361929505247\n",
      "Average test loss:  0.5698658871069494\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.07254332604784079\n",
      "Average test loss:  0.5787889684333627\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.0655597027108669\n",
      "Average test loss:  0.5884302610323818\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.05951266508547771\n",
      "Average test loss:  0.5988087526522187\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.054228298738855076\n",
      "Average test loss:  0.6094236278770025\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.049597452971920135\n",
      "Average test loss:  0.620134474799993\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.04551227971858976\n",
      "Average test loss:  0.6309597592524053\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.04189881301483491\n",
      "Average test loss:  0.642403289990518\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.03867494100917498\n",
      "Average test loss:  0.6536036737937319\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6953256195010815\n",
      "Average test loss:  0.6954445478765431\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6922373640105253\n",
      "Average test loss:  0.6928372605452536\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6907656998769548\n",
      "Average test loss:  0.6923330810803386\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.515625\n",
      "Average test accuracy:  0.50375\n",
      "\n",
      "Average train loss:  0.6876184999144792\n",
      "Average test loss:  0.6912520774900646\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.669375\n",
      "Average test accuracy:  0.55\n",
      "\n",
      "Average train loss:  0.6811267789241011\n",
      "Average test loss:  0.6889846664330231\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.76875\n",
      "Average test accuracy:  0.58875\n",
      "\n",
      "Average train loss:  0.6685238011470428\n",
      "Average test loss:  0.6845862234361425\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.856875\n",
      "Average test accuracy:  0.6525\n",
      "\n",
      "Average train loss:  0.6452984985616839\n",
      "Average test loss:  0.6763623285951185\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.908125\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.6061327049506745\n",
      "Average test loss:  0.6622276366768335\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.5486046565242519\n",
      "Average test loss:  0.6413786596997569\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.4778923226486947\n",
      "Average test loss:  0.6158977414738219\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.40461637751549673\n",
      "Average test loss:  0.5901878802807852\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.33752392115572744\n",
      "Average test loss:  0.5682408114209966\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.2808455483058947\n",
      "Average test loss:  0.5519596052310468\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.2348979423383136\n",
      "Average test loss:  0.5409586565442339\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.1982370767555098\n",
      "Average test loss:  0.5351601974855414\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.1689699821956617\n",
      "Average test loss:  0.5332003824017325\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.14540108038112662\n",
      "Average test loss:  0.5344461057031464\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.12624514154647934\n",
      "Average test loss:  0.5379910064917505\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.11052383371769968\n",
      "Average test loss:  0.5433996783835419\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.09747662207691782\n",
      "Average test loss:  0.5505374304762989\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.08654932741571512\n",
      "Average test loss:  0.5584751781615744\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07730871499137149\n",
      "Average test loss:  0.5674909237735201\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06942126458989147\n",
      "Average test loss:  0.5772120457816173\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06265204315771637\n",
      "Average test loss:  0.5874907970378729\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.056785822778958224\n",
      "Average test loss:  0.5983714759528688\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.05166578510387685\n",
      "Average test loss:  0.6095385735641042\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.047176027326324525\n",
      "Average test loss:  0.6210518417494001\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04321977747847481\n",
      "Average test loss:  0.632676495980086\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.039715540262954326\n",
      "Average test loss:  0.6444939848401904\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.036595592893781975\n",
      "Average test loss:  0.6564499557399214\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6927625384238895\n",
      "Average test loss:  0.693011240875006\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.6916429904972482\n",
      "Average test loss:  0.6926231034372861\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.75375\n",
      "Average test accuracy:  0.5425\n",
      "\n",
      "Average train loss:  0.6883228642160658\n",
      "Average test loss:  0.6914827599285295\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.936875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6797527717960898\n",
      "Average test loss:  0.6884910803926246\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6586611777867346\n",
      "Average test loss:  0.6811293747489692\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6135319561566179\n",
      "Average test loss:  0.6652172238966142\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9475\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5390578713789519\n",
      "Average test loss:  0.638872616574001\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.44881021002375254\n",
      "Average test loss:  0.6073499194087454\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.3631030108886118\n",
      "Average test loss:  0.5787175735152607\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2925371220488843\n",
      "Average test loss:  0.5579299473868168\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.966875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.23783582015296947\n",
      "Average test loss:  0.5442640023746654\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.19612017863349399\n",
      "Average test loss:  0.537110171755535\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.16404889182798507\n",
      "Average test loss:  0.5353229585570057\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13900812994973186\n",
      "Average test loss:  0.5371856656480521\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.11915532058493515\n",
      "Average test loss:  0.5414300122390254\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10319225948690407\n",
      "Average test loss:  0.5478401570130339\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.09014995644906527\n",
      "Average test loss:  0.5564439170509675\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07939037633059925\n",
      "Average test loss:  0.5657476090647094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07038069701617992\n",
      "Average test loss:  0.575739758379913\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.06278063617714645\n",
      "Average test loss:  0.5870501188297638\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.0563148866785202\n",
      "Average test loss:  0.5989403500633207\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.05076260162638386\n",
      "Average test loss:  0.6109454015526025\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.04594846303772207\n",
      "Average test loss:  0.6232761955888512\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.04176494493987876\n",
      "Average test loss:  0.6363218047776331\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.038106310062299364\n",
      "Average test loss:  0.6489145614761705\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.034882264197836806\n",
      "Average test loss:  0.6618393443598994\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.03203998397583138\n",
      "Average test loss:  0.6753626275892666\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.029511292823417395\n",
      "Average test loss:  0.6879413472947213\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.027264488901887443\n",
      "Average test loss:  0.701060244864178\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.025253336057409693\n",
      "Average test loss:  0.7144291626792453\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6925653770382866\n",
      "Average test loss:  0.6932899113361146\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.690594495509511\n",
      "Average test loss:  0.6922931198569433\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.86\n",
      "Average test accuracy:  0.66625\n",
      "\n",
      "Average train loss:  0.6880330016204891\n",
      "Average test loss:  0.6913860461004037\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.921875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.683258135266759\n",
      "Average test loss:  0.6897441687214222\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6743400668509315\n",
      "Average test loss:  0.686668047578411\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6587062351473616\n",
      "Average test loss:  0.6812060035915949\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.94125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6341744379298542\n",
      "Average test loss:  0.6724748896197212\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6009470133179732\n",
      "Average test loss:  0.6604675953251192\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.5614430724033113\n",
      "Average test loss:  0.6459533891578725\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5192206499125697\n",
      "Average test loss:  0.6303595340412017\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.47708902318303464\n",
      "Average test loss:  0.6147225746160219\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.43694994800542974\n",
      "Average test loss:  0.6000094948189288\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.3997546071175244\n",
      "Average test loss:  0.5866741993121274\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.36589232602440597\n",
      "Average test loss:  0.5747849128664555\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3353286281035229\n",
      "Average test loss:  0.564658356843141\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3078653944505561\n",
      "Average test loss:  0.5561411510328546\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2832286779396593\n",
      "Average test loss:  0.5491487282961989\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2611303991948229\n",
      "Average test loss:  0.5434193951642681\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.24129222599004327\n",
      "Average test loss:  0.5391017586770185\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.22344349937957864\n",
      "Average test loss:  0.5359159903650499\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.2073652481940955\n",
      "Average test loss:  0.5338134998935871\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.19284308943961082\n",
      "Average test loss:  0.5327104171218443\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.1796897571020777\n",
      "Average test loss:  0.5323830269560448\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.16774706950509097\n",
      "Average test loss:  0.5328300953180888\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.15688073155860224\n",
      "Average test loss:  0.5339985169500076\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.1469762283709648\n",
      "Average test loss:  0.5359124071902805\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.13792065198937853\n",
      "Average test loss:  0.5381434843384079\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.1296394460131087\n",
      "Average test loss:  0.5410365294756371\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.12203716063238217\n",
      "Average test loss:  0.5442651557983599\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.11504605989118159\n",
      "Average test loss:  0.547974781531135\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6934818673925632\n",
      "Average test loss:  0.6943132778601209\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6902807382213266\n",
      "Average test loss:  0.6922139835647011\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.870625\n",
      "Average test accuracy:  0.68125\n",
      "\n",
      "Average train loss:  0.6873471824582581\n",
      "Average test loss:  0.691121043540206\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.68200332300844\n",
      "Average test loss:  0.6892607651597616\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6715981353890289\n",
      "Average test loss:  0.6856256300956746\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6524444278389545\n",
      "Average test loss:  0.6788732042429461\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.94375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.621239358357039\n",
      "Average test loss:  0.6677560052301659\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5778435857819146\n",
      "Average test loss:  0.6521123572633419\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.52637161135893\n",
      "Average test loss:  0.6333405231299158\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.4724978515369878\n",
      "Average test loss:  0.6137117261734453\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.4207783862725086\n",
      "Average test loss:  0.5951111923122765\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.3735737368673062\n",
      "Average test loss:  0.5787327603392951\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.33176369707760284\n",
      "Average test loss:  0.564881144799673\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.295282370118879\n",
      "Average test loss:  0.5538969543407365\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2636378757882975\n",
      "Average test loss:  0.5452311019582897\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.23625599984682658\n",
      "Average test loss:  0.5388847531879326\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.21251712301740602\n",
      "Average test loss:  0.5347253987671348\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.19188976619557288\n",
      "Average test loss:  0.5322927645020578\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.17389093955748672\n",
      "Average test loss:  0.531399999220029\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.15813582182336716\n",
      "Average test loss:  0.5318985582826606\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.14429057937850795\n",
      "Average test loss:  0.5337624021648518\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.1320756709418712\n",
      "Average test loss:  0.5363665844903549\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.12124282259734864\n",
      "Average test loss:  0.5400090610993779\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.11161422587954102\n",
      "Average test loss:  0.544130904143449\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.1030117123134019\n",
      "Average test loss:  0.5491466441023404\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.09531637234712555\n",
      "Average test loss:  0.5546595515392151\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.08839448294988968\n",
      "Average test loss:  0.5607693929875109\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.08215784570053612\n",
      "Average test loss:  0.5671515125455979\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07651988134741299\n",
      "Average test loss:  0.5740048468324924\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07139842966028777\n",
      "Average test loss:  0.5811394019265815\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6993966126643513\n",
      "Average test loss:  0.7001909841315115\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6919225530714955\n",
      "Average test loss:  0.6935332929783788\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6891041058455677\n",
      "Average test loss:  0.6918591989396136\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.851875\n",
      "Average test accuracy:  0.56125\n",
      "\n",
      "Average train loss:  0.6860607175508021\n",
      "Average test loss:  0.6907243352563359\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.919375\n",
      "Average test accuracy:  0.69\n",
      "\n",
      "Average train loss:  0.6808417460012565\n",
      "Average test loss:  0.6888978299661238\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.7125\n",
      "\n",
      "Average train loss:  0.6714299172615839\n",
      "Average test loss:  0.685601846917613\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.936875\n",
      "Average test accuracy:  0.71125\n",
      "\n",
      "Average train loss:  0.6544093198342583\n",
      "Average test loss:  0.6796181958952915\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.94125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.6247262933026718\n",
      "Average test loss:  0.669112085770511\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.5783985343163544\n",
      "Average test loss:  0.6525852310650553\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.5180896480521177\n",
      "Average test loss:  0.6309862583136795\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.4530169904047973\n",
      "Average test loss:  0.6078017154204213\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.3913890868352327\n",
      "Average test loss:  0.5864100762158789\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3372820584635397\n",
      "Average test loss:  0.5687386997405066\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.29145819389355904\n",
      "Average test loss:  0.5551348261368451\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.2532293990941863\n",
      "Average test loss:  0.5451428475458483\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.22138211119669102\n",
      "Average test loss:  0.5386824572978521\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.1947696388874729\n",
      "Average test loss:  0.5350579871576102\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1724137197695794\n",
      "Average test loss:  0.5337150194678526\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.15349765729462\n",
      "Average test loss:  0.5343321167431695\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.1373843862651051\n",
      "Average test loss:  0.5364491681955975\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.12356824448722896\n",
      "Average test loss:  0.5399494859021132\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.11164449715215435\n",
      "Average test loss:  0.5447128528206079\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.1012891771186528\n",
      "Average test loss:  0.5502914290478331\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.09224526423781192\n",
      "Average test loss:  0.5565962845809391\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08430353781476059\n",
      "Average test loss:  0.5635629403614634\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.07729567863639399\n",
      "Average test loss:  0.5711139453264306\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07107800762190665\n",
      "Average test loss:  0.5793070851779483\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.06555277354749094\n",
      "Average test loss:  0.5875973178479675\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.06061463385117325\n",
      "Average test loss:  0.5962582711067522\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.05619668044230807\n",
      "Average test loss:  0.6052190354221203\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.716555698582518\n",
      "Average test loss:  0.7168454263030064\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.697868907493551\n",
      "Average test loss:  0.6986812475816601\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6909559273091498\n",
      "Average test loss:  0.6928661790393326\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.85625\n",
      "Average test accuracy:  0.5625\n",
      "\n",
      "Average train loss:  0.6874369377400186\n",
      "Average test loss:  0.691171881538677\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.801875\n",
      "Average test accuracy:  0.625\n",
      "\n",
      "Average train loss:  0.6830390047208822\n",
      "Average test loss:  0.689613487878605\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.76125\n",
      "Average test accuracy:  0.58375\n",
      "\n",
      "Average train loss:  0.6759685992083398\n",
      "Average test loss:  0.687136104324532\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.809375\n",
      "Average test accuracy:  0.625\n",
      "\n",
      "Average train loss:  0.6641515201862311\n",
      "Average test loss:  0.6829463170320196\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.855625\n",
      "Average test accuracy:  0.65\n",
      "\n",
      "Average train loss:  0.6442653736862011\n",
      "Average test loss:  0.6758310139962167\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.899375\n",
      "Average test accuracy:  0.67875\n",
      "\n",
      "Average train loss:  0.6125064275406217\n",
      "Average test loss:  0.6643146862513585\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.920625\n",
      "Average test accuracy:  0.7125\n",
      "\n",
      "Average train loss:  0.5670435808568164\n",
      "Average test loss:  0.6476370188080858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.5108302841007547\n",
      "Average test loss:  0.6267611196553736\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.45004879777227424\n",
      "Average test loss:  0.6043185819550297\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.958125\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3909962694404728\n",
      "Average test loss:  0.5829562549563109\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.3377599558744056\n",
      "Average test loss:  0.5647281563388734\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.29194176322881743\n",
      "Average test loss:  0.5504248225421832\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.25342959774069806\n",
      "Average test loss:  0.5400811603591278\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.22126708637582437\n",
      "Average test loss:  0.5332311695274244\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.19438894666636194\n",
      "Average test loss:  0.529389002217921\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.17182924417491333\n",
      "Average test loss:  0.5280498887623616\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1527770092832377\n",
      "Average test loss:  0.5288199714970844\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1365970667238802\n",
      "Average test loss:  0.5313112354620656\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.12276342883513736\n",
      "Average test loss:  0.5351714989332769\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.11085171325241601\n",
      "Average test loss:  0.5401913463802838\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.10054700047548577\n",
      "Average test loss:  0.5462448723698964\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.09157222916797188\n",
      "Average test loss:  0.5529743529134787\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.08370837625626985\n",
      "Average test loss:  0.5602601565784991\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07676933730748912\n",
      "Average test loss:  0.5682786521184698\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.0706302971694184\n",
      "Average test loss:  0.5766614756414437\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.06516810013384443\n",
      "Average test loss:  0.5853351013970197\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.060270949053741786\n",
      "Average test loss:  0.5944830029232139\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6921151363741553\n",
      "Average test loss:  0.6927870017634904\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5975\n",
      "Average test accuracy:  0.50375\n",
      "\n",
      "Average train loss:  0.6894601607392578\n",
      "Average test loss:  0.691881355736199\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.7625\n",
      "Average test accuracy:  0.53875\n",
      "\n",
      "Average train loss:  0.6830664966579092\n",
      "Average test loss:  0.6897074658832322\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.8925\n",
      "Average test accuracy:  0.6575\n",
      "\n",
      "Average train loss:  0.6702674709463344\n",
      "Average test loss:  0.6853059801146267\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.919375\n",
      "Average test accuracy:  0.7075\n",
      "\n",
      "Average train loss:  0.6476823863725562\n",
      "Average test loss:  0.6775373593963927\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.6111670319722599\n",
      "Average test loss:  0.6648897448711518\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.940625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.5588394501096383\n",
      "Average test loss:  0.64665129267757\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.49411549514990166\n",
      "Average test loss:  0.624154407236628\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.42511593644222473\n",
      "Average test loss:  0.6006626252210072\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.359836475833237\n",
      "Average test loss:  0.5795861102639379\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3028444845171416\n",
      "Average test loss:  0.5623120235195984\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.2554901268855709\n",
      "Average test loss:  0.5500793336393764\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.2169055689944415\n",
      "Average test loss:  0.5423114285877025\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.18560430901793823\n",
      "Average test loss:  0.5381616605820332\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1601279269863615\n",
      "Average test loss:  0.5372698995473919\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13924245758729678\n",
      "Average test loss:  0.5387647467694343\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.12196063785183471\n",
      "Average test loss:  0.5422322847869201\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10755236949176716\n",
      "Average test loss:  0.5475154600707806\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09544627881590383\n",
      "Average test loss:  0.5541382663039442\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.0851701269053715\n",
      "Average test loss:  0.5617729413318951\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07639498536382876\n",
      "Average test loss:  0.5702215936466973\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.06884485424926005\n",
      "Average test loss:  0.5792151961775296\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.062308229391434995\n",
      "Average test loss:  0.5888963139960605\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.05661561011085439\n",
      "Average test loss:  0.5990364905571596\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.05163817728475154\n",
      "Average test loss:  0.6093575359506183\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.047263645914277175\n",
      "Average test loss:  0.6198143667583592\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04340633368882143\n",
      "Average test loss:  0.6310844035470436\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.03997615715936476\n",
      "Average test loss:  0.6420256463196025\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.0369254167490199\n",
      "Average test loss:  0.6531744491222599\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.034190539996713835\n",
      "Average test loss:  0.6644148849806197\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.901875\n",
      "Average test accuracy:  0.685\n",
      "\n",
      "Average train loss:  0.6926969391216559\n",
      "Average test loss:  0.6929853664491604\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.7625\n",
      "Average test accuracy:  0.5525\n",
      "\n",
      "Average train loss:  0.6913427824835253\n",
      "Average test loss:  0.6925150440230272\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6871514708957078\n",
      "Average test loss:  0.6910577180874548\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.910625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.6764970744097022\n",
      "Average test loss:  0.6873411869906456\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.929375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.653555288834077\n",
      "Average test loss:  0.679282813567054\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.93125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.610639319966933\n",
      "Average test loss:  0.6641118075421061\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.938125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.5450162015766221\n",
      "Average test loss:  0.6407372249803563\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.46666130516010185\n",
      "Average test loss:  0.6128220088241715\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.3896889599505478\n",
      "Average test loss:  0.5860352083322568\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.32300967180703605\n",
      "Average test loss:  0.5645503741630634\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.26875115336810407\n",
      "Average test loss:  0.5489927761187198\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.22557606988710055\n",
      "Average test loss:  0.539167515692997\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.19127776453406076\n",
      "Average test loss:  0.5338057529649315\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.16382555224162368\n",
      "Average test loss:  0.5321877525816819\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.14158955203489565\n",
      "Average test loss:  0.5333512518616362\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.12340815798593856\n",
      "Average test loss:  0.5369286918353509\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.1083739018350736\n",
      "Average test loss:  0.5422918179649701\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.09583019858667123\n",
      "Average test loss:  0.5491230778964782\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08525523840653985\n",
      "Average test loss:  0.5571584540629962\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.07626774277114114\n",
      "Average test loss:  0.5660931620133369\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.06854782812449027\n",
      "Average test loss:  0.5758233649877641\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.71375\n",
      "\n",
      "Average train loss:  0.06189159224951874\n",
      "Average test loss:  0.5863876336690099\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.05609231915178677\n",
      "Average test loss:  0.5970739411282878\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.05103093188266913\n",
      "Average test loss:  0.6082282155670015\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.04656784717254866\n",
      "Average test loss:  0.6196088266635291\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.04263442886615243\n",
      "Average test loss:  0.6313832001265406\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.039149902805739184\n",
      "Average test loss:  0.6431681296713788\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.036050202224351326\n",
      "Average test loss:  0.6552323731241644\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.03329892714974617\n",
      "Average test loss:  0.6673710011035704\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.030835627213504652\n",
      "Average test loss:  0.6790681694787767\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7090029441131636\n",
      "Average test loss:  0.7099322006189293\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6912593259304511\n",
      "Average test loss:  0.6936213378923596\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.58375\n",
      "Average test accuracy:  0.50125\n",
      "\n",
      "Average train loss:  0.686632168821931\n",
      "Average test loss:  0.6909587753182104\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.926875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.6818884386567524\n",
      "Average test loss:  0.6892445910524346\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.6739090291896801\n",
      "Average test loss:  0.6864358958273636\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6599181273466074\n",
      "Average test loss:  0.6814905994832081\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.6361654235343069\n",
      "Average test loss:  0.6730620299360832\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5983087984306031\n",
      "Average test loss:  0.6595290131291416\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.5443734448758647\n",
      "Average test loss:  0.6404345752112017\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.4776131763610221\n",
      "Average test loss:  0.6170141161844537\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.40644745694907236\n",
      "Average test loss:  0.5929176629340455\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.3397118911279227\n",
      "Average test loss:  0.5716540569556172\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2824912292058903\n",
      "Average test loss:  0.5560206944016121\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.23573065086466372\n",
      "Average test loss:  0.5452866344755015\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.19830049570695021\n",
      "Average test loss:  0.5397810825845862\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.16843998432481558\n",
      "Average test loss:  0.5383297800097252\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.14447522391595727\n",
      "Average test loss:  0.5397298515591311\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1250547582745574\n",
      "Average test loss:  0.543957566480609\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.10917249324160616\n",
      "Average test loss:  0.5497276338603094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.09604462449093919\n",
      "Average test loss:  0.5573104554024056\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.08507454998591586\n",
      "Average test loss:  0.5657225471876539\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.07582246913256269\n",
      "Average test loss:  0.5752302255396313\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06796449279705258\n",
      "Average test loss:  0.5854648308980552\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.06122924420374815\n",
      "Average test loss:  0.5963604792519969\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.055431129923341226\n",
      "Average test loss:  0.6074848122831621\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.05039368303434691\n",
      "Average test loss:  0.6188943357993689\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.04601336604940776\n",
      "Average test loss:  0.630694157171695\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.042169762781245866\n",
      "Average test loss:  0.6423977210415392\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.03879096136578345\n",
      "Average test loss:  0.6542323214582156\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.035800846648551043\n",
      "Average test loss:  0.6661306938197247\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7035017078522988\n",
      "Average test loss:  0.7039514433042978\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6927300045381651\n",
      "Average test loss:  0.6936056141260067\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6906178363382485\n",
      "Average test loss:  0.6923158890012755\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.92375\n",
      "Average test accuracy:  0.6875\n",
      "\n",
      "Average train loss:  0.6880157599283052\n",
      "Average test loss:  0.6913837230050784\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.915\n",
      "Average test accuracy:  0.68\n",
      "\n",
      "Average train loss:  0.6827951744519206\n",
      "Average test loss:  0.6895711216306003\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.92\n",
      "Average test accuracy:  0.7025\n",
      "\n",
      "Average train loss:  0.6724993281754129\n",
      "Average test loss:  0.6859899051651324\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.921875\n",
      "Average test accuracy:  0.70625\n",
      "\n",
      "Average train loss:  0.6530287573742051\n",
      "Average test loss:  0.6792361770979559\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.71375\n",
      "\n",
      "Average train loss:  0.6184991408374811\n",
      "Average test loss:  0.6672095211536165\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.5639498465263122\n",
      "Average test loss:  0.6483948351691703\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.49123816975171014\n",
      "Average test loss:  0.6232996147351016\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.41151957987714555\n",
      "Average test loss:  0.5967900271995498\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.3374952758706966\n",
      "Average test loss:  0.5732297001229626\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.27578960492679566\n",
      "Average test loss:  0.556437653519354\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.2269428138531576\n",
      "Average test loss:  0.5460524969594567\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.18891361610237042\n",
      "Average test loss:  0.5410983688881111\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1592168511479523\n",
      "Average test loss:  0.5407541775096691\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13578810167247127\n",
      "Average test loss:  0.5433493089549529\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.11703950872227631\n",
      "Average test loss:  0.5486309684597194\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1018395360365341\n",
      "Average test loss:  0.5556723225085457\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08936242352817088\n",
      "Average test loss:  0.5640485980532887\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.0789898927128953\n",
      "Average test loss:  0.5739299904414301\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07028606907020556\n",
      "Average test loss:  0.5841188000233873\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.06291571958798718\n",
      "Average test loss:  0.5950114554705833\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.056632529910207695\n",
      "Average test loss:  0.6070761682648126\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.05123754697926671\n",
      "Average test loss:  0.6187463613757473\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.046572462177165846\n",
      "Average test loss:  0.6305350829236634\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.04252120433215222\n",
      "Average test loss:  0.6429105721671484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.03898144498729989\n",
      "Average test loss:  0.6551765001892965\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.0358771290757463\n",
      "Average test loss:  0.6675320227373653\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.03313790469978565\n",
      "Average test loss:  0.6798132300604021\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.691588467673221\n",
      "Average test loss:  0.6926116941224468\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.9\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.6887289151279689\n",
      "Average test loss:  0.6916172239535129\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6823101509917979\n",
      "Average test loss:  0.6894003111178074\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.6680561693787211\n",
      "Average test loss:  0.684472420186327\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.6384338630998296\n",
      "Average test loss:  0.6742011116764971\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.5854981543255207\n",
      "Average test loss:  0.6559013609849905\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.5107833433848226\n",
      "Average test loss:  0.6303071230541804\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.42687364156874025\n",
      "Average test loss:  0.602453606867423\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.34824944329698937\n",
      "Average test loss:  0.5783394525565294\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.2826930328189377\n",
      "Average test loss:  0.5604356958041673\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.23089129603611858\n",
      "Average test loss:  0.5492070013246321\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.190658225759736\n",
      "Average test loss:  0.5439780747275679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.1594244928388486\n",
      "Average test loss:  0.5437590467010969\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.13491727754559366\n",
      "Average test loss:  0.5463759056325684\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.11545825593401927\n",
      "Average test loss:  0.5515596044227772\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.09981208478862931\n",
      "Average test loss:  0.5594654860933139\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.08704377513536038\n",
      "Average test loss:  0.5684027022416989\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.07651350507618275\n",
      "Average test loss:  0.5782027449391803\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.06771976105239665\n",
      "Average test loss:  0.5894956176052576\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06032461234286581\n",
      "Average test loss:  0.6011883554518954\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.05403543093819335\n",
      "Average test loss:  0.6136591900148484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.04865666718895206\n",
      "Average test loss:  0.6262472864750175\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.04401109581207504\n",
      "Average test loss:  0.6392260823319084\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.03998491976614743\n",
      "Average test loss:  0.6524206546198713\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.03645963759464176\n",
      "Average test loss:  0.6653621613141171\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.03336689000822247\n",
      "Average test loss:  0.6786889052017487\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.030622652655419715\n",
      "Average test loss:  0.6921046068623364\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.02818206360458557\n",
      "Average test loss:  0.705519515677091\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.025991051298680696\n",
      "Average test loss:  0.7184832980651318\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.02401925529229888\n",
      "Average test loss:  0.7317108043776025\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6916132019203837\n",
      "Average test loss:  0.692613890097852\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.850625\n",
      "Average test accuracy:  0.655\n",
      "\n",
      "Average train loss:  0.688748686373093\n",
      "Average test loss:  0.6916185003611943\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.8925\n",
      "Average test accuracy:  0.69375\n",
      "\n",
      "Average train loss:  0.68242737480301\n",
      "Average test loss:  0.6894269406811969\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.89375\n",
      "Average test accuracy:  0.7\n",
      "\n",
      "Average train loss:  0.6692111810262028\n",
      "Average test loss:  0.6848306385015324\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.924375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.643685016084404\n",
      "Average test loss:  0.6758540329013826\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.5993940271873625\n",
      "Average test loss:  0.6602171049373832\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.945625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5344177025142551\n",
      "Average test loss:  0.6373736439928477\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.45707748798718967\n",
      "Average test loss:  0.6106120131776994\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.38013049182792463\n",
      "Average test loss:  0.5853480313078587\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.31271206808329316\n",
      "Average test loss:  0.565021140065805\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2575129151497692\n",
      "Average test loss:  0.5509865195091104\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.21357660753697758\n",
      "Average test loss:  0.5425499279318361\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1789085444108184\n",
      "Average test loss:  0.5390027541007526\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.15146476564541256\n",
      "Average test loss:  0.5391797951383731\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.12954390095431725\n",
      "Average test loss:  0.5422513491546038\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.11184469184988323\n",
      "Average test loss:  0.5476844068945613\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.0973991769588431\n",
      "Average test loss:  0.5549597985550445\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.08546260164012075\n",
      "Average test loss:  0.5634515878400773\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.07551918813517006\n",
      "Average test loss:  0.5733714239757297\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.06716086947691276\n",
      "Average test loss:  0.5836805854101451\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.060061769026287626\n",
      "Average test loss:  0.594869947586877\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.0539862916963576\n",
      "Average test loss:  0.6066236518529823\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.048739649813223256\n",
      "Average test loss:  0.6187107512513318\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.0441900389114561\n",
      "Average test loss:  0.6312885895088228\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.040208473111981544\n",
      "Average test loss:  0.643836241023514\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.03671620644314645\n",
      "Average test loss:  0.6565378468969939\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.03362733111445551\n",
      "Average test loss:  0.6693495149124998\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.030877126158720142\n",
      "Average test loss:  0.6824456466974937\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.02842383703515929\n",
      "Average test loss:  0.695489934941686\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.026235503429872815\n",
      "Average test loss:  0.7085232985295494\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.836875\n",
      "Average test accuracy:  0.645\n",
      "\n",
      "Average train loss:  0.6917273895147774\n",
      "Average test loss:  0.6926649785337661\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.9275\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.6892758672235746\n",
      "Average test loss:  0.6918286555394445\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.915\n",
      "Average test accuracy:  0.7\n",
      "\n",
      "Average train loss:  0.6844201372235533\n",
      "Average test loss:  0.690176784357908\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.901875\n",
      "Average test accuracy:  0.6725\n",
      "\n",
      "Average train loss:  0.6754878719764229\n",
      "Average test loss:  0.68714370459998\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.906875\n",
      "Average test accuracy:  0.67875\n",
      "\n",
      "Average train loss:  0.6608363643845611\n",
      "Average test loss:  0.6821524496425395\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.901875\n",
      "Average test accuracy:  0.665\n",
      "\n",
      "Average train loss:  0.6389144791030325\n",
      "Average test loss:  0.6747798033079294\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.91375\n",
      "Average test accuracy:  0.68625\n",
      "\n",
      "Average train loss:  0.609331363915022\n",
      "Average test loss:  0.6646545439523116\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.92625\n",
      "Average test accuracy:  0.70375\n",
      "\n",
      "Average train loss:  0.5728902465859976\n",
      "Average test loss:  0.6522673380764513\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.71125\n",
      "\n",
      "Average train loss:  0.5318952394985763\n",
      "Average test loss:  0.6381625705160671\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.489121590706836\n",
      "Average test loss:  0.6234461802469432\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.44717643815697006\n",
      "Average test loss:  0.6091309467811278\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.958125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.4076898254392776\n",
      "Average test loss:  0.595747025498974\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.3714859370285221\n",
      "Average test loss:  0.5836958771645174\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.33884844889769883\n",
      "Average test loss:  0.5734825741072123\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3096667121996817\n",
      "Average test loss:  0.5646436536277474\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.2836575301754858\n",
      "Average test loss:  0.5580020772783126\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.260480470520617\n",
      "Average test loss:  0.5522344236184249\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.23981792584335512\n",
      "Average test loss:  0.5480897550417722\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2213519324037653\n",
      "Average test loss:  0.5447799002134235\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.20481587429354833\n",
      "Average test loss:  0.543005589027931\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.1899647147738558\n",
      "Average test loss:  0.5420622919706379\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1765902103300158\n",
      "Average test loss:  0.5421425796751512\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.16450816921576836\n",
      "Average test loss:  0.5429464957120556\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.15356348750683083\n",
      "Average test loss:  0.5445015958793026\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.1436171074644849\n",
      "Average test loss:  0.5465932295033881\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.13455629341397726\n",
      "Average test loss:  0.549190395534737\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.1262764535904248\n",
      "Average test loss:  0.5524837999978874\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.11868893987700378\n",
      "Average test loss:  0.5561555239160527\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.11172458892654374\n",
      "Average test loss:  0.5602764219632114\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.10531433485819879\n",
      "Average test loss:  0.564716528374051\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7034900046479131\n",
      "Average test loss:  0.7040546246204089\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6942730581522208\n",
      "Average test loss:  0.6953054494772797\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6910953521282645\n",
      "Average test loss:  0.6927751831559515\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6890213543896598\n",
      "Average test loss:  0.6917610575127756\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.625625\n",
      "Average test accuracy:  0.53\n",
      "\n",
      "Average train loss:  0.6861670071020614\n",
      "Average test loss:  0.6907128279000005\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.814375\n",
      "Average test accuracy:  0.615\n",
      "\n",
      "Average train loss:  0.6811742705092921\n",
      "Average test loss:  0.6889581906909895\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.875\n",
      "Average test accuracy:  0.67125\n",
      "\n",
      "Average train loss:  0.6718286282769065\n",
      "Average test loss:  0.6856600582224478\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.900625\n",
      "Average test accuracy:  0.70625\n",
      "\n",
      "Average train loss:  0.6543205506957173\n",
      "Average test loss:  0.6793970319585343\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.924375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.6240593997281172\n",
      "Average test loss:  0.6683996639109644\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.940625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.5789479286375115\n",
      "Average test loss:  0.6516924524833062\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5228473502605052\n",
      "Average test loss:  0.6306378946379628\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.46358551389147634\n",
      "Average test loss:  0.6083802905256969\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.40773119317021395\n",
      "Average test loss:  0.587765840112774\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.35821571268062874\n",
      "Average test loss:  0.5704061721620609\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.31558760049426676\n",
      "Average test loss:  0.5563566556767485\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2792847239338339\n",
      "Average test loss:  0.5458810473191039\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.24841903858561576\n",
      "Average test loss:  0.5381978213401809\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.22209423415886587\n",
      "Average test loss:  0.5331653353708021\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.19953996647840622\n",
      "Average test loss:  0.5302528409774899\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1801085377588889\n",
      "Average test loss:  0.5292582607073113\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.1632935921247044\n",
      "Average test loss:  0.5299686763720083\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.14863161820264828\n",
      "Average test loss:  0.5317394352119723\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.13579774554245427\n",
      "Average test loss:  0.5346508100630698\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.12450436276885024\n",
      "Average test loss:  0.5385665069331061\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.11451205479653799\n",
      "Average test loss:  0.5430429253356764\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.10564334465560443\n",
      "Average test loss:  0.5485734019773064\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.09773371914349821\n",
      "Average test loss:  0.5543217584293917\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.09066604110060324\n",
      "Average test loss:  0.5606422973052001\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08432623311845315\n",
      "Average test loss:  0.567509115710715\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07861603175404326\n",
      "Average test loss:  0.5746925024595332\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.764375\n",
      "Average test accuracy:  0.5425\n",
      "\n",
      "Average train loss:  0.692390360596476\n",
      "Average test loss:  0.6928798852180336\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.88875\n",
      "Average test accuracy:  0.66375\n",
      "\n",
      "Average train loss:  0.6907673835186183\n",
      "Average test loss:  0.6923149222240509\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.93125\n",
      "Average test accuracy:  0.715\n",
      "\n",
      "Average train loss:  0.6867743798451663\n",
      "Average test loss:  0.6909215636692565\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.90125\n",
      "Average test accuracy:  0.6825\n",
      "\n",
      "Average train loss:  0.677871853808978\n",
      "Average test loss:  0.6878321446210652\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.895625\n",
      "Average test accuracy:  0.68\n",
      "\n",
      "Average train loss:  0.6591656740066406\n",
      "Average test loss:  0.6813761056003954\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.91125\n",
      "Average test accuracy:  0.69875\n",
      "\n",
      "Average train loss:  0.6247451061616454\n",
      "Average test loss:  0.6694586033159422\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.93375\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.5725828974366505\n",
      "Average test loss:  0.6514011913236429\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.940625\n",
      "Average test accuracy:  0.71375\n",
      "\n",
      "Average train loss:  0.5093051647526089\n",
      "Average test loss:  0.6294836825668215\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.4444446096964929\n",
      "Average test loss:  0.6074119961369626\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.384616981535006\n",
      "Average test loss:  0.5876785156181203\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.3323611643170136\n",
      "Average test loss:  0.5714225073274605\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.28799205881931167\n",
      "Average test loss:  0.5588715943711473\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.25077915776516907\n",
      "Average test loss:  0.5499582909122279\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2196178635765739\n",
      "Average test loss:  0.5441417534917982\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1934614268434414\n",
      "Average test loss:  0.5410997529412419\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.17138203257606097\n",
      "Average test loss:  0.5402437221437693\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1526591104476343\n",
      "Average test loss:  0.541374174514085\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1366681947905145\n",
      "Average test loss:  0.5437200127651596\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.12292711036609112\n",
      "Average test loss:  0.54784788775006\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.11105254883646777\n",
      "Average test loss:  0.5531175835040933\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.10071618294138839\n",
      "Average test loss:  0.5590558444043682\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09168937647098778\n",
      "Average test loss:  0.5655981071849304\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.0837618932301396\n",
      "Average test loss:  0.5729715555030293\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.07677118376831966\n",
      "Average test loss:  0.5810400339138905\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.07058234273991432\n",
      "Average test loss:  0.5891937192682413\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.06508185731742062\n",
      "Average test loss:  0.597993587304187\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.06018813578948712\n",
      "Average test loss:  0.6069260061447315\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.0558152034700932\n",
      "Average test loss:  0.615798824178156\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.05190894096457951\n",
      "Average test loss:  0.6250383889768734\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.048390146855502865\n",
      "Average test loss:  0.6343730471409089\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6990970255758767\n",
      "Average test loss:  0.7002355659105358\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.689405508250288\n",
      "Average test loss:  0.6922511703176882\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.6851957878933814\n",
      "Average test loss:  0.69040387925241\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.88125\n",
      "Average test accuracy:  0.6775\n",
      "\n",
      "Average train loss:  0.6794737661901166\n",
      "Average test loss:  0.6883885132272146\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.8875\n",
      "Average test accuracy:  0.67875\n",
      "\n",
      "Average train loss:  0.6693532489620121\n",
      "Average test loss:  0.6848223333445459\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.915625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.6510589909548999\n",
      "Average test loss:  0.6783056400458275\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.93125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.61970740920991\n",
      "Average test loss:  0.6670591788213939\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.571911128981672\n",
      "Average test loss:  0.6498179538683858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.5102948163563066\n",
      "Average test loss:  0.6275985247832094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.4428319454013608\n",
      "Average test loss:  0.6035863500067061\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.37806772744363487\n",
      "Average test loss:  0.5814151269186599\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.96625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.32098544569379744\n",
      "Average test loss:  0.5631959336229976\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.27298408163195126\n",
      "Average test loss:  0.5495885940611248\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2334546605909448\n",
      "Average test loss:  0.5405481111598168\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.20105958623632567\n",
      "Average test loss:  0.535361330708383\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.17445905743817583\n",
      "Average test loss:  0.5331258795306678\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.152484301407454\n",
      "Average test loss:  0.5336933499108433\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13420668965489033\n",
      "Average test loss:  0.5363067364649851\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.11888553534460507\n",
      "Average test loss:  0.5404626628934115\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.10593574991127154\n",
      "Average test loss:  0.5461823737434545\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.09489721257900667\n",
      "Average test loss:  0.5529092965328662\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.08544205478439271\n",
      "Average test loss:  0.5606997181645352\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07726524751578956\n",
      "Average test loss:  0.5690595391028113\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.07016509774092312\n",
      "Average test loss:  0.5780438816770518\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.06395492243085986\n",
      "Average test loss:  0.587451740785337\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.058499813665619425\n",
      "Average test loss:  0.597263926870896\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.05368568820783854\n",
      "Average test loss:  0.6074219139128916\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04942735624516447\n",
      "Average test loss:  0.6177306357492679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.04563581980789825\n",
      "Average test loss:  0.6281541404477611\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.04225779888029099\n",
      "Average test loss:  0.6385707192709594\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6918445345141816\n",
      "Average test loss:  0.6926966211142854\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.6675\n",
      "Average test accuracy:  0.51125\n",
      "\n",
      "Average train loss:  0.6889437882769563\n",
      "Average test loss:  0.6917002961216148\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.765\n",
      "Average test accuracy:  0.545\n",
      "\n",
      "Average train loss:  0.6821000073696074\n",
      "Average test loss:  0.6893786253997228\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.893125\n",
      "Average test accuracy:  0.6625\n",
      "\n",
      "Average train loss:  0.6682688167054028\n",
      "Average test loss:  0.6846309410495103\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.916875\n",
      "Average test accuracy:  0.70375\n",
      "\n",
      "Average train loss:  0.6429710285309925\n",
      "Average test loss:  0.6759983060185397\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.6010066195744731\n",
      "Average test loss:  0.6614342089866709\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.5402209349171236\n",
      "Average test loss:  0.6403678822166038\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.46704754975198903\n",
      "Average test loss:  0.6152701954917852\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.39364671287295794\n",
      "Average test loss:  0.590517597645031\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.958125\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.32832049158353854\n",
      "Average test loss:  0.5699724822004916\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.27399953928886916\n",
      "Average test loss:  0.5546001615338616\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.23017199113765033\n",
      "Average test loss:  0.5447377616831804\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1951008047816387\n",
      "Average test loss:  0.5393543172690173\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.16690102639682733\n",
      "Average test loss:  0.537406693626208\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.14403348018877044\n",
      "Average test loss:  0.5380048508867019\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.12531936595042464\n",
      "Average test loss:  0.5412516496558729\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.10986955498980182\n",
      "Average test loss:  0.546422158798182\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.09697889523013105\n",
      "Average test loss:  0.5528356059478224\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.08612462057862615\n",
      "Average test loss:  0.560640035318746\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.07691529020222759\n",
      "Average test loss:  0.5694571010793208\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06905170508122098\n",
      "Average test loss:  0.5787527927039251\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.06227520765343129\n",
      "Average test loss:  0.5889068774308565\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.056415305456207376\n",
      "Average test loss:  0.5992657091435999\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.051320930439738455\n",
      "Average test loss:  0.6101737013515016\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.04686204191786747\n",
      "Average test loss:  0.6207533361930812\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.04295078784522984\n",
      "Average test loss:  0.6323144589068858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.03949186522328221\n",
      "Average test loss:  0.6435022448585611\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.03642820447823579\n",
      "Average test loss:  0.6549492091461674\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.033692559127882715\n",
      "Average test loss:  0.6663914255014699\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.03124273818490068\n",
      "Average test loss:  0.6777326433273521\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.769375\n",
      "Average test accuracy:  0.55875\n",
      "\n",
      "Average train loss:  0.692133956899204\n",
      "Average test loss:  0.6927941982269417\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.925\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.6898169166558082\n",
      "Average test loss:  0.691992729293038\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.929375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.6839923510451255\n",
      "Average test loss:  0.6899824905825728\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.6712298977862452\n",
      "Average test loss:  0.6855546426323039\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.645569966568775\n",
      "Average test loss:  0.6765495352106187\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.6003571390452239\n",
      "Average test loss:  0.6605869987884484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5333288332219727\n",
      "Average test loss:  0.636794195714084\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.4541103156936434\n",
      "Average test loss:  0.6091920246734697\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.3769322819732033\n",
      "Average test loss:  0.5831074817829359\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3099371448585546\n",
      "Average test loss:  0.5625418054568979\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.2555374449566536\n",
      "Average test loss:  0.5482963184766413\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.21250661644020918\n",
      "Average test loss:  0.5398277740101369\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.17860931420703718\n",
      "Average test loss:  0.5361593266745082\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1517356518758805\n",
      "Average test loss:  0.5362930073281843\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.13018018135219833\n",
      "Average test loss:  0.5390959685317509\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.11271991755496054\n",
      "Average test loss:  0.544283923572383\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.09841553582769014\n",
      "Average test loss:  0.5513912385765876\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08658307722539227\n",
      "Average test loss:  0.5597155218875499\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07667340751407871\n",
      "Average test loss:  0.5695312150943693\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06831493844571505\n",
      "Average test loss:  0.5797919035923841\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06119563676724064\n",
      "Average test loss:  0.5906935495973376\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.055100865058372306\n",
      "Average test loss:  0.6022508510068594\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.04983397782281218\n",
      "Average test loss:  0.6139480173920924\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.045262380747296466\n",
      "Average test loss:  0.6259967938345605\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.041260383037496386\n",
      "Average test loss:  0.6383294611759057\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.03774430859696105\n",
      "Average test loss:  0.6508817508829333\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.03463501076266826\n",
      "Average test loss:  0.6630852201223111\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.031875452743986274\n",
      "Average test loss:  0.6756486153489476\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.02941174999901118\n",
      "Average test loss:  0.6881024285307532\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.02721083469299142\n",
      "Average test loss:  0.7007420413823476\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.692980732489812\n",
      "Average test loss:  0.6937196964012599\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.8775\n",
      "Average test accuracy:  0.69125\n",
      "\n",
      "Average train loss:  0.6900398574315743\n",
      "Average test loss:  0.6920713913275641\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.676875\n",
      "Average test accuracy:  0.55125\n",
      "\n",
      "Average train loss:  0.6868749000023548\n",
      "Average test loss:  0.6909770866572389\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.723125\n",
      "Average test accuracy:  0.56375\n",
      "\n",
      "Average train loss:  0.6812390745393415\n",
      "Average test loss:  0.6890157721546405\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.81125\n",
      "Average test accuracy:  0.6175\n",
      "\n",
      "Average train loss:  0.6709023681297889\n",
      "Average test loss:  0.6853864521983493\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.869375\n",
      "Average test accuracy:  0.6675\n",
      "\n",
      "Average train loss:  0.6515029122245043\n",
      "Average test loss:  0.6785100421571834\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9225\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.6167251886728752\n",
      "Average test loss:  0.6659604812948164\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.940625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.5620473042689565\n",
      "Average test loss:  0.6462132897195275\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.4924078227958442\n",
      "Average test loss:  0.6212393198093702\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.4188932586967138\n",
      "Average test loss:  0.5956403539296639\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.3511975229168389\n",
      "Average test loss:  0.5734931941047757\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.29359419259391034\n",
      "Average test loss:  0.5566292663741431\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2463820602161546\n",
      "Average test loss:  0.5452883876299026\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.20827630427992516\n",
      "Average test loss:  0.5386369877221694\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1775822794966836\n",
      "Average test loss:  0.5358208477172112\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.15273393519220826\n",
      "Average test loss:  0.536049366706456\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13245399068270677\n",
      "Average test loss:  0.5388956838129201\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.11576511164529805\n",
      "Average test loss:  0.5438504274747692\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10189921934315672\n",
      "Average test loss:  0.5503728834451288\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.09027321600820354\n",
      "Average test loss:  0.5578170361173304\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08045574793709032\n",
      "Average test loss:  0.5666659867716715\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07209165236165056\n",
      "Average test loss:  0.5761305762886663\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.06491228587963958\n",
      "Average test loss:  0.586190403345442\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.058703341396581094\n",
      "Average test loss:  0.5969017007846968\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.053309309539179915\n",
      "Average test loss:  0.607773319089148\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.048598064525578126\n",
      "Average test loss:  0.6188650775085486\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.044455985964157424\n",
      "Average test loss:  0.6304728382083263\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.04079312829824754\n",
      "Average test loss:  0.6420672257015775\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.0375408265869649\n",
      "Average test loss:  0.6536569389295717\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.03463777593431328\n",
      "Average test loss:  0.6654363263450227\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6921269213218696\n",
      "Average test loss:  0.6931937519588338\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.654375\n",
      "Average test accuracy:  0.5475\n",
      "\n",
      "Average train loss:  0.6884462747574375\n",
      "Average test loss:  0.691524648751901\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.719375\n",
      "Average test accuracy:  0.56875\n",
      "\n",
      "Average train loss:  0.6826829437638934\n",
      "Average test loss:  0.6895333649308579\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.87625\n",
      "Average test accuracy:  0.67875\n",
      "\n",
      "Average train loss:  0.671216437447952\n",
      "Average test loss:  0.6855129838852702\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.904375\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.6495897749473747\n",
      "Average test loss:  0.6779112255429088\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.6113116059131661\n",
      "Average test loss:  0.6643354276321219\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.5507172998374957\n",
      "Average test loss:  0.6428203873567703\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.4711840384815909\n",
      "Average test loss:  0.6148898708243009\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3875697207371594\n",
      "Average test loss:  0.5866950722194874\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.3133643067613362\n",
      "Average test loss:  0.5638688064734007\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.966875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.25348149794102887\n",
      "Average test loss:  0.5482372374229061\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.20714225506278747\n",
      "Average test loss:  0.5396820005026809\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.17150086767090253\n",
      "Average test loss:  0.5363763603067682\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.14388269119155506\n",
      "Average test loss:  0.5377200176770303\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.12217944297166193\n",
      "Average test loss:  0.5418480450618678\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.10489777941397443\n",
      "Average test loss:  0.5482694365493911\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09093606344902716\n",
      "Average test loss:  0.5569507835224244\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07951364616690336\n",
      "Average test loss:  0.5667683743065554\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07005670757540124\n",
      "Average test loss:  0.5777153335901898\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06213574849441688\n",
      "Average test loss:  0.5891943372905645\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.05544399570631491\n",
      "Average test loss:  0.6012724373460744\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.049739466950639626\n",
      "Average test loss:  0.6141448369142201\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.04484032678555216\n",
      "Average test loss:  0.6270486674322261\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.04059977957689967\n",
      "Average test loss:  0.6400837906274988\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.036904682095223205\n",
      "Average test loss:  0.6534070413764117\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.03367580275934945\n",
      "Average test loss:  0.6670208125610539\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.030826515722794125\n",
      "Average test loss:  0.6801872760436529\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.02830012408553643\n",
      "Average test loss:  0.6936206629261367\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.02605596118991921\n",
      "Average test loss:  0.7068928817813053\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.024049627851834107\n",
      "Average test loss:  0.7204317227505431\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6983591276490478\n",
      "Average test loss:  0.6989767055657164\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.50625\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6897232002318526\n",
      "Average test loss:  0.6919927929365123\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.620625\n",
      "Average test accuracy:  0.53125\n",
      "\n",
      "Average train loss:  0.6858701097878533\n",
      "Average test loss:  0.6906412786726954\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.701875\n",
      "Average test accuracy:  0.5525\n",
      "\n",
      "Average train loss:  0.6793461322039461\n",
      "Average test loss:  0.6883788005510872\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.8075\n",
      "Average test accuracy:  0.61625\n",
      "\n",
      "Average train loss:  0.6677899091239666\n",
      "Average test loss:  0.6843262764790436\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.881875\n",
      "Average test accuracy:  0.67375\n",
      "\n",
      "Average train loss:  0.6477692678310989\n",
      "Average test loss:  0.6772132549966039\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.914375\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.6145555103738106\n",
      "Average test loss:  0.6652885972294614\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.5650506899964342\n",
      "Average test loss:  0.6474195491572498\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5013229563238263\n",
      "Average test loss:  0.624537479739654\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.43067128922546144\n",
      "Average test loss:  0.5998238924845191\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3621392915693751\n",
      "Average test loss:  0.5771184518591359\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.30191393127098615\n",
      "Average test loss:  0.5591840212273556\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.2518402625256591\n",
      "Average test loss:  0.5466519499639526\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.21128639821136286\n",
      "Average test loss:  0.5391299005470781\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.17877360220542027\n",
      "Average test loss:  0.5359617824656515\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1526419886502932\n",
      "Average test loss:  0.5361625506145778\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.13150696216432523\n",
      "Average test loss:  0.539381946281348\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.11426427723212897\n",
      "Average test loss:  0.5443901104374517\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.10005783862610497\n",
      "Average test loss:  0.5513898600486823\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.08824797954063131\n",
      "Average test loss:  0.559643899150498\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.07832433729958317\n",
      "Average test loss:  0.5687852054548321\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.06992415238930404\n",
      "Average test loss:  0.578784643558197\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.06275794565191198\n",
      "Average test loss:  0.589381766932297\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.05659150111913783\n",
      "Average test loss:  0.6004755634467908\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.051256580078129686\n",
      "Average test loss:  0.6121674687669328\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.04660194866139659\n",
      "Average test loss:  0.6239465925760198\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.04252817931432095\n",
      "Average test loss:  0.6359830571102991\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.03893459591356004\n",
      "Average test loss:  0.6479542638942928\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.035755324401244244\n",
      "Average test loss:  0.6601956497200826\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.032932306795535556\n",
      "Average test loss:  0.6726133408057131\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6922373466932004\n",
      "Average test loss:  0.6928391995455213\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.715\n",
      "Average test accuracy:  0.51375\n",
      "\n",
      "Average train loss:  0.6906280830204835\n",
      "Average test loss:  0.6922845601530437\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.936875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6866730056139717\n",
      "Average test loss:  0.690907911442013\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6760117702238896\n",
      "Average test loss:  0.6871997179781615\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6476687241111924\n",
      "Average test loss:  0.6772686437783694\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5838106189852666\n",
      "Average test loss:  0.654826948511329\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.48305870991598354\n",
      "Average test loss:  0.6196533229437075\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.37574145415245747\n",
      "Average test loss:  0.5840623885332573\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.28838989126097775\n",
      "Average test loss:  0.5578849994476771\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.22467242192037232\n",
      "Average test loss:  0.5429814274515841\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.17885168162624418\n",
      "Average test loss:  0.5375568990464996\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1454035791293249\n",
      "Average test loss:  0.5381060665737349\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.12036683631290224\n",
      "Average test loss:  0.5431568686731886\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.10119942969800978\n",
      "Average test loss:  0.5512679231919199\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08621339216528563\n",
      "Average test loss:  0.5613497889865782\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.07426988044513187\n",
      "Average test loss:  0.5726630738771522\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06463475529297678\n",
      "Average test loss:  0.5858579366549233\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.05670673244739812\n",
      "Average test loss:  0.5993325084029141\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.050139175990440855\n",
      "Average test loss:  0.6140849538717239\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04461684196940477\n",
      "Average test loss:  0.6285078620046646\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.03994406995829266\n",
      "Average test loss:  0.6433865943255075\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.03595824136167972\n",
      "Average test loss:  0.6584015191179393\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.03251573566663646\n",
      "Average test loss:  0.6731301785774004\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.02952320979101238\n",
      "Average test loss:  0.6882464612351634\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.026910818942625512\n",
      "Average test loss:  0.703238339418931\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.024606379995431\n",
      "Average test loss:  0.7178546680970855\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.02256162888997117\n",
      "Average test loss:  0.7329525149476246\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.020752396950828856\n",
      "Average test loss:  0.7472525161058464\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.01913233927303251\n",
      "Average test loss:  0.7618294071261106\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.017700153158125443\n",
      "Average test loss:  0.7760883189697534\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5225\n",
      "Average test accuracy:  0.50375\n",
      "\n",
      "Average train loss:  0.6914079089558139\n",
      "Average test loss:  0.6925414482971094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.928125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.6886799214404896\n",
      "Average test loss:  0.6915971732427665\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.8975\n",
      "Average test accuracy:  0.67875\n",
      "\n",
      "Average train loss:  0.6833363031875012\n",
      "Average test loss:  0.68976326801532\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.888125\n",
      "Average test accuracy:  0.65375\n",
      "\n",
      "Average train loss:  0.6729031290905764\n",
      "Average test loss:  0.6862014325429886\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.881875\n",
      "Average test accuracy:  0.64125\n",
      "\n",
      "Average train loss:  0.6545306637830297\n",
      "Average test loss:  0.6799702733270726\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.889375\n",
      "Average test accuracy:  0.65375\n",
      "\n",
      "Average train loss:  0.6264137816679395\n",
      "Average test loss:  0.670477926707656\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.901875\n",
      "Average test accuracy:  0.67625\n",
      "\n",
      "Average train loss:  0.5893806130754787\n",
      "Average test loss:  0.657968925022178\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.92375\n",
      "Average test accuracy:  0.705\n",
      "\n",
      "Average train loss:  0.5465306668879819\n",
      "Average test loss:  0.6434238375139132\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.5018502615155017\n",
      "Average test loss:  0.6280140104322598\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.45850192045057847\n",
      "Average test loss:  0.6129553891358176\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.41810965654797866\n",
      "Average test loss:  0.5991319907793925\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.38133220289977615\n",
      "Average test loss:  0.5869427294439858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3482846265403767\n",
      "Average test loss:  0.5762312544728639\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.31881870199567125\n",
      "Average test loss:  0.5672063558608149\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2925849977758073\n",
      "Average test loss:  0.5602837528101094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2692025928771884\n",
      "Average test loss:  0.5545133370775926\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.9825\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.24835624852847127\n",
      "Average test loss:  0.5502232403300104\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2296963534438918\n",
      "Average test loss:  0.5469231434288064\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.21295623903641167\n",
      "Average test loss:  0.544894791917094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.19789661024510383\n",
      "Average test loss:  0.5442394283262101\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.18429668858397916\n",
      "Average test loss:  0.5441498870933322\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.1719904758086337\n",
      "Average test loss:  0.5448682099594366\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.16081957534009098\n",
      "Average test loss:  0.5464263213001055\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.15064956941753044\n",
      "Average test loss:  0.5484350163784494\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.14136487235260076\n",
      "Average test loss:  0.5512881118415924\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.13286377028053245\n",
      "Average test loss:  0.5546817921716997\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.12506251866854864\n",
      "Average test loss:  0.5582652942117862\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.1178790209402309\n",
      "Average test loss:  0.5623764780532718\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.11126143788051997\n",
      "Average test loss:  0.5669271971076579\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.10515588157492499\n",
      "Average test loss:  0.5715624425251221\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6932536666401895\n",
      "Average test loss:  0.6941871040218494\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6895272911606186\n",
      "Average test loss:  0.6919439120365913\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.926875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6852161538678359\n",
      "Average test loss:  0.6903942564382399\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.676794405872993\n",
      "Average test loss:  0.6874470733417485\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.6601067364847873\n",
      "Average test loss:  0.6815787397905666\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.6293762371632287\n",
      "Average test loss:  0.6707636004981664\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.5818477734580809\n",
      "Average test loss:  0.6540856235635545\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.5226682625411385\n",
      "Average test loss:  0.6332010967826841\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.4605752152593306\n",
      "Average test loss:  0.6114736729849587\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.40239988442852637\n",
      "Average test loss:  0.5915161649529361\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.3510858034410262\n",
      "Average test loss:  0.5748202568941532\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3070836901677675\n",
      "Average test loss:  0.5613224349330524\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2698582051712131\n",
      "Average test loss:  0.5513438259924267\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.23839994920025942\n",
      "Average test loss:  0.5442145974193449\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2117571095525972\n",
      "Average test loss:  0.5396700704736795\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.18907533057163525\n",
      "Average test loss:  0.5371043979040829\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.16966437590166072\n",
      "Average test loss:  0.5367521169066948\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.15295256963672582\n",
      "Average test loss:  0.5377610249020407\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.13847573506123587\n",
      "Average test loss:  0.5401866296287859\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1258609260604253\n",
      "Average test loss:  0.5436466852581184\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.11481978269197059\n",
      "Average test loss:  0.548127860239268\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.10510876392665841\n",
      "Average test loss:  0.5534291982393175\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09652572744853698\n",
      "Average test loss:  0.5593989349636223\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08891079242967782\n",
      "Average test loss:  0.5660748329831616\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.08211672900293658\n",
      "Average test loss:  0.5729566682680338\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.076048581512752\n",
      "Average test loss:  0.5802998450817705\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.07060284469656142\n",
      "Average test loss:  0.5880922786328644\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.0657097715291552\n",
      "Average test loss:  0.5962824325254448\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06129871674314033\n",
      "Average test loss:  0.6043575394175311\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.05732026174973078\n",
      "Average test loss:  0.6127480314600064\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6963996134983231\n",
      "Average test loss:  0.6971495002457098\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6907021844733189\n",
      "Average test loss:  0.6925444081783055\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.908125\n",
      "Average test accuracy:  0.65875\n",
      "\n",
      "Average train loss:  0.6871158883964229\n",
      "Average test loss:  0.691076613373807\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.920625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.6804277560475028\n",
      "Average test loss:  0.688739391022084\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.92375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6665206673833396\n",
      "Average test loss:  0.6838657501393719\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6390085456520155\n",
      "Average test loss:  0.6741431296002603\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5918922318333962\n",
      "Average test loss:  0.6573141390784384\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.5269483735552688\n",
      "Average test loss:  0.6340982750979957\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.45481277212503807\n",
      "Average test loss:  0.60853259256958\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.386667702913603\n",
      "Average test loss:  0.5852441219529575\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3278967852862124\n",
      "Average test loss:  0.5661590311557787\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.27925807282883164\n",
      "Average test loss:  0.5524535391570696\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.23953381594971782\n",
      "Average test loss:  0.5430331746869719\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.20713173321863695\n",
      "Average test loss:  0.5371945144232378\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.18052504450815712\n",
      "Average test loss:  0.5345843399413567\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.15848718578846868\n",
      "Average test loss:  0.5346449615208004\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.14009620735662812\n",
      "Average test loss:  0.5367040446631833\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.12459567847904014\n",
      "Average test loss:  0.5403555842289592\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.11144437614515675\n",
      "Average test loss:  0.5454525125262857\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.10018516878637627\n",
      "Average test loss:  0.5517530912749061\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.09048814534163126\n",
      "Average test loss:  0.5590317463281815\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.08208103810948798\n",
      "Average test loss:  0.5665982173616939\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07475448118820761\n",
      "Average test loss:  0.5749072787011028\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.06832953773104375\n",
      "Average test loss:  0.583829936422784\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.06267533100707501\n",
      "Average test loss:  0.5932272663637933\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.05767869955198407\n",
      "Average test loss:  0.6027995026261692\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.053249039598604796\n",
      "Average test loss:  0.61258744848179\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.04930295594010945\n",
      "Average test loss:  0.6225776493728883\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.045785137470391084\n",
      "Average test loss:  0.6324216792904066\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.042636015538976335\n",
      "Average test loss:  0.6424955596317834\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6996146716658833\n",
      "Average test loss:  0.7003890676903856\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6897769629914042\n",
      "Average test loss:  0.6922222691751934\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.92375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6850021690264759\n",
      "Average test loss:  0.6902781609253297\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.845625\n",
      "Average test accuracy:  0.60625\n",
      "\n",
      "Average train loss:  0.6775510610589416\n",
      "Average test loss:  0.687778401152085\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.889375\n",
      "Average test accuracy:  0.655\n",
      "\n",
      "Average train loss:  0.6641930715500015\n",
      "Average test loss:  0.683244864612916\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.91375\n",
      "Average test accuracy:  0.6975\n",
      "\n",
      "Average train loss:  0.6410942795116241\n",
      "Average test loss:  0.6753696644492888\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.930625\n",
      "Average test accuracy:  0.71375\n",
      "\n",
      "Average train loss:  0.6037796036405074\n",
      "Average test loss:  0.6625981590633444\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.938125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.550276407526077\n",
      "Average test loss:  0.6441606322003669\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.48516393002961583\n",
      "Average test loss:  0.6215223419109613\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.4172020171068101\n",
      "Average test loss:  0.598418424909602\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.35406596539396423\n",
      "Average test loss:  0.5776153272879466\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.29951901087100824\n",
      "Average test loss:  0.5612650672976919\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.2542102868082194\n",
      "Average test loss:  0.5493499268075704\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2171468334655754\n",
      "Average test loss:  0.5419088962543759\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.18688671328318543\n",
      "Average test loss:  0.5382009795480726\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1620772811051573\n",
      "Average test loss:  0.5370011158964965\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.9825\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.14161136140656608\n",
      "Average test loss:  0.5386159225516046\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.12459207414132188\n",
      "Average test loss:  0.5416921181144615\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.1103176414042919\n",
      "Average test loss:  0.5467765161342634\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.09823959663034916\n",
      "Average test loss:  0.5531461861157521\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.08794365277243232\n",
      "Average test loss:  0.5601796002867871\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07911628259374087\n",
      "Average test loss:  0.5681086330844058\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.07149138497870895\n",
      "Average test loss:  0.5771416862551185\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.06486396746233741\n",
      "Average test loss:  0.5866083907607171\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.05908882568209656\n",
      "Average test loss:  0.5963551304459961\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.054027176282913175\n",
      "Average test loss:  0.6061262119355896\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04957959828803726\n",
      "Average test loss:  0.6163063028571644\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04564830895783605\n",
      "Average test loss:  0.6266880778540131\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.042165584007153735\n",
      "Average test loss:  0.6371271061137179\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.03906812738214891\n",
      "Average test loss:  0.6475330503189177\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6918167103862122\n",
      "Average test loss:  0.6927432509652989\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.75375\n",
      "Average test accuracy:  0.55\n",
      "\n",
      "Average train loss:  0.6892028580907158\n",
      "Average test loss:  0.691771861635726\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.835\n",
      "Average test accuracy:  0.5875\n",
      "\n",
      "Average train loss:  0.6837530602770155\n",
      "Average test loss:  0.6899122606567337\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.879375\n",
      "Average test accuracy:  0.62625\n",
      "\n",
      "Average train loss:  0.6711176722305021\n",
      "Average test loss:  0.6856207102930557\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.898125\n",
      "Average test accuracy:  0.67\n",
      "\n",
      "Average train loss:  0.6430211111403513\n",
      "Average test loss:  0.676116938340301\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9275\n",
      "Average test accuracy:  0.70875\n",
      "\n",
      "Average train loss:  0.5898807311967144\n",
      "Average test loss:  0.6580275860434766\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.5137216111384003\n",
      "Average test loss:  0.6320458118806146\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.4294960413834388\n",
      "Average test loss:  0.6035682768048244\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3526171440065835\n",
      "Average test loss:  0.5788143161018411\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.75875\n",
      "\n",
      "Average train loss:  0.2893675145613085\n",
      "Average test loss:  0.5607263359480306\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.23934589115094793\n",
      "Average test loss:  0.5486315506212822\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.20013460125140195\n",
      "Average test loss:  0.5424090608579638\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.16928295787711697\n",
      "Average test loss:  0.5400350656752538\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.14473557788387012\n",
      "Average test loss:  0.5414453743568295\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.12494000500602907\n",
      "Average test loss:  0.545430015794706\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.10879326882019498\n",
      "Average test loss:  0.5513198606735742\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09547500470180809\n",
      "Average test loss:  0.5587373112045825\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08437571008442157\n",
      "Average test loss:  0.5673037421998427\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.07504435199452361\n",
      "Average test loss:  0.5770992675737782\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06712160053286316\n",
      "Average test loss:  0.5873645506165999\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06036706859933532\n",
      "Average test loss:  0.5980226820165103\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.05457928462286956\n",
      "Average test loss:  0.6095126060267796\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.049571676635969925\n",
      "Average test loss:  0.6210521307155091\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.045233703005404025\n",
      "Average test loss:  0.6330041852967976\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.04144836042989588\n",
      "Average test loss:  0.6444460443515688\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.03812558154251706\n",
      "Average test loss:  0.656176925780231\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.03520723074405877\n",
      "Average test loss:  0.6680293520438778\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.03261414535980648\n",
      "Average test loss:  0.6799625158018424\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.030301298094808055\n",
      "Average test loss:  0.6915531308131889\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.028220013498559907\n",
      "Average test loss:  0.7032094967367518\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7199897587990577\n",
      "Average test loss:  0.7211405417198941\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6936559462592994\n",
      "Average test loss:  0.6964832630704079\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6853608083526818\n",
      "Average test loss:  0.6906184690010675\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.915625\n",
      "Average test accuracy:  0.71125\n",
      "\n",
      "Average train loss:  0.6793534489598904\n",
      "Average test loss:  0.6882196096554273\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.92625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.670584781634433\n",
      "Average test loss:  0.6851966223201877\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6558137218229185\n",
      "Average test loss:  0.6800824986884147\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.94375\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.6298732344611628\n",
      "Average test loss:  0.6710066473174652\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.5855988898814303\n",
      "Average test loss:  0.6553133873987712\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.5209224352793181\n",
      "Average test loss:  0.6320459811901836\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.4450123080871953\n",
      "Average test loss:  0.6048659860839932\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.37098776693628793\n",
      "Average test loss:  0.5790726543525578\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.30702890583189885\n",
      "Average test loss:  0.5584533396959248\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.25506798456396307\n",
      "Average test loss:  0.5439530469106743\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.2137649623203345\n",
      "Average test loss:  0.5350273387680532\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.18101579277989233\n",
      "Average test loss:  0.530810469844977\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.15485930335058676\n",
      "Average test loss:  0.5304330937030964\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13374231607803125\n",
      "Average test loss:  0.5328774263829225\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.11651641823662033\n",
      "Average test loss:  0.5371570817583817\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.10230624383621074\n",
      "Average test loss:  0.5439578793771127\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.09046837760592302\n",
      "Average test loss:  0.5513013887227868\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.08050226238646814\n",
      "Average test loss:  0.5602982904615451\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.07204248979649468\n",
      "Average test loss:  0.5700257103441494\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.715\n",
      "\n",
      "Average train loss:  0.06479253368550598\n",
      "Average test loss:  0.5804612132169897\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.715\n",
      "\n",
      "Average train loss:  0.05853393408466412\n",
      "Average test loss:  0.5914374315030992\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.053094517592980596\n",
      "Average test loss:  0.6027645491612985\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.71125\n",
      "\n",
      "Average train loss:  0.04834238964037385\n",
      "Average test loss:  0.6142738253573369\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.715\n",
      "\n",
      "Average train loss:  0.04415623829830063\n",
      "Average test loss:  0.6260070619996335\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.04046892670807549\n",
      "Average test loss:  0.6379612508667628\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.037202443432802684\n",
      "Average test loss:  0.6501729535930916\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.0343058082580519\n",
      "Average test loss:  0.6619906157783827\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.695900613523127\n",
      "Average test loss:  0.6968103832441624\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6898746812555432\n",
      "Average test loss:  0.6920678889327515\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.93375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6860957664894421\n",
      "Average test loss:  0.6907157742441731\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6778671994827526\n",
      "Average test loss:  0.6878402901370079\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6592544758552611\n",
      "Average test loss:  0.6813172223251779\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9475\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.6202074492759292\n",
      "Average test loss:  0.667558245249748\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9475\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.5514004457848364\n",
      "Average test loss:  0.6433760466197515\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.4597478046809085\n",
      "Average test loss:  0.6114789939082761\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.3682810121285161\n",
      "Average test loss:  0.5809617837277803\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.292371386233705\n",
      "Average test loss:  0.5582382780259921\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.23430269161141157\n",
      "Average test loss:  0.544565887469775\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.19068998875050625\n",
      "Average test loss:  0.5377729317909448\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.15765480158031409\n",
      "Average test loss:  0.5364912649184403\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1322448094722661\n",
      "Average test loss:  0.5395216980649952\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.11237842056386803\n",
      "Average test loss:  0.5453232409031838\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09656571169984973\n",
      "Average test loss:  0.5535528199172645\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08380152196482726\n",
      "Average test loss:  0.5630090493144211\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07334187087341809\n",
      "Average test loss:  0.5740719652498777\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06468531573638836\n",
      "Average test loss:  0.58583656936354\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.05744172571679138\n",
      "Average test loss:  0.5981577094360039\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.05133841408430262\n",
      "Average test loss:  0.6110428626460762\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.04613809473475772\n",
      "Average test loss:  0.6243296268690436\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.04169365288764803\n",
      "Average test loss:  0.6377221077846723\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.03785312032543051\n",
      "Average test loss:  0.6512194337404358\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.034519795366339846\n",
      "Average test loss:  0.66459749421209\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.03159650005690943\n",
      "Average test loss:  0.6780428986105099\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.029008496732677993\n",
      "Average test loss:  0.6911625441721018\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.02669887389792758\n",
      "Average test loss:  0.7046344009282537\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.024616483523390548\n",
      "Average test loss:  0.7179287646700366\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.022740527938489297\n",
      "Average test loss:  0.7311779103461497\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6920253672860412\n",
      "Average test loss:  0.6928200038858435\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.875\n",
      "Average test accuracy:  0.68625\n",
      "\n",
      "Average train loss:  0.6897485703279015\n",
      "Average test loss:  0.6919563119370489\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.6841038050452477\n",
      "Average test loss:  0.6900066932672235\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6689247942413576\n",
      "Average test loss:  0.6847367171944042\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.6318538181291125\n",
      "Average test loss:  0.6718471637136054\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.94125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5584036541864555\n",
      "Average test loss:  0.6462991916380926\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.45652068019754516\n",
      "Average test loss:  0.6112158397937616\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3569593880603798\n",
      "Average test loss:  0.5788805401459943\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.2778264859468702\n",
      "Average test loss:  0.556029680340202\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.21946637096823626\n",
      "Average test loss:  0.5434788907454617\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.17676560446687176\n",
      "Average test loss:  0.5388575473895557\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1450197278953088\n",
      "Average test loss:  0.5397237831699832\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9825\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.12091043911534383\n",
      "Average test loss:  0.5444102783259377\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.1022205817104591\n",
      "Average test loss:  0.5518704969803979\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.0874602160708668\n",
      "Average test loss:  0.5615966786726712\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.07560435563244929\n",
      "Average test loss:  0.5729593785362641\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0659690864338779\n",
      "Average test loss:  0.5853400416145176\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.05803199982740437\n",
      "Average test loss:  0.5983175660433195\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.05141382454199766\n",
      "Average test loss:  0.6124543917829948\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.045849728130832\n",
      "Average test loss:  0.6261999231915945\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04113385275868511\n",
      "Average test loss:  0.6406129476337978\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.03709683714610456\n",
      "Average test loss:  0.6551389519952058\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.03360867238833599\n",
      "Average test loss:  0.6693428137852515\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.03056604885467597\n",
      "Average test loss:  0.6837226162762119\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.027890583684648\n",
      "Average test loss:  0.6979330773987864\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.02551578583811262\n",
      "Average test loss:  0.7125869904978818\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.02339884099790172\n",
      "Average test loss:  0.7268669190148133\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.021516754926041007\n",
      "Average test loss:  0.7405443008925654\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.019843773093454555\n",
      "Average test loss:  0.7548701829724344\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.018365445331963885\n",
      "Average test loss:  0.7681981276438771\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6953554627873727\n",
      "Average test loss:  0.6966225717307056\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.76125\n",
      "Average test accuracy:  0.57375\n",
      "\n",
      "Average train loss:  0.6876048127938041\n",
      "Average test loss:  0.6911669604740996\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.860625\n",
      "Average test accuracy:  0.65375\n",
      "\n",
      "Average train loss:  0.6822888388815608\n",
      "Average test loss:  0.6893469073107656\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.8925\n",
      "Average test accuracy:  0.67875\n",
      "\n",
      "Average train loss:  0.6729082565894012\n",
      "Average test loss:  0.6861483038465673\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.919375\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.6555950917710269\n",
      "Average test loss:  0.6802215603172524\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.623971429322758\n",
      "Average test loss:  0.6693409601096314\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5699751954721795\n",
      "Average test loss:  0.650573519304333\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.945625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.4918832336783289\n",
      "Average test loss:  0.6232506892512995\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.40283484472032566\n",
      "Average test loss:  0.5928252484897952\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.958125\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3212592173895202\n",
      "Average test loss:  0.5666742248306585\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.2559917316347764\n",
      "Average test loss:  0.5490090119682534\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.2064274808306186\n",
      "Average test loss:  0.5392947978240673\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.16909858701791047\n",
      "Average test loss:  0.5353155750411318\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.14067755062190762\n",
      "Average test loss:  0.5365150340979478\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.11867623406324697\n",
      "Average test loss:  0.5411000151681132\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10133308657822071\n",
      "Average test loss:  0.5484537844982406\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08745355105468815\n",
      "Average test loss:  0.5570819285415202\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.0761822880009884\n",
      "Average test loss:  0.5681186094906567\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.066890429040578\n",
      "Average test loss:  0.5794077090635327\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.05916138791579834\n",
      "Average test loss:  0.5916891377504516\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.05267051248572389\n",
      "Average test loss:  0.6045869376241552\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.04714978179203281\n",
      "Average test loss:  0.6178026481817396\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.0424440064059974\n",
      "Average test loss:  0.6312810375136692\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.03838483506841822\n",
      "Average test loss:  0.6450830918350262\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.034879196590615676\n",
      "Average test loss:  0.6589049966749464\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.031820890102340425\n",
      "Average test loss:  0.6729357948435543\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.029143774152302824\n",
      "Average test loss:  0.6865468007564791\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.02678943141937162\n",
      "Average test loss:  0.7000434344985988\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.02470475547378644\n",
      "Average test loss:  0.7137860819153666\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.0228477906045836\n",
      "Average test loss:  0.7274409005633582\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5025\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6915995703844285\n",
      "Average test loss:  0.6926071812187112\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.866875\n",
      "Average test accuracy:  0.63375\n",
      "\n",
      "Average train loss:  0.6873639328516328\n",
      "Average test loss:  0.6911411642823159\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.91625\n",
      "Average test accuracy:  0.7075\n",
      "\n",
      "Average train loss:  0.6755541759167935\n",
      "Average test loss:  0.6870620742963128\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.929375\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.6488219510981034\n",
      "Average test loss:  0.6778363387323325\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.5953513249188882\n",
      "Average test loss:  0.6593061888959592\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.945625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.5091907774165046\n",
      "Average test loss:  0.6295695987120499\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.4064290519910149\n",
      "Average test loss:  0.5955111186227103\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.31386217216655504\n",
      "Average test loss:  0.5665176583494755\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.24282219117445794\n",
      "Average test loss:  0.5494640444029378\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.19112167473092703\n",
      "Average test loss:  0.5415698784416692\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.15346817788010902\n",
      "Average test loss:  0.5399848129742649\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1255943256042847\n",
      "Average test loss:  0.5443546438320911\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10450025921995172\n",
      "Average test loss:  0.5519894255968234\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.0882189838294808\n",
      "Average test loss:  0.5622408923539647\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.07537949721398324\n",
      "Average test loss:  0.5741968580722875\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06510671067591743\n",
      "Average test loss:  0.5876213595164376\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.05675284487797555\n",
      "Average test loss:  0.6013505021387885\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.04987778236245613\n",
      "Average test loss:  0.6164813859058719\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.044148850964295334\n",
      "Average test loss:  0.6316716512474025\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.03933986403168457\n",
      "Average test loss:  0.6471084310688108\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.03524564144341356\n",
      "Average test loss:  0.6624543067675358\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.03173523478538104\n",
      "Average test loss:  0.6785622788340904\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.028684377659557638\n",
      "Average test loss:  0.6937068021171827\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.026029852669324866\n",
      "Average test loss:  0.7092917479408491\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.023689417117100712\n",
      "Average test loss:  0.7246614462304155\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.02164200236210882\n",
      "Average test loss:  0.7397338112348898\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.019840062990286757\n",
      "Average test loss:  0.7555415345291255\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.01825653957740977\n",
      "Average test loss:  0.7701403071503515\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.0168617847393158\n",
      "Average test loss:  0.7846985408347363\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.015622507237109557\n",
      "Average test loss:  0.7994987147778194\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7335402110742875\n",
      "Average test loss:  0.7342555737091961\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7099042742331543\n",
      "Average test loss:  0.7114781505995315\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6970628222995038\n",
      "Average test loss:  0.6996641665305803\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6902828765805907\n",
      "Average test loss:  0.6941157736890112\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6857267642135456\n",
      "Average test loss:  0.6912740684435125\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6808894529686018\n",
      "Average test loss:  0.6891250922970754\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.71875\n",
      "Average test accuracy:  0.515\n",
      "\n",
      "Average train loss:  0.6735012238083491\n",
      "Average test loss:  0.6863481666390935\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.870625\n",
      "Average test accuracy:  0.62625\n",
      "\n",
      "Average train loss:  0.6606931563080977\n",
      "Average test loss:  0.6817144235250368\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.91375\n",
      "Average test accuracy:  0.7025\n",
      "\n",
      "Average train loss:  0.6398495940394283\n",
      "Average test loss:  0.6741543371266419\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.6098118340457338\n",
      "Average test loss:  0.6630882130221486\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.5711997450458518\n",
      "Average test loss:  0.6486656446675435\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5268390541711728\n",
      "Average test loss:  0.6318931250241795\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.48081703502622347\n",
      "Average test loss:  0.6145204644341388\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.43655756523424577\n",
      "Average test loss:  0.5979834719851526\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3959402537530799\n",
      "Average test loss:  0.5831897577308686\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.3596181520643517\n",
      "Average test loss:  0.5704305936803821\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3274921860521764\n",
      "Average test loss:  0.5598403567921676\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.29920490939313416\n",
      "Average test loss:  0.5514304450084836\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.27427452048697915\n",
      "Average test loss:  0.5448764926146467\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.2522440913895722\n",
      "Average test loss:  0.5399673280398899\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.23271722641105227\n",
      "Average test loss:  0.5364328701872515\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2153426076556261\n",
      "Average test loss:  0.5342755767635793\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.19982462749664767\n",
      "Average test loss:  0.5331420474109718\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.18590963358329726\n",
      "Average test loss:  0.533136454464796\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.17338630602065228\n",
      "Average test loss:  0.5338882177064598\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.16207221985857198\n",
      "Average test loss:  0.535450389180717\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.15180537341732828\n",
      "Average test loss:  0.5376545742548455\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.1424716278090877\n",
      "Average test loss:  0.5402890548517175\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.13396776927311205\n",
      "Average test loss:  0.5436991401369288\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.12620307834636155\n",
      "Average test loss:  0.5474384976883776\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6940456856720282\n",
      "Average test loss:  0.6958720390897226\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6868842011172281\n",
      "Average test loss:  0.6911443348996813\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6816050739414411\n",
      "Average test loss:  0.6891614529329123\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.91\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.67374194744378\n",
      "Average test loss:  0.6863872662900014\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.915625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.660852043043972\n",
      "Average test loss:  0.6818143503600863\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.6397017895764491\n",
      "Average test loss:  0.6742504054223261\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.607469824770131\n",
      "Average test loss:  0.6626550772857023\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.5636501239136371\n",
      "Average test loss:  0.646756843592127\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5116538625530033\n",
      "Average test loss:  0.6278718238957048\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.4569878584841061\n",
      "Average test loss:  0.6081311491262148\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.40451350594294944\n",
      "Average test loss:  0.5895350693002706\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.966875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.35685999082653524\n",
      "Average test loss:  0.5733491153604894\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.31499317731447934\n",
      "Average test loss:  0.5600292642222269\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2787849048169551\n",
      "Average test loss:  0.5495288650202723\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.2476878032273111\n",
      "Average test loss:  0.5420642404171515\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.22099566736095347\n",
      "Average test loss:  0.5367583167117675\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1980404523928517\n",
      "Average test loss:  0.5336337465349753\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.17821258088551126\n",
      "Average test loss:  0.5323232347511637\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.16103275958514074\n",
      "Average test loss:  0.5326794342554236\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.14608294375240818\n",
      "Average test loss:  0.534312914621177\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.13303171712632852\n",
      "Average test loss:  0.5371753653383903\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.12155782973228042\n",
      "Average test loss:  0.540867030729732\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.11143835309003745\n",
      "Average test loss:  0.5455179371536233\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.1024731574276977\n",
      "Average test loss:  0.5508200250860007\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09450824289127265\n",
      "Average test loss:  0.5566913988198484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08739556543992917\n",
      "Average test loss:  0.5632182046939381\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.081032666781797\n",
      "Average test loss:  0.5701380550305051\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07530904298533345\n",
      "Average test loss:  0.5775082301142515\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.07014788507247023\n",
      "Average test loss:  0.5851777487331374\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.06547052078960436\n",
      "Average test loss:  0.5930599139640375\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.915\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.6915737658731542\n",
      "Average test loss:  0.6926066240590013\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.88625\n",
      "Average test accuracy:  0.69375\n",
      "\n",
      "Average train loss:  0.6884739665589872\n",
      "Average test loss:  0.6915385387063432\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.92125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.6811604153421064\n",
      "Average test loss:  0.6890139910604294\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.92625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.6645661220008122\n",
      "Average test loss:  0.6832528143940032\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6304496941585935\n",
      "Average test loss:  0.6712872223770967\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5723958772661022\n",
      "Average test loss:  0.6506523949895899\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.4984697022952756\n",
      "Average test loss:  0.6244473659003306\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.42401317640825353\n",
      "Average test loss:  0.5984214680385285\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.3579957486452036\n",
      "Average test loss:  0.5760802388997747\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3029276883022508\n",
      "Average test loss:  0.5591552348226233\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2580092966746387\n",
      "Average test loss:  0.5471876020839155\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.22153393432145874\n",
      "Average test loss:  0.5394246180984159\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.19175347879762727\n",
      "Average test loss:  0.5354117206981205\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1672978187869942\n",
      "Average test loss:  0.5341808672045976\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.14702963973649918\n",
      "Average test loss:  0.5354318578033098\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.13008177477548555\n",
      "Average test loss:  0.5385779263164813\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.11578829542747714\n",
      "Average test loss:  0.54345035308614\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.10364010702287187\n",
      "Average test loss:  0.5493267576657909\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.09323953619047821\n",
      "Average test loss:  0.5564596286622427\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.08427641312581725\n",
      "Average test loss:  0.5642257190012393\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07649909679724376\n",
      "Average test loss:  0.5729633994800526\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.06972266970525774\n",
      "Average test loss:  0.5822692834956457\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06377187085910564\n",
      "Average test loss:  0.5916019878162438\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.058548742798739395\n",
      "Average test loss:  0.6016214059769165\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.05393427574378027\n",
      "Average test loss:  0.6115831777151317\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04984892793588467\n",
      "Average test loss:  0.6217188416902096\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.046214972574903944\n",
      "Average test loss:  0.6318176858483642\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.042973005155103085\n",
      "Average test loss:  0.6419758835610135\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04006868840002376\n",
      "Average test loss:  0.6523997283071273\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.03744707855507479\n",
      "Average test loss:  0.6624345782316596\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6919317933135147\n",
      "Average test loss:  0.6927973498373107\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.81375\n",
      "Average test accuracy:  0.62375\n",
      "\n",
      "Average train loss:  0.68946035288459\n",
      "Average test loss:  0.6918619819653345\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.80375\n",
      "Average test accuracy:  0.61875\n",
      "\n",
      "Average train loss:  0.6838346513822197\n",
      "Average test loss:  0.689923098528836\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.854375\n",
      "Average test accuracy:  0.655\n",
      "\n",
      "Average train loss:  0.6709708625046039\n",
      "Average test loss:  0.6854612265269511\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.89\n",
      "Average test accuracy:  0.6875\n",
      "\n",
      "Average train loss:  0.6449989013548434\n",
      "Average test loss:  0.676367435140746\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.91125\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.600596074574383\n",
      "Average test loss:  0.6605801214570665\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.5384868442935993\n",
      "Average test loss:  0.6381686229502775\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.46736436661573105\n",
      "Average test loss:  0.6124547612361929\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.3978550471676347\n",
      "Average test loss:  0.5877322096424987\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.3363158384638069\n",
      "Average test loss:  0.5668987529000509\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.28462027639474513\n",
      "Average test loss:  0.5511413643912292\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.24225417496089863\n",
      "Average test loss:  0.5403637333352982\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2078036338482506\n",
      "Average test loss:  0.5337404086413248\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1796840440809598\n",
      "Average test loss:  0.5308576492548897\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1565865019457154\n",
      "Average test loss:  0.5307671667183774\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.13745440497677788\n",
      "Average test loss:  0.5331493122758026\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.12148936873863649\n",
      "Average test loss:  0.5373778566599127\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.10805328454288608\n",
      "Average test loss:  0.5431080482435935\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.09665978771884741\n",
      "Average test loss:  0.5500596533924904\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.08690700929770002\n",
      "Average test loss:  0.5580924591180213\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.0785072445064836\n",
      "Average test loss:  0.566687048443371\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.07121966517958543\n",
      "Average test loss:  0.5759859481451978\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.0648546413984611\n",
      "Average test loss:  0.585926182275929\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.05925627849222434\n",
      "Average test loss:  0.5963457541508151\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.05430014143113201\n",
      "Average test loss:  0.6070579370997818\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04989662147939088\n",
      "Average test loss:  0.6179864935854971\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.04596244564647437\n",
      "Average test loss:  0.6291292321376379\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.04244335379276854\n",
      "Average test loss:  0.6404989508727783\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.03929865280142784\n",
      "Average test loss:  0.6518486766570016\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.036483002617186094\n",
      "Average test loss:  0.6631616406542437\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.928125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.6913238313058799\n",
      "Average test loss:  0.6925074814737401\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.9275\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.6875957501819339\n",
      "Average test loss:  0.691213939715633\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6781476521854767\n",
      "Average test loss:  0.6879194361607953\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6561035977515391\n",
      "Average test loss:  0.6802269445601747\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6107865453206287\n",
      "Average test loss:  0.6644076139959569\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5366411500994487\n",
      "Average test loss:  0.6384677508780477\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.4475556202172464\n",
      "Average test loss:  0.6076764445570417\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.3637056657673463\n",
      "Average test loss:  0.579876037209128\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.29455085679496656\n",
      "Average test loss:  0.5591096016447001\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.24055368326203422\n",
      "Average test loss:  0.545943305356987\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.19885886535906672\n",
      "Average test loss:  0.5388923157069464\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.16651838222384466\n",
      "Average test loss:  0.5364117148229558\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1411403203926507\n",
      "Average test loss:  0.5376759448665839\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.12089857515239649\n",
      "Average test loss:  0.5419561524571999\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.10457850222280052\n",
      "Average test loss:  0.5485801885583065\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09124906948228269\n",
      "Average test loss:  0.5568786430308345\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08023917939148717\n",
      "Average test loss:  0.5662620211741523\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07103944914365036\n",
      "Average test loss:  0.5766947992130937\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.0633011865452514\n",
      "Average test loss:  0.5877517341356421\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.05673315736874581\n",
      "Average test loss:  0.5997355214189873\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.051122268657103176\n",
      "Average test loss:  0.6116116160721065\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.046296920016444504\n",
      "Average test loss:  0.623922093610897\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04211658925802788\n",
      "Average test loss:  0.6363440415447031\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.038478148094302306\n",
      "Average test loss:  0.6489277880026075\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.03528548700641685\n",
      "Average test loss:  0.6612159711004072\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.032454991671878736\n",
      "Average test loss:  0.6740288317560985\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.029927098531047674\n",
      "Average test loss:  0.686293763472204\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.02764937899642708\n",
      "Average test loss:  0.6991727308006018\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.025585981754722754\n",
      "Average test loss:  0.7114287654136081\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.023724618070369585\n",
      "Average test loss:  0.7238992158979157\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.500625\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6914886164400813\n",
      "Average test loss:  0.6925678344672974\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.85\n",
      "Average test accuracy:  0.655\n",
      "\n",
      "Average train loss:  0.688079971202125\n",
      "Average test loss:  0.6913802991965529\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.8775\n",
      "Average test accuracy:  0.68125\n",
      "\n",
      "Average train loss:  0.6795278242217128\n",
      "Average test loss:  0.6884116229792565\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.911875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.6602168355112612\n",
      "Average test loss:  0.6816600919266348\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.9225\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.622880867602246\n",
      "Average test loss:  0.6685121993927404\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.938125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.5625866563395016\n",
      "Average test loss:  0.6470673395003307\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.48363118779114894\n",
      "Average test loss:  0.6190272266641171\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.40080362362474986\n",
      "Average test loss:  0.5902008775942776\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3269016894777507\n",
      "Average test loss:  0.5661102411059448\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.26670665045134667\n",
      "Average test loss:  0.5489804578191249\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.21947867035799076\n",
      "Average test loss:  0.5385483945420679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.18270403279181371\n",
      "Average test loss:  0.5335583526510603\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.15390180412155383\n",
      "Average test loss:  0.533168997542737\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.13108752388598374\n",
      "Average test loss:  0.5360283826697482\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.11280996889514257\n",
      "Average test loss:  0.5414765072115602\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.09795737673758707\n",
      "Average test loss:  0.5489955127920224\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.08574986143668406\n",
      "Average test loss:  0.5577992609120307\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07561038609041151\n",
      "Average test loss:  0.5680188822220841\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06709530521966861\n",
      "Average test loss:  0.5790572016051064\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.059879211647326125\n",
      "Average test loss:  0.5909222202006098\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.053709149882402905\n",
      "Average test loss:  0.6031590035290043\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.04839860625634282\n",
      "Average test loss:  0.6158924228422772\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.04379667621887091\n",
      "Average test loss:  0.6287853736420311\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.03979093461301095\n",
      "Average test loss:  0.6418488149152193\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.036298229477011584\n",
      "Average test loss:  0.6553153880602102\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.033229089331623336\n",
      "Average test loss:  0.6683441647866956\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.03054145459890124\n",
      "Average test loss:  0.6816037232737729\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.028166448520918697\n",
      "Average test loss:  0.694600735061945\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.026063529085832978\n",
      "Average test loss:  0.7077074291660009\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.02419135991029649\n",
      "Average test loss:  0.7205031041627867\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6958792686437079\n",
      "Average test loss:  0.6966941217581786\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.50375\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6893953627386304\n",
      "Average test loss:  0.6919081117336553\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.845\n",
      "Average test accuracy:  0.655\n",
      "\n",
      "Average train loss:  0.684790724434618\n",
      "Average test loss:  0.6902811041661602\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.895625\n",
      "Average test accuracy:  0.70375\n",
      "\n",
      "Average train loss:  0.6756917645887665\n",
      "Average test loss:  0.6871082782177793\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6572623206908519\n",
      "Average test loss:  0.680637505224631\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.621117088976134\n",
      "Average test loss:  0.6679480608833274\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.5582291073306974\n",
      "Average test loss:  0.6460585369414696\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.47300816602732737\n",
      "Average test loss:  0.6171885234550497\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.3850422684517451\n",
      "Average test loss:  0.5887045381600075\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.30961894671764423\n",
      "Average test loss:  0.566824369990953\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.25041681311707004\n",
      "Average test loss:  0.5525336677934402\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.20513854750538527\n",
      "Average test loss:  0.5456584544631101\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.170471093524972\n",
      "Average test loss:  0.5433778645025212\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1435926822832003\n",
      "Average test loss:  0.5456351230784159\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.12243021241037043\n",
      "Average test loss:  0.5506680608103851\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1055004455083461\n",
      "Average test loss:  0.5583080906201935\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09177426231291601\n",
      "Average test loss:  0.5673561801012323\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08049693741629128\n",
      "Average test loss:  0.5776992057726348\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.07114601001132721\n",
      "Average test loss:  0.5895322380184628\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.06330109308186449\n",
      "Average test loss:  0.6007824243841782\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.05668074062519681\n",
      "Average test loss:  0.6134086716009651\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.051040721755469275\n",
      "Average test loss:  0.6261273245894686\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.046206027874005566\n",
      "Average test loss:  0.6387535885180068\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.042032195514858706\n",
      "Average test loss:  0.6521755192045873\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.038403951875155766\n",
      "Average test loss:  0.6650798772574392\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.035227282363897404\n",
      "Average test loss:  0.6779428463596758\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.03243177024398037\n",
      "Average test loss:  0.6910330668353892\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.029945009111273447\n",
      "Average test loss:  0.7037751040393859\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.027733079932461924\n",
      "Average test loss:  0.7162957669300382\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.02575149625081215\n",
      "Average test loss:  0.7290960668595198\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.553125\n",
      "Average test accuracy:  0.50125\n",
      "\n",
      "Average train loss:  0.691283175144168\n",
      "Average test loss:  0.6924864381356176\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.854375\n",
      "Average test accuracy:  0.605\n",
      "\n",
      "Average train loss:  0.6874952944967476\n",
      "Average test loss:  0.6911806936442488\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.9225\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.6774336842895486\n",
      "Average test loss:  0.6877057259202563\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.6499130227825641\n",
      "Average test loss:  0.6781567291708192\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.5866985389892677\n",
      "Average test loss:  0.6561778435622158\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.48560927041813207\n",
      "Average test loss:  0.621033839784971\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.3784885506564648\n",
      "Average test loss:  0.5851721343729087\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2911996356068102\n",
      "Average test loss:  0.5588148806271919\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.22699031364723873\n",
      "Average test loss:  0.5433348053070963\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.18057433689849656\n",
      "Average test loss:  0.5371506059813187\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1465419820887796\n",
      "Average test loss:  0.5370115414364648\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1210210549734952\n",
      "Average test loss:  0.5411250551081438\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.10147161621257256\n",
      "Average test loss:  0.5493286746384423\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.08620124724111455\n",
      "Average test loss:  0.5592725425132555\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07405375667644548\n",
      "Average test loss:  0.5710493859774574\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.06424710722696968\n",
      "Average test loss:  0.584201647963021\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.056217023565875095\n",
      "Average test loss:  0.598125197431264\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.049569175635509756\n",
      "Average test loss:  0.612219371517802\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.04400961155250038\n",
      "Average test loss:  0.6269408947496125\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.0393155768215564\n",
      "Average test loss:  0.6418514280783555\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.03531069808976887\n",
      "Average test loss:  0.6570454999333856\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.0318784871586778\n",
      "Average test loss:  0.6722355048960704\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.02890657392950535\n",
      "Average test loss:  0.6873426455278498\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.02631835329016999\n",
      "Average test loss:  0.7022011982291025\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.024044050310584954\n",
      "Average test loss:  0.7172164238536705\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.022030904412094297\n",
      "Average test loss:  0.7319761573001832\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.020243016170139464\n",
      "Average test loss:  0.7467586405763962\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.01864758601938239\n",
      "Average test loss:  0.7610185996962778\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.01723488241223836\n",
      "Average test loss:  0.775470349825084\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.015985445649488825\n",
      "Average test loss:  0.7891998288177314\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.509375\n",
      "Average test accuracy:  0.50375\n",
      "\n",
      "Average train loss:  0.6914253669726342\n",
      "Average test loss:  0.6925578384660606\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.8825\n",
      "Average test accuracy:  0.6825\n",
      "\n",
      "Average train loss:  0.6872896118467299\n",
      "Average test loss:  0.6911247785667146\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6759321275507926\n",
      "Average test loss:  0.6871906402234947\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.9325\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.6464024351327019\n",
      "Average test loss:  0.6769886770064679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.5816793213415998\n",
      "Average test loss:  0.654637270484352\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.4813648067595639\n",
      "Average test loss:  0.6203117355784528\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.37499203543602794\n",
      "Average test loss:  0.5857586861571858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.28764011621357566\n",
      "Average test loss:  0.5603371036204066\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.22326166800556133\n",
      "Average test loss:  0.5460099499275912\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.17685103037597535\n",
      "Average test loss:  0.5411011429669951\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.14299274973394857\n",
      "Average test loss:  0.5425341953526814\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.11774666860142664\n",
      "Average test loss:  0.5475676639553638\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.0984874372255405\n",
      "Average test loss:  0.556581242562765\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.0835039571526461\n",
      "Average test loss:  0.5672850044543455\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.0716309792792549\n",
      "Average test loss:  0.5806184666517672\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.062069590116511995\n",
      "Average test loss:  0.5940863855120173\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.054267803193813774\n",
      "Average test loss:  0.608394563785985\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.04783837672733354\n",
      "Average test loss:  0.6231563615098329\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.042472823423716555\n",
      "Average test loss:  0.6385040023708303\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.037947124746889487\n",
      "Average test loss:  0.653744946719555\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.03408837198259906\n",
      "Average test loss:  0.66926526205896\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.030758932269886057\n",
      "Average test loss:  0.6847373562161678\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.027850976975715935\n",
      "Average test loss:  0.7000590104289198\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.02530408371885302\n",
      "Average test loss:  0.715074443509915\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.023063849666905462\n",
      "Average test loss:  0.7302942801952886\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.021102839807949105\n",
      "Average test loss:  0.7451667635406064\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.019379816853758492\n",
      "Average test loss:  0.7600528097682059\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.017877982253633132\n",
      "Average test loss:  0.774343361905196\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.016552557033204844\n",
      "Average test loss:  0.7890904051157737\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.01536661826735354\n",
      "Average test loss:  0.8029891720930533\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6912519037794077\n",
      "Average test loss:  0.6925319302671454\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.88875\n",
      "Average test accuracy:  0.69375\n",
      "\n",
      "Average train loss:  0.6874302335324783\n",
      "Average test loss:  0.6911809423763912\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6779434971939908\n",
      "Average test loss:  0.6878976478954981\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6561430527473301\n",
      "Average test loss:  0.6803355169277113\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6114808808118097\n",
      "Average test loss:  0.6648736958360743\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5350034988459923\n",
      "Average test loss:  0.6383603351526185\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.4344595627456947\n",
      "Average test loss:  0.6043773426805303\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.958125\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.335675748064404\n",
      "Average test loss:  0.5729846565113478\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.2567058075438094\n",
      "Average test loss:  0.5517933313354926\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.19917319496787925\n",
      "Average test loss:  0.5420283579026804\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.15793463712364433\n",
      "Average test loss:  0.5397974138744733\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1278539209124098\n",
      "Average test loss:  0.543392203502617\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.105448486365241\n",
      "Average test loss:  0.5514282570457325\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.0883829871865121\n",
      "Average test loss:  0.5622338740252583\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07506350239077297\n",
      "Average test loss:  0.5745603150239238\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.06451909284900927\n",
      "Average test loss:  0.5886538646074356\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.05601592678411218\n",
      "Average test loss:  0.603393643626538\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04907530870250578\n",
      "Average test loss:  0.6185001121778745\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.043332933137121575\n",
      "Average test loss:  0.634214147635567\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.038530776719670416\n",
      "Average test loss:  0.6502199755549339\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.0344822482635266\n",
      "Average test loss:  0.6659461982678896\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.03100992294554254\n",
      "Average test loss:  0.6821256397812894\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.02800508344813334\n",
      "Average test loss:  0.6983877582849822\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.025391538251479513\n",
      "Average test loss:  0.7137539743116198\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.02309356653030539\n",
      "Average test loss:  0.7293066543312611\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.021072077680939123\n",
      "Average test loss:  0.7450408313501254\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.019302474670905276\n",
      "Average test loss:  0.7603991267924686\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.017762347753020987\n",
      "Average test loss:  0.7754874897125147\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.016402256423568327\n",
      "Average test loss:  0.7903740215480743\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.015203642999840311\n",
      "Average test loss:  0.8051517038883564\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6914910619806794\n",
      "Average test loss:  0.6925894120241791\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.9225\n",
      "Average test accuracy:  0.7075\n",
      "\n",
      "Average train loss:  0.6886303122977422\n",
      "Average test loss:  0.6915957089803881\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.85125\n",
      "Average test accuracy:  0.6\n",
      "\n",
      "Average train loss:  0.6826684750570898\n",
      "Average test loss:  0.6895596619869439\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.85\n",
      "Average test accuracy:  0.60375\n",
      "\n",
      "Average train loss:  0.6707911010690722\n",
      "Average test loss:  0.6855160665220662\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.83875\n",
      "Average test accuracy:  0.58625\n",
      "\n",
      "Average train loss:  0.6495890290875966\n",
      "Average test loss:  0.6784972120111178\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.870625\n",
      "Average test accuracy:  0.62375\n",
      "\n",
      "Average train loss:  0.6167592556872411\n",
      "Average test loss:  0.6675866751491925\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.89625\n",
      "Average test accuracy:  0.6725\n",
      "\n",
      "Average train loss:  0.574300427060004\n",
      "Average test loss:  0.6533202237167278\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.92375\n",
      "Average test accuracy:  0.705\n",
      "\n",
      "Average train loss:  0.5269139823670596\n",
      "Average test loss:  0.637161052445558\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.715\n",
      "\n",
      "Average train loss:  0.47950607486074753\n",
      "Average test loss:  0.6209632187724067\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.4350560517180215\n",
      "Average test loss:  0.6059157910664476\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.39478571036704074\n",
      "Average test loss:  0.5924094932140894\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.966875\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.35891729538376543\n",
      "Average test loss:  0.580941015308284\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3271999045308578\n",
      "Average test loss:  0.5711490367639386\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2992220832446894\n",
      "Average test loss:  0.5634747493257851\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.2744888277440279\n",
      "Average test loss:  0.5571014923217072\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.2525871555196859\n",
      "Average test loss:  0.5529021593449074\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.23311465062103012\n",
      "Average test loss:  0.5496515409775329\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.21574278889488382\n",
      "Average test loss:  0.5478456169724653\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.2001926003353661\n",
      "Average test loss:  0.5471139914292463\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.18620834379771514\n",
      "Average test loss:  0.5472049251347643\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.1736092616097199\n",
      "Average test loss:  0.5483693596513115\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.16220215719593883\n",
      "Average test loss:  0.5499271029900815\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.15185042985981756\n",
      "Average test loss:  0.5524738983736037\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.1424217656647868\n",
      "Average test loss:  0.5554173568183365\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.1338085592786895\n",
      "Average test loss:  0.5590689664221662\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.1259221702448605\n",
      "Average test loss:  0.5633294303364688\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.11867223690381079\n",
      "Average test loss:  0.5676764458782503\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.11200806803648074\n",
      "Average test loss:  0.5724813428384721\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10587078026741753\n",
      "Average test loss:  0.5773151705031386\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10022112667860084\n",
      "Average test loss:  0.5825737783285364\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6953674930384669\n",
      "Average test loss:  0.6964238106065759\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6896069806311624\n",
      "Average test loss:  0.6921376869068597\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.921875\n",
      "Average test accuracy:  0.6975\n",
      "\n",
      "Average train loss:  0.6845995101171306\n",
      "Average test loss:  0.6902290009245918\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6745209472130173\n",
      "Average test loss:  0.6867122797285922\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.653417904187572\n",
      "Average test loss:  0.6793236286297697\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.6143996871492287\n",
      "Average test loss:  0.6655725166774457\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5560692855613165\n",
      "Average test loss:  0.6446989722500469\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.4877766635293179\n",
      "Average test loss:  0.6201709630176627\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.4209319554245922\n",
      "Average test loss:  0.5963244533502734\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3620859332520716\n",
      "Average test loss:  0.5758981695710466\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.31256954156252625\n",
      "Average test loss:  0.5596696100797346\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2715410543022794\n",
      "Average test loss:  0.5478134132749058\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.23753722662660523\n",
      "Average test loss:  0.5395616251356196\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2092261091318511\n",
      "Average test loss:  0.5341990167415339\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.185489390026931\n",
      "Average test loss:  0.5315983577187796\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.16544085661120578\n",
      "Average test loss:  0.531230149708258\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.14838418389953514\n",
      "Average test loss:  0.532486556071522\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.13376926126262476\n",
      "Average test loss:  0.535246907235611\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.1211446000877509\n",
      "Average test loss:  0.5392106981101552\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.11019022875022137\n",
      "Average test loss:  0.5441403053651099\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.1006075498505589\n",
      "Average test loss:  0.5500681454735273\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.09220563666627683\n",
      "Average test loss:  0.5564845110866727\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08478865541011377\n",
      "Average test loss:  0.5637439658041795\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07820732344442097\n",
      "Average test loss:  0.5713051442077398\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07234320904740711\n",
      "Average test loss:  0.5795860998589042\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06709288651453067\n",
      "Average test loss:  0.587865111767161\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06238022028144541\n",
      "Average test loss:  0.5963892165741734\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.058139799101159705\n",
      "Average test loss:  0.6053216872828976\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.0543195853431833\n",
      "Average test loss:  0.6141957627546114\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.05086698872877726\n",
      "Average test loss:  0.6230672055905048\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7089257613158457\n",
      "Average test loss:  0.7097506054152346\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.695142752836606\n",
      "Average test loss:  0.6967997604490588\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6895954773445615\n",
      "Average test loss:  0.692465935878969\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.501875\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6857397669098647\n",
      "Average test loss:  0.6905991564728088\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.834375\n",
      "Average test accuracy:  0.62875\n",
      "\n",
      "Average train loss:  0.6802510591970244\n",
      "Average test loss:  0.6886349604468679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.916875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.670058233326874\n",
      "Average test loss:  0.6850964587650434\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6505174470316154\n",
      "Average test loss:  0.6782406017227735\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6158477951960681\n",
      "Average test loss:  0.6658218014743144\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5635931698780713\n",
      "Average test loss:  0.646653672002342\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.4978635348219702\n",
      "Average test loss:  0.6221131791412996\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.4276697177107341\n",
      "Average test loss:  0.595926089620225\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.36326319044005234\n",
      "Average test loss:  0.5726124012170594\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.30918585657247627\n",
      "Average test loss:  0.5545302869167038\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2651172509862172\n",
      "Average test loss:  0.5415679303912753\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2292424633603982\n",
      "Average test loss:  0.5333249249912734\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.19987350894069736\n",
      "Average test loss:  0.5287224333308699\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.17562257458609223\n",
      "Average test loss:  0.5272332908470369\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.15541809290240577\n",
      "Average test loss:  0.5281181729906463\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.1384318092440395\n",
      "Average test loss:  0.5308722327780355\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.1240212841454688\n",
      "Average test loss:  0.5350599097330219\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.11171701525447364\n",
      "Average test loss:  0.5407677670607393\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.10113259152622821\n",
      "Average test loss:  0.5472486087218872\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.09196798168580189\n",
      "Average test loss:  0.5546761733545966\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.08398514142091355\n",
      "Average test loss:  0.5625255349845119\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07699924541113447\n",
      "Average test loss:  0.5710967840524631\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07084343440806294\n",
      "Average test loss:  0.5801579796669251\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06537908925069641\n",
      "Average test loss:  0.5894747047881929\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06050265973741937\n",
      "Average test loss:  0.5991574469919314\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.056125725188382485\n",
      "Average test loss:  0.6089705268770755\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.05216531556528109\n",
      "Average test loss:  0.6190224254491486\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6910146742102005\n",
      "Average test loss:  0.6925021428955432\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.928125\n",
      "Average test accuracy:  0.7125\n",
      "\n",
      "Average train loss:  0.6872475324971842\n",
      "Average test loss:  0.6910987681177464\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.931875\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.6794954839143451\n",
      "Average test loss:  0.6884033760333491\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.662494066925694\n",
      "Average test loss:  0.6824767630924705\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.6270175090632768\n",
      "Average test loss:  0.6700713361428509\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.5641748443727167\n",
      "Average test loss:  0.6480813904915246\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.4805825619641902\n",
      "Average test loss:  0.6190204061591668\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.39639543150027495\n",
      "Average test loss:  0.5904907429648082\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.3244361227659496\n",
      "Average test loss:  0.5678261913096109\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.26702219605495175\n",
      "Average test loss:  0.552439460806462\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2221903538285499\n",
      "Average test loss:  0.5426949794739727\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.1870774581518672\n",
      "Average test loss:  0.5382292127377872\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.1592907781789151\n",
      "Average test loss:  0.537553194055345\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.13703608140365053\n",
      "Average test loss:  0.5401899857307196\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1189729118589105\n",
      "Average test loss:  0.5446196258757073\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10414667707988723\n",
      "Average test loss:  0.5512385327913806\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.09184857785521605\n",
      "Average test loss:  0.5595087387507307\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08154557475985615\n",
      "Average test loss:  0.5686000281735324\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.07284403603512608\n",
      "Average test loss:  0.5786553313724765\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.06545101040207199\n",
      "Average test loss:  0.5889458760335005\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.05911317935705982\n",
      "Average test loss:  0.6001828867098541\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.05365579533798074\n",
      "Average test loss:  0.6116061367822163\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.0489363167500582\n",
      "Average test loss:  0.623196919684319\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.04482642387838285\n",
      "Average test loss:  0.6348769712441237\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.041235600761252496\n",
      "Average test loss:  0.64641594831993\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.038071786841870375\n",
      "Average test loss:  0.6580501077460846\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.035273914600514704\n",
      "Average test loss:  0.6697707189253216\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.03278200809777961\n",
      "Average test loss:  0.6813790568439712\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.030549499924589472\n",
      "Average test loss:  0.6927905052811861\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.028531856456265173\n",
      "Average test loss:  0.7045138825219657\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7557162832066756\n",
      "Average test loss:  0.7566795327591395\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7157233809841657\n",
      "Average test loss:  0.7176709237519899\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.696868014905939\n",
      "Average test loss:  0.6999699790585723\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6881448499433495\n",
      "Average test loss:  0.6928552692327671\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6825003020935778\n",
      "Average test loss:  0.6897019546548343\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.891875\n",
      "Average test accuracy:  0.61\n",
      "\n",
      "Average train loss:  0.6758225176242517\n",
      "Average test loss:  0.6870613357078511\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.6654425383991596\n",
      "Average test loss:  0.6832480487784386\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6482618746161947\n",
      "Average test loss:  0.6769817298793758\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.6189392291467796\n",
      "Average test loss:  0.666234070137871\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.5714068008084773\n",
      "Average test loss:  0.6488459499197197\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.5059727326617468\n",
      "Average test loss:  0.625109532720963\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.4324818401674866\n",
      "Average test loss:  0.5991869026891448\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.36243235527393675\n",
      "Average test loss:  0.5757976901571967\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.30238747596252713\n",
      "Average test loss:  0.5578373766913388\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.25344763751746835\n",
      "Average test loss:  0.5457056418327483\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.21429429376424078\n",
      "Average test loss:  0.5386748088813648\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.1829414545431579\n",
      "Average test loss:  0.5360055736776257\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.15767234458539509\n",
      "Average test loss:  0.53653738197146\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13712332121946155\n",
      "Average test loss:  0.539440062005467\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1202223503482474\n",
      "Average test loss:  0.5444121101933859\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.10617864036549896\n",
      "Average test loss:  0.5508581155177676\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.09441413847976188\n",
      "Average test loss:  0.558737603133766\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.08444882724221851\n",
      "Average test loss:  0.5674297940072858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.07595114534331973\n",
      "Average test loss:  0.5768214812617006\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.06864669712139704\n",
      "Average test loss:  0.5869297470618392\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.06232912025715403\n",
      "Average test loss:  0.597433739060214\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.056837825508581054\n",
      "Average test loss:  0.608037573129426\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.05204096554548502\n",
      "Average test loss:  0.6187480487078135\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.0478267529622499\n",
      "Average test loss:  0.629806759850393\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.04411934318728541\n",
      "Average test loss:  0.6409643566322187\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.838125\n",
      "Average test accuracy:  0.59625\n",
      "\n",
      "Average train loss:  0.6917728743400189\n",
      "Average test loss:  0.6926765020702725\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.905\n",
      "Average test accuracy:  0.69\n",
      "\n",
      "Average train loss:  0.6881151947527112\n",
      "Average test loss:  0.6914195631689447\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6768751819505531\n",
      "Average test loss:  0.6875254548424139\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6481608464349954\n",
      "Average test loss:  0.6775725909196709\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5889003807717891\n",
      "Average test loss:  0.6568095624496904\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.4997192344983438\n",
      "Average test loss:  0.6254490136131688\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.40202946174553017\n",
      "Average test loss:  0.5916172984188063\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.31764120549793357\n",
      "Average test loss:  0.5645080924110655\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.2523686959992195\n",
      "Average test loss:  0.5471927917711686\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.2035077436443907\n",
      "Average test loss:  0.5377149569256635\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.16684002807316403\n",
      "Average test loss:  0.5344417215249181\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.13883979795489212\n",
      "Average test loss:  0.5360596401247996\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.11710800085390465\n",
      "Average test loss:  0.5411015867622793\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.09997360613204163\n",
      "Average test loss:  0.5489450445997828\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08625063025091458\n",
      "Average test loss:  0.5583191763072904\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07509364781552565\n",
      "Average test loss:  0.5696426705283861\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.06590778109981471\n",
      "Average test loss:  0.5815683622958145\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.058270637000906324\n",
      "Average test loss:  0.5947151763068038\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.05185280001267262\n",
      "Average test loss:  0.6078103370448199\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04642309562679628\n",
      "Average test loss:  0.6215421432784681\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04179658536741888\n",
      "Average test loss:  0.6353064646377088\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.0378123624282282\n",
      "Average test loss:  0.6490225078275004\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.03437016471251064\n",
      "Average test loss:  0.6632206749808661\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.031366404372192395\n",
      "Average test loss:  0.6766980368875104\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.028733454591823412\n",
      "Average test loss:  0.6905477857184726\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.026422521084349216\n",
      "Average test loss:  0.7042788587582162\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.024394160754176608\n",
      "Average test loss:  0.7176859482906094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.022595734807967695\n",
      "Average test loss:  0.7311024840957773\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.02099914133321634\n",
      "Average test loss:  0.7445425043041999\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.01955899031255347\n",
      "Average test loss:  0.7570662957098128\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6920322221833879\n",
      "Average test loss:  0.6928635524195511\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.79625\n",
      "Average test accuracy:  0.63125\n",
      "\n",
      "Average train loss:  0.6894354682138855\n",
      "Average test loss:  0.6918718361548987\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.88625\n",
      "Average test accuracy:  0.68125\n",
      "\n",
      "Average train loss:  0.6830841888069189\n",
      "Average test loss:  0.689659409809467\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.66563228128374\n",
      "Average test loss:  0.6835464544068929\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6232238020160973\n",
      "Average test loss:  0.668650168105307\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5444155419611202\n",
      "Average test loss:  0.641011880244628\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.44251766160454786\n",
      "Average test loss:  0.6061916162934095\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.3472837328325642\n",
      "Average test loss:  0.5757510453493858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.27238839409316146\n",
      "Average test loss:  0.5550351010319794\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.21672568226137687\n",
      "Average test loss:  0.544145263122028\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.17550113125990552\n",
      "Average test loss:  0.53997915452785\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.1445629488962997\n",
      "Average test loss:  0.5410564347752045\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.12091816273781135\n",
      "Average test loss:  0.5465620478152816\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10251273700568757\n",
      "Average test loss:  0.5542329812555046\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08792101041125089\n",
      "Average test loss:  0.5645791963175509\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07617205310687791\n",
      "Average test loss:  0.5758523468755062\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.06658756345600357\n",
      "Average test loss:  0.5884950536815453\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.05868493413187647\n",
      "Average test loss:  0.6014655544084082\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.05210651510125361\n",
      "Average test loss:  0.6151210991416248\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.04656452166937733\n",
      "Average test loss:  0.6288470593232073\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.04187211712985431\n",
      "Average test loss:  0.6429020297820554\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.03785193691595609\n",
      "Average test loss:  0.6571242155801773\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.034386203770405216\n",
      "Average test loss:  0.6711368050050538\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.03136484959915967\n",
      "Average test loss:  0.6852338778075926\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.02868897050143977\n",
      "Average test loss:  0.6992550451533012\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.02630691532488641\n",
      "Average test loss:  0.713153166817284\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.024157827405384375\n",
      "Average test loss:  0.7269377994746383\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.022212161999312956\n",
      "Average test loss:  0.7409391091924933\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.020480518016681715\n",
      "Average test loss:  0.754149693130031\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.01895060819924974\n",
      "Average test loss:  0.7675962938514668\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6913045695237477\n",
      "Average test loss:  0.6925935112074016\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.920625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.6876418794349677\n",
      "Average test loss:  0.6912672420299065\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6789733206618163\n",
      "Average test loss:  0.6882778210931176\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6570316507711919\n",
      "Average test loss:  0.6806734976192997\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.94375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6049333281884739\n",
      "Average test loss:  0.6625295714623943\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.5112649451198287\n",
      "Average test loss:  0.6298445973649215\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.4003232240061993\n",
      "Average test loss:  0.591833952656248\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3055832777438446\n",
      "Average test loss:  0.5627746508647905\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.96625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.2356619898673448\n",
      "Average test loss:  0.5452564067515718\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.18565534408803086\n",
      "Average test loss:  0.5380468083229624\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.14946019134247743\n",
      "Average test loss:  0.5373582907341287\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.12263175000768413\n",
      "Average test loss:  0.541625833254937\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10229732952611122\n",
      "Average test loss:  0.5500379779939472\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.08651793679515636\n",
      "Average test loss:  0.5604291685984407\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07409044122399987\n",
      "Average test loss:  0.5725715949420679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0640948562731881\n",
      "Average test loss:  0.5861660324441882\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0559593326626698\n",
      "Average test loss:  0.6005111242048949\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04925413133865545\n",
      "Average test loss:  0.6149887694568319\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.04366342327113004\n",
      "Average test loss:  0.6303652729135696\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.038960811522173906\n",
      "Average test loss:  0.6452201996084026\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.03496782401346656\n",
      "Average test loss:  0.6610939393427491\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.031542011659561414\n",
      "Average test loss:  0.6762600124575541\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.028580232972959575\n",
      "Average test loss:  0.6916019231011927\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.02599970900760336\n",
      "Average test loss:  0.706801176742517\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.02372668172181244\n",
      "Average test loss:  0.7215847737749161\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.02171775730914946\n",
      "Average test loss:  0.7365700059650971\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.019934767080781655\n",
      "Average test loss:  0.7511391991123125\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.018352570843432534\n",
      "Average test loss:  0.7656803016918028\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.01695351074527385\n",
      "Average test loss:  0.779985588836575\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.015725315071513393\n",
      "Average test loss:  0.7943179963248417\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.926875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.6918643469191593\n",
      "Average test loss:  0.692699594649207\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.928125\n",
      "Average test accuracy:  0.7125\n",
      "\n",
      "Average train loss:  0.6882059015953254\n",
      "Average test loss:  0.6914340938096548\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.924375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.676175637538491\n",
      "Average test loss:  0.6872516002325716\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6422122393151409\n",
      "Average test loss:  0.6753802279834084\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5652091598171055\n",
      "Average test loss:  0.6484303845590581\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.45058262200326477\n",
      "Average test loss:  0.6083178947406909\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.3400639670554426\n",
      "Average test loss:  0.5721527786816419\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.25682784691841953\n",
      "Average test loss:  0.549276974724954\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.19835652085293068\n",
      "Average test loss:  0.5378235953270085\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.15709375196851458\n",
      "Average test loss:  0.5354509583018193\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.1271946208119839\n",
      "Average test loss:  0.5393474055319104\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.10491775048582914\n",
      "Average test loss:  0.5467890903058846\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08791780801498929\n",
      "Average test loss:  0.5575478083871056\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07467284691657512\n",
      "Average test loss:  0.5700324984647024\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06414863741983547\n",
      "Average test loss:  0.5841585187265349\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.055654427207649855\n",
      "Average test loss:  0.5985187706842376\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.04870165821920833\n",
      "Average test loss:  0.6146785127760453\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.04295217204596844\n",
      "Average test loss:  0.6305539977304785\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.03814439706809169\n",
      "Average test loss:  0.6463734948392124\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.03408205771735057\n",
      "Average test loss:  0.6626896688328185\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.030614343320930996\n",
      "Average test loss:  0.6787794207660722\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.027640745375835576\n",
      "Average test loss:  0.6948859317089386\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.025068543807821586\n",
      "Average test loss:  0.7110887914381152\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.022819109534010257\n",
      "Average test loss:  0.7268597536490967\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.020835275986004573\n",
      "Average test loss:  0.7418869623854135\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.019083265142689744\n",
      "Average test loss:  0.757627119846124\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.017538200820272697\n",
      "Average test loss:  0.7726312772957117\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.016180234877157893\n",
      "Average test loss:  0.7879563693804729\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.014996763467907855\n",
      "Average test loss:  0.8022176978265945\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.013956728710895315\n",
      "Average test loss:  0.816489665634606\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.509375\n",
      "Average test accuracy:  0.50125\n",
      "\n",
      "Average train loss:  0.6910645226536092\n",
      "Average test loss:  0.6924013468366111\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.690625\n",
      "Average test accuracy:  0.51875\n",
      "\n",
      "Average train loss:  0.6869504124014602\n",
      "Average test loss:  0.6910040978464943\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.841875\n",
      "Average test accuracy:  0.58625\n",
      "\n",
      "Average train loss:  0.6774453415152449\n",
      "Average test loss:  0.6877860885491721\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.91875\n",
      "Average test accuracy:  0.7025\n",
      "\n",
      "Average train loss:  0.6562638974441596\n",
      "Average test loss:  0.6805528752286247\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.931875\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.6129387810665828\n",
      "Average test loss:  0.6659281683083051\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.5383486666870478\n",
      "Average test loss:  0.6404826291016202\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.4407499489975469\n",
      "Average test loss:  0.6079022632962386\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.955\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3449862030990956\n",
      "Average test loss:  0.57724340563052\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.26811961783803384\n",
      "Average test loss:  0.5562441587095374\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.21125596338686314\n",
      "Average test loss:  0.5443046229844226\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1695618213511484\n",
      "Average test loss:  0.5399698585504474\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.13859162394817018\n",
      "Average test loss:  0.541236537912623\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.1151598295600475\n",
      "Average test loss:  0.5471671552103449\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.09703766490850883\n",
      "Average test loss:  0.5551935466003561\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.0827969394241423\n",
      "Average test loss:  0.5657046224139006\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07139325674109574\n",
      "Average test loss:  0.577739114907101\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06215294872092919\n",
      "Average test loss:  0.5904274240784112\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.054545519425742296\n",
      "Average test loss:  0.6040681039091346\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.04823142047536538\n",
      "Average test loss:  0.6183833270435501\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.04293458887215205\n",
      "Average test loss:  0.6329831455948868\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.03845889752764028\n",
      "Average test loss:  0.6481473198427011\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.03463650358940427\n",
      "Average test loss:  0.6627724122590668\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.03134302816954918\n",
      "Average test loss:  0.6779587140749529\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.028484128263794862\n",
      "Average test loss:  0.6925345133266227\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.02598335550756037\n",
      "Average test loss:  0.7075056164513215\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.023773184982295182\n",
      "Average test loss:  0.7220251486592865\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.021818563923236983\n",
      "Average test loss:  0.7367481125843144\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.020084450286465605\n",
      "Average test loss:  0.7510139708065333\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.018532102095705\n",
      "Average test loss:  0.7654425291867653\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.01715816593517814\n",
      "Average test loss:  0.7794744898648142\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.8010071627180739\n",
      "Average test loss:  0.802055598682422\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7607233664784459\n",
      "Average test loss:  0.7624096328977631\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7366451213414088\n",
      "Average test loss:  0.7387477279478549\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7215388996745364\n",
      "Average test loss:  0.7239436985050455\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.711555556467141\n",
      "Average test loss:  0.7142259904268412\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7045272427513284\n",
      "Average test loss:  0.7074987047868353\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6992770556338015\n",
      "Average test loss:  0.7026692066518619\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6949950856285024\n",
      "Average test loss:  0.6990315512861679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6910537039025689\n",
      "Average test loss:  0.696129755599776\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6867677771364685\n",
      "Average test loss:  0.6935923423958309\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6810563381389909\n",
      "Average test loss:  0.6908773548577054\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6721446919389064\n",
      "Average test loss:  0.6872382719540638\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6571019088101722\n",
      "Average test loss:  0.6814174959800635\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.70375\n",
      "Average test accuracy:  0.56125\n",
      "\n",
      "Average train loss:  0.6323064958556192\n",
      "Average test loss:  0.6717065194332518\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.911875\n",
      "Average test accuracy:  0.685\n",
      "\n",
      "Average train loss:  0.5958067186807267\n",
      "Average test loss:  0.6571286561646669\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5493982010553068\n",
      "Average test loss:  0.6384456395625389\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.49828106963726154\n",
      "Average test loss:  0.6178797668158227\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.4482535834761956\n",
      "Average test loss:  0.5980622529920808\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.4028717844330994\n",
      "Average test loss:  0.5806445249138316\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.36317724046282507\n",
      "Average test loss:  0.5662684058835065\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.32885884602857424\n",
      "Average test loss:  0.5548650937241315\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.29923799829300635\n",
      "Average test loss:  0.5460290078205093\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.27355107404183526\n",
      "Average test loss:  0.5395562238353041\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.25116145537616114\n",
      "Average test loss:  0.535018206984837\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.23152369934074948\n",
      "Average test loss:  0.5320419890794904\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.21419335883730972\n",
      "Average test loss:  0.5303894890129252\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.19880420234487964\n",
      "Average test loss:  0.529851213536344\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.18505740072630392\n",
      "Average test loss:  0.5302117359243691\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.17272505183098616\n",
      "Average test loss:  0.5313204939869662\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.16161302376200984\n",
      "Average test loss:  0.5331396991150151\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6912930671125063\n",
      "Average test loss:  0.6925327517170626\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.9075\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.6882092852800934\n",
      "Average test loss:  0.691421124726023\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.91625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.6819756602433658\n",
      "Average test loss:  0.689224775189231\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6693746995155495\n",
      "Average test loss:  0.6847746242719716\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.938125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6450674874785189\n",
      "Average test loss:  0.6761637342742407\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6027659654430518\n",
      "Average test loss:  0.6611601877624291\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.94125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.5427029237950275\n",
      "Average test loss:  0.6399148900843173\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.4756306413199514\n",
      "Average test loss:  0.6160724959136232\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.958125\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.4118559388049989\n",
      "Average test loss:  0.5936618936107495\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.35615592491859394\n",
      "Average test loss:  0.575137773267053\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3092103928664838\n",
      "Average test loss:  0.5605829081920676\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.2700713627867943\n",
      "Average test loss:  0.5499684473592978\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.23744956894210945\n",
      "Average test loss:  0.5426372549204345\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.2101496374384698\n",
      "Average test loss:  0.5382692347043467\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.18715023876735104\n",
      "Average test loss:  0.5365362140759686\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.16763697598045427\n",
      "Average test loss:  0.536559921238409\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1509400615985153\n",
      "Average test loss:  0.5382976033165138\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.13656951587505575\n",
      "Average test loss:  0.5417491059925904\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.12410196915929024\n",
      "Average test loss:  0.5461599687553952\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.11324464167268718\n",
      "Average test loss:  0.5514322570258267\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10372293526137337\n",
      "Average test loss:  0.5574514222685613\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09532835120687379\n",
      "Average test loss:  0.564356735616334\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08789127157234859\n",
      "Average test loss:  0.5717913884014793\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08127886064756722\n",
      "Average test loss:  0.579626020927395\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.0753674158242075\n",
      "Average test loss:  0.5876004271914868\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.07007899502712112\n",
      "Average test loss:  0.5959241041072395\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.06533726979286028\n",
      "Average test loss:  0.6044840907579473\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.06107040532537331\n",
      "Average test loss:  0.6131983131779792\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.05722097484418468\n",
      "Average test loss:  0.6220127425019265\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.0537256029900459\n",
      "Average test loss:  0.6306153132372607\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6913874926353175\n",
      "Average test loss:  0.6925443440799212\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.66375\n",
      "Average test accuracy:  0.5075\n",
      "\n",
      "Average train loss:  0.6884641887535764\n",
      "Average test loss:  0.6915370539419786\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.683125\n",
      "Average test accuracy:  0.51125\n",
      "\n",
      "Average train loss:  0.683243733446225\n",
      "Average test loss:  0.68980365621884\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.865625\n",
      "Average test accuracy:  0.5975\n",
      "\n",
      "Average train loss:  0.6723352226476141\n",
      "Average test loss:  0.6860964879763752\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.898125\n",
      "Average test accuracy:  0.65875\n",
      "\n",
      "Average train loss:  0.6489942711704576\n",
      "Average test loss:  0.6782629962806923\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.925625\n",
      "Average test accuracy:  0.705\n",
      "\n",
      "Average train loss:  0.6052940162300136\n",
      "Average test loss:  0.6633434636123313\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.541228749451086\n",
      "Average test loss:  0.6413340625727872\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.4677877977201634\n",
      "Average test loss:  0.6162721097200542\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.39751784488876724\n",
      "Average test loss:  0.5927205421478428\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.33680929723452907\n",
      "Average test loss:  0.5731979886130426\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.2865296761364646\n",
      "Average test loss:  0.5587940295061341\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.24546810954502077\n",
      "Average test loss:  0.5489622138405567\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.21194901507662064\n",
      "Average test loss:  0.5428195264465926\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.18445134399875465\n",
      "Average test loss:  0.5396865233321521\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.16173429131544356\n",
      "Average test loss:  0.5395942669957333\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.14279082394595957\n",
      "Average test loss:  0.5414365325985738\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.12683606542155082\n",
      "Average test loss:  0.5453113093760679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.11331639743978093\n",
      "Average test loss:  0.5502154724825621\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.10175570423052423\n",
      "Average test loss:  0.5567399295449991\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.0918181679777484\n",
      "Average test loss:  0.5637919694495364\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.08320983401179079\n",
      "Average test loss:  0.571722624782503\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0757256872581798\n",
      "Average test loss:  0.5802253325855585\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06918447843923047\n",
      "Average test loss:  0.5892572066447211\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06344902765403655\n",
      "Average test loss:  0.5983093419483465\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.058399956676387976\n",
      "Average test loss:  0.6077807787378703\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.053939346557449565\n",
      "Average test loss:  0.6172677413145623\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.049981380150667554\n",
      "Average test loss:  0.6273506176051686\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.04646265869387569\n",
      "Average test loss:  0.6370685244664566\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.04331099549607451\n",
      "Average test loss:  0.6469092279262783\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04048863516799759\n",
      "Average test loss:  0.6568025801608748\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7000372280605576\n",
      "Average test loss:  0.7005204526140208\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6917081001874879\n",
      "Average test loss:  0.6930373090114857\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.641875\n",
      "Average test accuracy:  0.53625\n",
      "\n",
      "Average train loss:  0.6883896890397314\n",
      "Average test loss:  0.6914762031317035\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.9\n",
      "Average test accuracy:  0.7025\n",
      "\n",
      "Average train loss:  0.6830317520481018\n",
      "Average test loss:  0.6896115278345495\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.928125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.6714551250194329\n",
      "Average test loss:  0.6855911210739419\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.6453320390021956\n",
      "Average test loss:  0.6764103867203692\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.940625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.592865480399448\n",
      "Average test loss:  0.6578181688297381\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.5113923647501107\n",
      "Average test loss:  0.628898470099115\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.4203034319273069\n",
      "Average test loss:  0.5971748832668914\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.34039294011321886\n",
      "Average test loss:  0.5708752443903123\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2773046808071639\n",
      "Average test loss:  0.5529833566394847\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.22885091226620577\n",
      "Average test loss:  0.541541019312136\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1915649502759952\n",
      "Average test loss:  0.5364948014483791\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.16248902938863222\n",
      "Average test loss:  0.5357511432594927\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.13943210011441384\n",
      "Average test loss:  0.5384132584418921\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.12089253524815202\n",
      "Average test loss:  0.5433391802633221\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.10576097223523688\n",
      "Average test loss:  0.5499690457304944\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.09324760294241226\n",
      "Average test loss:  0.5588325261718279\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08280621351922536\n",
      "Average test loss:  0.5680198126742274\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07398376793564064\n",
      "Average test loss:  0.5782319122770856\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.06649858220174844\n",
      "Average test loss:  0.5894929648206785\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.06009573081001938\n",
      "Average test loss:  0.6006899682534211\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.05458888019809941\n",
      "Average test loss:  0.6121902611267815\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.04983404017589271\n",
      "Average test loss:  0.6238062774898905\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.045696669737225394\n",
      "Average test loss:  0.6355472895228704\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.042087863032587575\n",
      "Average test loss:  0.64734724704399\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.038916625455974296\n",
      "Average test loss:  0.6587031959930009\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.036113838327400886\n",
      "Average test loss:  0.6704122932552599\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.033622356851139686\n",
      "Average test loss:  0.6817235120619204\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.031404140066803955\n",
      "Average test loss:  0.6933375809599807\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.696212375551785\n",
      "Average test loss:  0.697311639340397\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6892719938078732\n",
      "Average test loss:  0.6919025642214504\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.6851744612855448\n",
      "Average test loss:  0.6904004891796425\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.89625\n",
      "Average test accuracy:  0.7\n",
      "\n",
      "Average train loss:  0.6780539397186273\n",
      "Average test loss:  0.6879116456869231\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.91625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.6639880454752533\n",
      "Average test loss:  0.6829616029324314\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9325\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.636002876002296\n",
      "Average test loss:  0.6730411893616002\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.5841980682673934\n",
      "Average test loss:  0.6545173462194283\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5044095905935495\n",
      "Average test loss:  0.625908785976442\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.4130742281802026\n",
      "Average test loss:  0.5936435150307148\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3314146811115266\n",
      "Average test loss:  0.5665352684203208\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.2668725060467954\n",
      "Average test loss:  0.5478157947928236\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.21788418285130676\n",
      "Average test loss:  0.5369679559074809\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.1805867760885664\n",
      "Average test loss:  0.5324664328379834\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.15179474811481672\n",
      "Average test loss:  0.5324426073121288\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.12921423693555525\n",
      "Average test loss:  0.5357395862582502\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.11123401693196122\n",
      "Average test loss:  0.5421480070106587\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.0967185309241038\n",
      "Average test loss:  0.5501124309515845\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08482695595962152\n",
      "Average test loss:  0.5594848422351567\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07496692996873065\n",
      "Average test loss:  0.570039432331077\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06670549221070741\n",
      "Average test loss:  0.5813968398227646\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.059722717138352165\n",
      "Average test loss:  0.5932882853830314\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.0537532993999329\n",
      "Average test loss:  0.6061860768040762\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0486250959021243\n",
      "Average test loss:  0.618266065962461\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04418541152419685\n",
      "Average test loss:  0.6312189079135447\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.040313032240760105\n",
      "Average test loss:  0.6439476546582386\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0369174306204808\n",
      "Average test loss:  0.6566747016873934\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.033904357889689714\n",
      "Average test loss:  0.6692152804531358\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.031234625334190688\n",
      "Average test loss:  0.6819571503807514\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.028876603966829336\n",
      "Average test loss:  0.6947456361387098\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.026790976280505807\n",
      "Average test loss:  0.7070997756863925\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.93125\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.6907992025976165\n",
      "Average test loss:  0.692328940912801\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.78625\n",
      "Average test accuracy:  0.55\n",
      "\n",
      "Average train loss:  0.6864066230658784\n",
      "Average test loss:  0.6908294972733735\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.88625\n",
      "Average test accuracy:  0.64125\n",
      "\n",
      "Average train loss:  0.6755981747992664\n",
      "Average test loss:  0.6871352667948543\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.925625\n",
      "Average test accuracy:  0.705\n",
      "\n",
      "Average train loss:  0.6491715187489726\n",
      "Average test loss:  0.6780957028652658\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.5921236802010738\n",
      "Average test loss:  0.6585423135918537\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.94375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.500501534756045\n",
      "Average test loss:  0.6274570938163658\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.3989625692298892\n",
      "Average test loss:  0.5934852910866539\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.31295725719677076\n",
      "Average test loss:  0.5674026866734123\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.24748351404066926\n",
      "Average test loss:  0.5501796172949894\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1989239094279137\n",
      "Average test loss:  0.5417096427992804\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.16268820363602635\n",
      "Average test loss:  0.5390995511525783\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9825\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13516782348765624\n",
      "Average test loss:  0.5418822406403055\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.11388062290377561\n",
      "Average test loss:  0.5475477695772476\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09711198588399632\n",
      "Average test loss:  0.5554667415189432\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.08370093587613454\n",
      "Average test loss:  0.566287798601029\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07281798793217707\n",
      "Average test loss:  0.5774954761419832\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06389515001913638\n",
      "Average test loss:  0.5894782183056764\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.05650228653363687\n",
      "Average test loss:  0.6023743033234585\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.050324201993073546\n",
      "Average test loss:  0.6160464809350744\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.04511731867629679\n",
      "Average test loss:  0.6295016881188115\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04068846192103182\n",
      "Average test loss:  0.6431744078340816\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.03689495533315503\n",
      "Average test loss:  0.6571448898654954\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.03360680277091425\n",
      "Average test loss:  0.6708981486187598\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.030725452635804163\n",
      "Average test loss:  0.6847058911818391\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.028169840980771396\n",
      "Average test loss:  0.6980636314698739\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.02587266162551392\n",
      "Average test loss:  0.7116480844983446\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.02378721776628398\n",
      "Average test loss:  0.7251064356952015\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.021899894813852863\n",
      "Average test loss:  0.7385596577424182\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.020204149870994524\n",
      "Average test loss:  0.7519622539247476\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.018699445753609573\n",
      "Average test loss:  0.7652100538129303\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7073965693855873\n",
      "Average test loss:  0.7084999498357059\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6917957575264424\n",
      "Average test loss:  0.69414606782006\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6869578296954245\n",
      "Average test loss:  0.6911322133158041\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.6819858071049677\n",
      "Average test loss:  0.6892427002387679\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.6728914929595459\n",
      "Average test loss:  0.6859984974266382\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9475\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.6541619621619862\n",
      "Average test loss:  0.6793161719263784\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9475\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.6160306820531928\n",
      "Average test loss:  0.6656551400083344\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5501934917231704\n",
      "Average test loss:  0.642066214383358\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.955\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.4637468659722878\n",
      "Average test loss:  0.6117763019041172\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3762087825673793\n",
      "Average test loss:  0.5827135695348253\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.30162091471940533\n",
      "Average test loss:  0.5605932163413364\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.24310415081193415\n",
      "Average test loss:  0.5467609149472393\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.19846514824680686\n",
      "Average test loss:  0.539975391124726\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.1643859935341974\n",
      "Average test loss:  0.5384096328126097\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.13805221727703765\n",
      "Average test loss:  0.5413140965364663\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.11743663691368988\n",
      "Average test loss:  0.5470723853335636\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.10102561968575892\n",
      "Average test loss:  0.555012950006336\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.08775457279942676\n",
      "Average test loss:  0.5644716928995531\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.07690218107388751\n",
      "Average test loss:  0.5754689291774381\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.06791752325236451\n",
      "Average test loss:  0.5869311861762471\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.060421448535024784\n",
      "Average test loss:  0.5993485502614969\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.05408814058905193\n",
      "Average test loss:  0.6120087384651042\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.04870874966510364\n",
      "Average test loss:  0.6248411278465352\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.04411091888597338\n",
      "Average test loss:  0.6379320879697811\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.040144905992485706\n",
      "Average test loss:  0.6512559749058219\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.03670788405740844\n",
      "Average test loss:  0.6643100727193559\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.03370937661316215\n",
      "Average test loss:  0.6774508217680011\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.03107581592294852\n",
      "Average test loss:  0.6902516672501927\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.028738223772075425\n",
      "Average test loss:  0.70303854547269\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.026654238251782966\n",
      "Average test loss:  0.7154933621279698\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6987834900541792\n",
      "Average test loss:  0.699457433478766\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6897885922738806\n",
      "Average test loss:  0.6920250249078196\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.84875\n",
      "Average test accuracy:  0.6475\n",
      "\n",
      "Average train loss:  0.6857954160208918\n",
      "Average test loss:  0.6905588233790975\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.86875\n",
      "Average test accuracy:  0.645\n",
      "\n",
      "Average train loss:  0.678918711335258\n",
      "Average test loss:  0.6882034377690642\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.90625\n",
      "Average test accuracy:  0.68875\n",
      "\n",
      "Average train loss:  0.6648341376604728\n",
      "Average test loss:  0.6833728341242228\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6348138769598742\n",
      "Average test loss:  0.6728412116858985\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5753972201090466\n",
      "Average test loss:  0.6518924303362011\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.48089444840656465\n",
      "Average test loss:  0.6179967044454076\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.37539017800118524\n",
      "Average test loss:  0.5811376687728437\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.28756801072726473\n",
      "Average test loss:  0.5538227118122859\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.22327439168710417\n",
      "Average test loss:  0.5377968752395811\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.17728427358110668\n",
      "Average test loss:  0.5315420027099361\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1438812427914747\n",
      "Average test loss:  0.5323262187386203\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.11903035584096455\n",
      "Average test loss:  0.5374493404602028\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.10007327087480584\n",
      "Average test loss:  0.5458616368295727\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08528608810242887\n",
      "Average test loss:  0.5567402181515745\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07351971339607676\n",
      "Average test loss:  0.5692868840445102\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06400735570431476\n",
      "Average test loss:  0.5825322948983543\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.05618155345142936\n",
      "Average test loss:  0.5967776146944762\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.04968358768353328\n",
      "Average test loss:  0.6118433867216888\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.0442183920870751\n",
      "Average test loss:  0.6269640179143888\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.03958291649251281\n",
      "Average test loss:  0.6420394517904932\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.03564258250858121\n",
      "Average test loss:  0.6571318865715855\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.03225925275691267\n",
      "Average test loss:  0.6724425632091114\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.029344121613127102\n",
      "Average test loss:  0.6873074943660079\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.02683167661106588\n",
      "Average test loss:  0.7020237552580819\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.024649537505287825\n",
      "Average test loss:  0.7167243897095882\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.02274368208773873\n",
      "Average test loss:  0.7308773841155144\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.021072248152328346\n",
      "Average test loss:  0.7453126963166827\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.019599539101574377\n",
      "Average test loss:  0.7591995803896511\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.885\n",
      "Average test accuracy:  0.70875\n",
      "\n",
      "Average train loss:  0.6918147752315886\n",
      "Average test loss:  0.6926799021694946\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.716875\n",
      "Average test accuracy:  0.56625\n",
      "\n",
      "Average train loss:  0.6875668794059163\n",
      "Average test loss:  0.6912107256196411\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.818125\n",
      "Average test accuracy:  0.63375\n",
      "\n",
      "Average train loss:  0.6742433921749628\n",
      "Average test loss:  0.68660647969525\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.890625\n",
      "Average test accuracy:  0.6925\n",
      "\n",
      "Average train loss:  0.6386101681026582\n",
      "Average test loss:  0.6741933082394481\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.5584617307284572\n",
      "Average test loss:  0.6459388051541506\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.44173152804859445\n",
      "Average test loss:  0.6047963082455808\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.3335556329750769\n",
      "Average test loss:  0.5689136447210102\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2530180044392763\n",
      "Average test loss:  0.546284689452197\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.1963694769354871\n",
      "Average test loss:  0.5357326712739027\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.15615830233257644\n",
      "Average test loss:  0.5334913236799191\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.12685581411453675\n",
      "Average test loss:  0.5372058907060264\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1049429115504601\n",
      "Average test loss:  0.5448633434351301\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.08815949072542795\n",
      "Average test loss:  0.5554911269371662\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0750263995992515\n",
      "Average test loss:  0.5680282461935704\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.06457029361877899\n",
      "Average test loss:  0.5823667773808406\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.056082821472613426\n",
      "Average test loss:  0.5968545386213227\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04911140833632799\n",
      "Average test loss:  0.6127590155043062\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04332822870567086\n",
      "Average test loss:  0.6286998496947707\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.03848160405230167\n",
      "Average test loss:  0.6451615039268032\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.0344039397205719\n",
      "Average test loss:  0.6613985905119018\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.030942091972081382\n",
      "Average test loss:  0.6777944069430496\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.027986769571662323\n",
      "Average test loss:  0.6940760475483231\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.025447231025219424\n",
      "Average test loss:  0.7096200055304903\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.02325501487021994\n",
      "Average test loss:  0.7261234763458911\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.021322662211454485\n",
      "Average test loss:  0.7412491158617996\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.01961550935118204\n",
      "Average test loss:  0.7563135108477287\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.01807810732072307\n",
      "Average test loss:  0.7717005043854531\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.016685767749812674\n",
      "Average test loss:  0.7866964503541641\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.01541826409688421\n",
      "Average test loss:  0.8011554125515722\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.014287286221289835\n",
      "Average test loss:  0.8160569091391686\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.92\n",
      "Average test accuracy:  0.67875\n",
      "\n",
      "Average train loss:  0.6903299811560909\n",
      "Average test loss:  0.6921730653826265\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.705625\n",
      "Average test accuracy:  0.56375\n",
      "\n",
      "Average train loss:  0.6850249250925953\n",
      "Average test loss:  0.6903488910707402\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.865625\n",
      "Average test accuracy:  0.6675\n",
      "\n",
      "Average train loss:  0.6727852664870889\n",
      "Average test loss:  0.6860961460169964\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6452670178583669\n",
      "Average test loss:  0.6764625439466757\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.945625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5913661391051863\n",
      "Average test loss:  0.6576081023577692\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5055033921046296\n",
      "Average test loss:  0.6277672301154663\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.40250689942061224\n",
      "Average test loss:  0.5934684369858303\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.3087838100733658\n",
      "Average test loss:  0.5652536455638674\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.2368955395875064\n",
      "Average test loss:  0.5477264736113684\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.18500336108718107\n",
      "Average test loss:  0.5409526795986641\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.14756331886791624\n",
      "Average test loss:  0.5407794688626043\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.12008656149592534\n",
      "Average test loss:  0.5460223623717056\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.09943704043171371\n",
      "Average test loss:  0.5548456933702447\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08357672191340156\n",
      "Average test loss:  0.5664150313793004\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.07117274043036105\n",
      "Average test loss:  0.5791989046895943\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.06130635273260473\n",
      "Average test loss:  0.5940158646973647\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.053305882259069244\n",
      "Average test loss:  0.6083525853178648\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.04675976559691156\n",
      "Average test loss:  0.6242711439584833\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.04132048299760266\n",
      "Average test loss:  0.6402479913327827\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.03674683569252677\n",
      "Average test loss:  0.6560736328428004\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.032864431818983915\n",
      "Average test loss:  0.6720883633133347\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.029522558350902728\n",
      "Average test loss:  0.6882182769686608\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.02663692861277057\n",
      "Average test loss:  0.7041237404860858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.024129282634592446\n",
      "Average test loss:  0.7199320312064682\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.021935885214809863\n",
      "Average test loss:  0.7357197364473539\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.020030988731195562\n",
      "Average test loss:  0.7511489516931776\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.018369901486204508\n",
      "Average test loss:  0.7662521227750441\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.016905313924647836\n",
      "Average test loss:  0.781756416385211\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.015613141621221889\n",
      "Average test loss:  0.7965524179332554\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.01445677948986604\n",
      "Average test loss:  0.811321020506525\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7741889412058112\n",
      "Average test loss:  0.774677223263092\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7506714940401938\n",
      "Average test loss:  0.7512740725442821\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7331065271868343\n",
      "Average test loss:  0.7337624918163456\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7163671801838657\n",
      "Average test loss:  0.7174464884427452\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7021634024519319\n",
      "Average test loss:  0.7042276698442876\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6928983706903348\n",
      "Average test loss:  0.6964508461415847\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6853161820344577\n",
      "Average test loss:  0.6918281368970641\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6735328512087587\n",
      "Average test loss:  0.6868967941475819\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.774375\n",
      "Average test accuracy:  0.54125\n",
      "\n",
      "Average train loss:  0.6527858509722196\n",
      "Average test loss:  0.6788947121374459\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9325\n",
      "Average test accuracy:  0.715\n",
      "\n",
      "Average train loss:  0.6226555543352993\n",
      "Average test loss:  0.6670322193576889\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.5838309208007498\n",
      "Average test loss:  0.6517409211993278\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.5379301246761279\n",
      "Average test loss:  0.6337423980806243\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.48895935758624764\n",
      "Average test loss:  0.6147199877439555\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.44150761030248115\n",
      "Average test loss:  0.5964894985864165\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3984595724975524\n",
      "Average test loss:  0.5806342820300431\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.36060832052194874\n",
      "Average test loss:  0.5674218415873641\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3276917285478756\n",
      "Average test loss:  0.5568735389707417\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.2990814701858259\n",
      "Average test loss:  0.5485613569837242\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.2741526279604443\n",
      "Average test loss:  0.5423110526066562\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2523166704918651\n",
      "Average test loss:  0.5379774477199704\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2330947230678071\n",
      "Average test loss:  0.5352791957345033\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.21607699711060838\n",
      "Average test loss:  0.5335943826180292\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.20091862956157483\n",
      "Average test loss:  0.5329596345457495\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.18734468136988622\n",
      "Average test loss:  0.5335662197697139\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.17512732577600768\n",
      "Average test loss:  0.5347877532470772\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1640979203217888\n",
      "Average test loss:  0.5366145506814628\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1541065206807358\n",
      "Average test loss:  0.5393029035903664\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.14503830944136717\n",
      "Average test loss:  0.5425292980330377\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.13677628040419032\n",
      "Average test loss:  0.5460036053543594\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.12923105587339911\n",
      "Average test loss:  0.549935343722907\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7531567193131044\n",
      "Average test loss:  0.7543692738138006\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7170307550958871\n",
      "Average test loss:  0.7190513120089747\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6981796526883709\n",
      "Average test loss:  0.7016387835395991\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6885271548664887\n",
      "Average test loss:  0.69386714406291\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6824488792185436\n",
      "Average test loss:  0.6901870408671612\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.515\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6763953232945822\n",
      "Average test loss:  0.6875515929555917\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.7975\n",
      "Average test accuracy:  0.54375\n",
      "\n",
      "Average train loss:  0.6679120068685842\n",
      "Average test loss:  0.6843940013102636\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.881875\n",
      "Average test accuracy:  0.6325\n",
      "\n",
      "Average train loss:  0.6542733339429732\n",
      "Average test loss:  0.6795019129350965\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9075\n",
      "Average test accuracy:  0.68875\n",
      "\n",
      "Average train loss:  0.6314944622197226\n",
      "Average test loss:  0.6714419222062444\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9225\n",
      "Average test accuracy:  0.70875\n",
      "\n",
      "Average train loss:  0.5954950066440206\n",
      "Average test loss:  0.6587082449610239\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.5460862472280321\n",
      "Average test loss:  0.6411351100043494\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.4887315466965047\n",
      "Average test loss:  0.6205933672428973\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.4308345532648418\n",
      "Average test loss:  0.6003451953050686\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.37750129199581334\n",
      "Average test loss:  0.5820949347643195\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3308318516817231\n",
      "Average test loss:  0.5673224640046549\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.29094096989871926\n",
      "Average test loss:  0.555823652350962\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.25713306936554947\n",
      "Average test loss:  0.5475647194382182\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.22847820146275274\n",
      "Average test loss:  0.5419893431141256\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.2041305201612623\n",
      "Average test loss:  0.5390081519836291\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.18332029518487838\n",
      "Average test loss:  0.5380702597008128\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.16543887570304167\n",
      "Average test loss:  0.5386978006169958\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1499817255903397\n",
      "Average test loss:  0.5407731429596584\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1365168127869885\n",
      "Average test loss:  0.5439285581161891\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.12475613569518677\n",
      "Average test loss:  0.5484415228266352\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.11440650434993886\n",
      "Average test loss:  0.5533491334990474\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.10526596721933895\n",
      "Average test loss:  0.5590840358710419\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.09714941748636986\n",
      "Average test loss:  0.5654878853098676\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.08991794351973882\n",
      "Average test loss:  0.5725294326917397\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.08343615273012228\n",
      "Average test loss:  0.5797443254764064\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.07762131752560862\n",
      "Average test loss:  0.5874715567699522\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6977804895962337\n",
      "Average test loss:  0.6990682077639464\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.688832342764958\n",
      "Average test loss:  0.691940895868921\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.861875\n",
      "Average test accuracy:  0.65875\n",
      "\n",
      "Average train loss:  0.6838697280304366\n",
      "Average test loss:  0.6898888246717507\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.6757892520535284\n",
      "Average test loss:  0.6871077842554526\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6582209811712872\n",
      "Average test loss:  0.6810590852557047\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.620769599440265\n",
      "Average test loss:  0.6679579742428284\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.5568896714713473\n",
      "Average test loss:  0.6450514949463368\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.47716370059841795\n",
      "Average test loss:  0.6160755892230552\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3991155360773863\n",
      "Average test loss:  0.5881396048978779\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.33258085555187605\n",
      "Average test loss:  0.5658176742395851\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.2788640917378609\n",
      "Average test loss:  0.5497342745310649\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.23610732495026668\n",
      "Average test loss:  0.5393058392028102\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.2019836560106637\n",
      "Average test loss:  0.5334869386195774\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.17447951357615113\n",
      "Average test loss:  0.5314370720500111\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.15208207037926094\n",
      "Average test loss:  0.5320815570367705\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.13362551509182838\n",
      "Average test loss:  0.5351659854503366\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.11826802223746403\n",
      "Average test loss:  0.540215147783389\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.10535557469602168\n",
      "Average test loss:  0.5465144639995253\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.09441878769178176\n",
      "Average test loss:  0.5539928694097177\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.08506196077991644\n",
      "Average test loss:  0.5621367761851067\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07701110713678537\n",
      "Average test loss:  0.571501288796285\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07002822395948119\n",
      "Average test loss:  0.5810189068432932\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.06393516805944348\n",
      "Average test loss:  0.5909867133426335\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.058593925728895914\n",
      "Average test loss:  0.6012930764346297\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.053906445344980104\n",
      "Average test loss:  0.6116650507859954\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04977245487895334\n",
      "Average test loss:  0.6220317482308958\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.046115803697539516\n",
      "Average test loss:  0.6326302426704261\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.04286057414671477\n",
      "Average test loss:  0.6430817251787001\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.0399498592977315\n",
      "Average test loss:  0.6536197108338938\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.037328620541667766\n",
      "Average test loss:  0.6639753741874034\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.83\n",
      "Average test accuracy:  0.6325\n",
      "\n",
      "Average train loss:  0.691334405973865\n",
      "Average test loss:  0.6925193535276115\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.903125\n",
      "Average test accuracy:  0.685\n",
      "\n",
      "Average train loss:  0.6879218339102419\n",
      "Average test loss:  0.6913405406636747\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6799411278476226\n",
      "Average test loss:  0.6885789224738427\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.931875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.65974918022391\n",
      "Average test loss:  0.6815432437252239\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.94125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6131257377784504\n",
      "Average test loss:  0.6651155775016524\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5322830821076381\n",
      "Average test loss:  0.636166902585854\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.4376955332775791\n",
      "Average test loss:  0.6022250103435157\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.35340438305289906\n",
      "Average test loss:  0.5731845297330237\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2867804715110856\n",
      "Average test loss:  0.5527714598903025\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.23573063352840604\n",
      "Average test loss:  0.5398426447998632\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.19656492148442353\n",
      "Average test loss:  0.5333795762326231\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1660677997137754\n",
      "Average test loss:  0.5318111518468421\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.14193142217257174\n",
      "Average test loss:  0.5337401633150276\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.12259476765242465\n",
      "Average test loss:  0.5385200578817421\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.10687863057313333\n",
      "Average test loss:  0.5451200701871329\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.09394523886386219\n",
      "Average test loss:  0.553769634062892\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.08318064003265709\n",
      "Average test loss:  0.5635332386616893\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07413551468597775\n",
      "Average test loss:  0.5741179164956955\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.06647257131548612\n",
      "Average test loss:  0.5853239065216118\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.05991539636776518\n",
      "Average test loss:  0.5969262459131454\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.05428872553464185\n",
      "Average test loss:  0.6090309363849676\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04941793555543974\n",
      "Average test loss:  0.6211519051620176\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.045192391966971286\n",
      "Average test loss:  0.6333733103386062\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04150975576149602\n",
      "Average test loss:  0.6456487105401855\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.03825443974096824\n",
      "Average test loss:  0.6575025714370335\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.03536276192868041\n",
      "Average test loss:  0.6696897525287748\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.03275831012921252\n",
      "Average test loss:  0.6814810514239001\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.030383526482242008\n",
      "Average test loss:  0.6935100747154607\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.02821877169244383\n",
      "Average test loss:  0.7055759797717066\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.026285604222728895\n",
      "Average test loss:  0.7176075954809308\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6915660062127778\n",
      "Average test loss:  0.6925983437637018\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.829375\n",
      "Average test accuracy:  0.59\n",
      "\n",
      "Average train loss:  0.6877659201673504\n",
      "Average test loss:  0.691271017810069\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.930625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.677749573402115\n",
      "Average test loss:  0.6878038226276241\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6524369433051248\n",
      "Average test loss:  0.6790440076052491\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5960797892029667\n",
      "Average test loss:  0.6594020468242987\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5039832559595598\n",
      "Average test loss:  0.6268713470221762\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.40288198113066515\n",
      "Average test loss:  0.592057551434898\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.31753251353140216\n",
      "Average test loss:  0.5647360671395577\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.25275371407258795\n",
      "Average test loss:  0.5474215613126603\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2045421136732872\n",
      "Average test loss:  0.5377530484722436\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.168328906137673\n",
      "Average test loss:  0.5349739961882763\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.14062955027445243\n",
      "Average test loss:  0.5366489655160288\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.11905710311767947\n",
      "Average test loss:  0.5413307169401103\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.10195284500615698\n",
      "Average test loss:  0.5490238829751317\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.08821121025272348\n",
      "Average test loss:  0.5585125691193086\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07700947406369246\n",
      "Average test loss:  0.5690165817236118\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06776436971443654\n",
      "Average test loss:  0.5805618031380742\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0600608922547903\n",
      "Average test loss:  0.5933455518704688\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.05359935563994883\n",
      "Average test loss:  0.6061907758259967\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.04812676811305788\n",
      "Average test loss:  0.6199097957446195\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.043468256069369764\n",
      "Average test loss:  0.6327797270622543\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.039470250075213716\n",
      "Average test loss:  0.646043694528862\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.03600558481514226\n",
      "Average test loss:  0.6592275632225522\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.03297790022993606\n",
      "Average test loss:  0.6728388994672855\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.03029682947893254\n",
      "Average test loss:  0.6857308871337162\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.027910777744424787\n",
      "Average test loss:  0.6985032373874566\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.025786418118611376\n",
      "Average test loss:  0.7118043553748366\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.02390414030435828\n",
      "Average test loss:  0.724730891016899\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.02223902664466176\n",
      "Average test loss:  0.7372953299506183\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.02076411343094349\n",
      "Average test loss:  0.7496574839606683\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.89375\n",
      "Average test accuracy:  0.6675\n",
      "\n",
      "Average train loss:  0.6902400660440323\n",
      "Average test loss:  0.6921229541654906\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.876875\n",
      "Average test accuracy:  0.68625\n",
      "\n",
      "Average train loss:  0.6839349456022047\n",
      "Average test loss:  0.6899349041388317\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.938125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.6669328687617044\n",
      "Average test loss:  0.6840006229697212\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.938125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6265741840450928\n",
      "Average test loss:  0.6699010681521361\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.94125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5509662472645388\n",
      "Average test loss:  0.6434769289643341\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.45179982628364024\n",
      "Average test loss:  0.6097947998169925\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.35636160800539357\n",
      "Average test loss:  0.5793889634560344\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.27977269135818816\n",
      "Average test loss:  0.5573593337668293\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.22230905137431103\n",
      "Average test loss:  0.5448607115112295\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.17955133954067304\n",
      "Average test loss:  0.5397316409574952\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.9825\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1474335444341569\n",
      "Average test loss:  0.5402467634739513\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1229095000924928\n",
      "Average test loss:  0.5446625438348746\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.10383244999172525\n",
      "Average test loss:  0.552181007841484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08875257554577333\n",
      "Average test loss:  0.5619663054906358\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.07665612518215427\n",
      "Average test loss:  0.5732450739182989\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.06681563584813123\n",
      "Average test loss:  0.5852954585133331\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.05873292345821534\n",
      "Average test loss:  0.5983522300739685\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.05201699887989373\n",
      "Average test loss:  0.611946756530898\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.04638368618011333\n",
      "Average test loss:  0.6260105255728049\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.04161943909145878\n",
      "Average test loss:  0.6402535845574066\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.03753898088054721\n",
      "Average test loss:  0.6543594913514426\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.03400693477818612\n",
      "Average test loss:  0.6686116389922226\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.030910755986718847\n",
      "Average test loss:  0.6824344172420579\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.028154387140563092\n",
      "Average test loss:  0.6967003991560681\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.02569987091173456\n",
      "Average test loss:  0.710865671816209\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.023530538356297412\n",
      "Average test loss:  0.7245046917945862\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.021628148217388867\n",
      "Average test loss:  0.7382273772101078\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.019968546319135697\n",
      "Average test loss:  0.7518567305205526\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.018512466268121437\n",
      "Average test loss:  0.7654958223450358\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.017222245319956527\n",
      "Average test loss:  0.778312324940277\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.646875\n",
      "Average test accuracy:  0.51125\n",
      "\n",
      "Average train loss:  0.6918403115272896\n",
      "Average test loss:  0.6926927996256057\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.9325\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.687903754482829\n",
      "Average test loss:  0.6913302580534753\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.923125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.6751484049241826\n",
      "Average test loss:  0.6868957034819774\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.640412969852735\n",
      "Average test loss:  0.6747421197617484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.94375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5651720381671854\n",
      "Average test loss:  0.6482258972871559\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.4565411268181627\n",
      "Average test loss:  0.6106680603929868\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3518900188705792\n",
      "Average test loss:  0.5761576952074782\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2703751748948196\n",
      "Average test loss:  0.553066671105542\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.21124787860737237\n",
      "Average test loss:  0.5411635731955162\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.16853462352986817\n",
      "Average test loss:  0.5372684652701805\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.13708720451158815\n",
      "Average test loss:  0.539088168360616\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.11347368541955412\n",
      "Average test loss:  0.5456099181690538\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09532665896966852\n",
      "Average test loss:  0.5547574285018927\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08113780261832045\n",
      "Average test loss:  0.5661883571197884\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.06983478160055095\n",
      "Average test loss:  0.578905617301725\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.060703104799298656\n",
      "Average test loss:  0.5928087070573794\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.05323457673934926\n",
      "Average test loss:  0.607383305819461\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.04705633102943563\n",
      "Average test loss:  0.6220183203618895\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.04189224038043388\n",
      "Average test loss:  0.6372331710401368\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.03752767186757663\n",
      "Average test loss:  0.6523532084414195\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.033793743965627274\n",
      "Average test loss:  0.6673826486906235\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.030562726736307427\n",
      "Average test loss:  0.6826235121842101\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.027732851418894616\n",
      "Average test loss:  0.6972595615717644\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.02524193566153819\n",
      "Average test loss:  0.7123158921998806\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.023031510264960826\n",
      "Average test loss:  0.7270145706773796\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.021087290882613494\n",
      "Average test loss:  0.7422270587983332\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.01936905139889084\n",
      "Average test loss:  0.7563057248455752\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.01787326244828478\n",
      "Average test loss:  0.7707737850602179\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.01656241671882557\n",
      "Average test loss:  0.7842791316404073\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.015410383789758819\n",
      "Average test loss:  0.7981881305821598\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.651875\n",
      "Average test accuracy:  0.54125\n",
      "\n",
      "Average train loss:  0.690194640282232\n",
      "Average test loss:  0.6921295304697175\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.936875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6835247981263314\n",
      "Average test loss:  0.6898264080657345\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6651353697582879\n",
      "Average test loss:  0.6834679232145596\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.620763632594071\n",
      "Average test loss:  0.6681847280366534\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.5358204396594619\n",
      "Average test loss:  0.6393785145154346\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.4254620227204158\n",
      "Average test loss:  0.6030061708092376\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3246241201164138\n",
      "Average test loss:  0.5722866043634065\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2484493997184132\n",
      "Average test loss:  0.5541884821598546\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.19372283476634203\n",
      "Average test loss:  0.5455688165532137\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1544158008499589\n",
      "Average test loss:  0.5443089889388187\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1255783659161572\n",
      "Average test loss:  0.5490790471376629\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.10393619097395912\n",
      "Average test loss:  0.5570930973440267\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08731963727085545\n",
      "Average test loss:  0.568219861207436\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.07431745444848199\n",
      "Average test loss:  0.5809723012779991\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.06397449137377699\n",
      "Average test loss:  0.5950262231472188\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.0556267619519464\n",
      "Average test loss:  0.6095114671278243\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.048786653540206705\n",
      "Average test loss:  0.6246092028660467\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.04311997648321064\n",
      "Average test loss:  0.6413443620662541\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.03837760237465753\n",
      "Average test loss:  0.6564242531494896\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.03435839222234959\n",
      "Average test loss:  0.6719712906841663\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.03091051690840134\n",
      "Average test loss:  0.6876986217864056\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.02792765575119061\n",
      "Average test loss:  0.7037223348200335\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.025327684247595256\n",
      "Average test loss:  0.7191983860158118\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.02305200592255686\n",
      "Average test loss:  0.7341276278797998\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.021058166956172398\n",
      "Average test loss:  0.7497232008349579\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.01931517475628769\n",
      "Average test loss:  0.7646120979206424\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.01778660860625035\n",
      "Average test loss:  0.7792271598526724\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.016422306420772675\n",
      "Average test loss:  0.7938027382667657\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.01519553496419527\n",
      "Average test loss:  0.8084247862703128\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.014074811842885638\n",
      "Average test loss:  0.8219846699348694\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6913848646383344\n",
      "Average test loss:  0.6928267528811866\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.60875\n",
      "Average test accuracy:  0.53\n",
      "\n",
      "Average train loss:  0.6868873201295664\n",
      "Average test loss:  0.6910035334482368\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.770625\n",
      "Average test accuracy:  0.6\n",
      "\n",
      "Average train loss:  0.678935603028021\n",
      "Average test loss:  0.688236105842115\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.86625\n",
      "Average test accuracy:  0.66875\n",
      "\n",
      "Average train loss:  0.6619078226349836\n",
      "Average test loss:  0.6822554891192295\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.91875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.6272506882207983\n",
      "Average test loss:  0.6699310514114676\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.5649780466679492\n",
      "Average test loss:  0.647758068738513\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.4762475099383803\n",
      "Average test loss:  0.6166192664937759\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.3811356285958829\n",
      "Average test loss:  0.5850372387107633\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.29884295621958656\n",
      "Average test loss:  0.5608578526786033\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.235323118017714\n",
      "Average test loss:  0.5460935839561015\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.18801104708874483\n",
      "Average test loss:  0.5396248418622887\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.15284225318497932\n",
      "Average test loss:  0.5396565710344384\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.12626372823429452\n",
      "Average test loss:  0.5437723766828394\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1058654442177801\n",
      "Average test loss:  0.5512560255901825\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.08991695434753955\n",
      "Average test loss:  0.5609398493437087\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.07724890055432729\n",
      "Average test loss:  0.5721654720370034\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.06702060286469928\n",
      "Average test loss:  0.5851590304041737\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.058655407364565613\n",
      "Average test loss:  0.5986737729849056\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.051733460503270406\n",
      "Average test loss:  0.6125279411763428\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.045947417314277476\n",
      "Average test loss:  0.6271150343845744\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.04104426232240263\n",
      "Average test loss:  0.6415311092231386\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.03686400086343324\n",
      "Average test loss:  0.6562794434172879\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.03326634595275732\n",
      "Average test loss:  0.671248275857602\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.030134077459048846\n",
      "Average test loss:  0.6859841067885428\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.027392308122508983\n",
      "Average test loss:  0.7005723461157549\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.024980051200927073\n",
      "Average test loss:  0.7151627443568483\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.02285471312326606\n",
      "Average test loss:  0.729637859028715\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.020980702941024266\n",
      "Average test loss:  0.7438528357399172\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.019327259639881245\n",
      "Average test loss:  0.7581489794059236\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.01785850340593904\n",
      "Average test loss:  0.7722965596360045\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.930625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.6898233922125718\n",
      "Average test loss:  0.6919957612997522\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.9\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.6810801109643229\n",
      "Average test loss:  0.6889890905066793\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.6560608514567288\n",
      "Average test loss:  0.6803707339363706\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.5962152771643247\n",
      "Average test loss:  0.659697718646542\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.49214167689284133\n",
      "Average test loss:  0.6238769592075942\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.37282580678272065\n",
      "Average test loss:  0.5841706729547426\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2743368774557093\n",
      "Average test loss:  0.5561481186365453\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.20496067150593567\n",
      "Average test loss:  0.5418334685736043\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1573788181828434\n",
      "Average test loss:  0.5388479458385266\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.12411177450965664\n",
      "Average test loss:  0.54279023995305\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.10016134435741862\n",
      "Average test loss:  0.5522865560276459\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.08241872293161791\n",
      "Average test loss:  0.5648292134538812\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06892078151311487\n",
      "Average test loss:  0.5795757455071247\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.05843490318879648\n",
      "Average test loss:  0.5956477762149083\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.050152913505295584\n",
      "Average test loss:  0.6128690267361033\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.043461717577530055\n",
      "Average test loss:  0.6299642044408275\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.03801297557024683\n",
      "Average test loss:  0.6480769996366003\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.03349342726817636\n",
      "Average test loss:  0.6659230223232778\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.029706191012159988\n",
      "Average test loss:  0.6839125861080771\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.02651169634616861\n",
      "Average test loss:  0.7015751642170973\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.02377437338179787\n",
      "Average test loss:  0.718804420597457\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.02142825595289437\n",
      "Average test loss:  0.7368503711118825\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.01942220325785207\n",
      "Average test loss:  0.7533260720670004\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.017702221304744456\n",
      "Average test loss:  0.7700229780027588\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.016217470245262607\n",
      "Average test loss:  0.7867554305278276\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.014921883254150661\n",
      "Average test loss:  0.802740653964907\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.013786399605503569\n",
      "Average test loss:  0.8184525048545245\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.012775076456510331\n",
      "Average test loss:  0.833486272861491\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.011864850613481368\n",
      "Average test loss:  0.8488255047319586\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.999375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.01103171680583856\n",
      "Average test loss:  0.8638588774973764\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_range = 20\n",
    "model_list = []\n",
    "aver_train_score = []\n",
    "aver_test_score = []\n",
    "aver_train_loss = []\n",
    "aver_test_loss = []\n",
    "\n",
    "\n",
    "for t in range(10):\n",
    "    for i in range(10):\n",
    "        for iteration in range(30):\n",
    "            k = 3\n",
    "            kfold = KFold(n_splits=k)\n",
    "\n",
    "            train_scores = []\n",
    "            test_scores = []\n",
    "            train_loss = []\n",
    "            test_loss = []\n",
    "\n",
    "            model = MLPClassifier(hidden_layer_sizes=(t+1,i+2), \n",
    "                            activation='logistic',\n",
    "                            solver='adam',\n",
    "                            alpha=0.0001,\n",
    "                            max_iter=(iteration+1)*10, tol=1e-6,\n",
    "                            random_state=1)\n",
    "            for train_idx, test_idx in kfold.split(X):\n",
    "                X_train, X_test = X[train_idx,:], X[test_idx,:]\n",
    "                y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "                pred_train = model.predict_proba(X_train)\n",
    "                pred_test = model.predict_proba(X_test)\n",
    "\n",
    "                # Score\n",
    "                score_train = model.score(X_train, y_train)\n",
    "                score_test = model.score(X_test, y_test)\n",
    "        #         print(\"Train score: \", score_train)\n",
    "        #         print(\"Test score: \", score_test)\n",
    "                train_scores.append(score_train)\n",
    "                test_scores.append(score_test)\n",
    "\n",
    "                # Log loss\n",
    "                log_loss_train = sklearn.metrics.log_loss(y_train,pred_train)\n",
    "                log_loss_test = sklearn.metrics.log_loss(y_test,pred_test)\n",
    "\n",
    "        #         print(\"Train loss: \", log_loss_train)\n",
    "        #         print(\"Test loss: \", log_loss_test)\n",
    "                train_loss.append(log_loss_train)\n",
    "                test_loss.append(log_loss_test)\n",
    "                \n",
    "\n",
    "        #         with warnings.catch_warnings(record=True) as warn_list:\n",
    "        #             print('finished LBFGS run :loss %.3f' % (\n",
    "        #              model.loss_))\n",
    "\n",
    "\n",
    "            print(\"For layers: \", t+1)\n",
    "            print(\"For neurons: \", i+2)\n",
    "            print(\"For iteration \", iteration)\n",
    "            print(\"\\nAverage train accuracy: \", np.average(score_train))\n",
    "            print(\"Average test accuracy: \", np.average(score_test))\n",
    "            print(\"\\nAverage train loss: \", np.average(train_loss))\n",
    "            print(\"Average test loss: \", np.average(test_loss))\n",
    "\n",
    "            print('------------------------------------------------\\n')\n",
    "\n",
    "            model_list.append(model)\n",
    "            aver_train_score.append(np.average(score_train))\n",
    "            aver_test_score.append(np.average(score_test))\n",
    "            aver_train_loss.append(np.average(train_loss))\n",
    "            aver_test_loss.append(np.average(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-liberia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-billy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-darkness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-elements",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-belly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-lesson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "olympic-duration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.2525871555196859\n",
      "Average test loss:  0.5529021593449074\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.16544085661120578\n",
      "Average test loss:  0.531230149708258\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.19987350894069736\n",
      "Average test loss:  0.5287224333308699\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10414667707988723\n",
      "Average test loss:  0.5512385327913806\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.21429429376424078\n",
      "Average test loss:  0.5386748088813648\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07509364781552565\n",
      "Average test loss:  0.5696426705283861\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07617205310687791\n",
      "Average test loss:  0.5758523468755062\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0640948562731881\n",
      "Average test loss:  0.5861660324441882\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.055654427207649855\n",
      "Average test loss:  0.5985187706842376\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07139325674109574\n",
      "Average test loss:  0.577739114907101\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_range = 20\n",
    "model_list = []\n",
    "aver_train_score = []\n",
    "aver_test_score = []\n",
    "aver_train_loss = []\n",
    "aver_test_loss = []\n",
    "\n",
    "\n",
    "# for t in range(10):\n",
    "for i in range(10):\n",
    "# for iteration in range(30):\n",
    "    k = 3\n",
    "    kfold = KFold(n_splits=k)\n",
    "\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "\n",
    "    model = MLPClassifier(hidden_layer_sizes=(8,i+2), \n",
    "                    activation='logistic',\n",
    "                    solver='adam',\n",
    "                    alpha=0.0001,\n",
    "                    max_iter=160, tol=1e-6,\n",
    "                    random_state=1)\n",
    "    for train_idx, test_idx in kfold.split(X):\n",
    "        X_train, X_test = X[train_idx,:], X[test_idx,:]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = model.predict_proba(X_train)\n",
    "        pred_test = model.predict_proba(X_test)\n",
    "\n",
    "        # Score\n",
    "        score_train = model.score(X_train, y_train)\n",
    "        score_test = model.score(X_test, y_test)\n",
    "#         print(\"Train score: \", score_train)\n",
    "#         print(\"Test score: \", score_test)\n",
    "        train_scores.append(score_train)\n",
    "        test_scores.append(score_test)\n",
    "\n",
    "        # Log loss\n",
    "        log_loss_train = sklearn.metrics.log_loss(y_train,pred_train)\n",
    "        log_loss_test = sklearn.metrics.log_loss(y_test,pred_test)\n",
    "\n",
    "#         print(\"Train loss: \", log_loss_train)\n",
    "#         print(\"Test loss: \", log_loss_test)\n",
    "        train_loss.append(log_loss_train)\n",
    "        test_loss.append(log_loss_test)\n",
    "\n",
    "\n",
    "#         with warnings.catch_warnings(record=True) as warn_list:\n",
    "#             print('finished LBFGS run :loss %.3f' % (\n",
    "#              model.loss_))\n",
    "\n",
    "\n",
    "    print(\"For layers: \", 8)\n",
    "    print(\"For neurons: \", 4)\n",
    "    print(\"For iteration \", iteration)\n",
    "    print(\"\\nAverage train accuracy: \", np.average(score_train))\n",
    "    print(\"Average test accuracy: \", np.average(score_test))\n",
    "    print(\"\\nAverage train loss: \", np.average(train_loss))\n",
    "    print(\"Average test loss: \", np.average(test_loss))\n",
    "\n",
    "    print('------------------------------------------------\\n')\n",
    "\n",
    "    model_list.append(model)\n",
    "    aver_train_score.append(np.average(score_train))\n",
    "    aver_test_score.append(np.average(score_test))\n",
    "    aver_train_loss.append(np.average(train_loss))\n",
    "    aver_test_loss.append(np.average(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-spell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-leisure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-record",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-flavor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-portland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-fourth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "spare-management",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.4739570696645874\n",
      "Average test loss:  0.6131862312315367\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.29972138479208216\n",
      "Average test loss:  0.5623977672711454\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3060734564397008\n",
      "Average test loss:  0.5581603555474728\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.22138211119669102\n",
      "Average test loss:  0.5386824572978521\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.17138203257606097\n",
      "Average test loss:  0.5402437221437693\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.15848718578846868\n",
      "Average test loss:  0.5346449615208004\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.13008177477548555\n",
      "Average test loss:  0.5385779263164813\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.19987350894069736\n",
      "Average test loss:  0.5287224333308699\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.14279082394595957\n",
      "Average test loss:  0.5414365325985738\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.13362551509182838\n",
      "Average test loss:  0.5351659854503366\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_range = 20\n",
    "model_list = []\n",
    "aver_train_score = []\n",
    "aver_test_score = []\n",
    "aver_train_loss = []\n",
    "aver_test_loss = []\n",
    "\n",
    "\n",
    "for t in range(10):\n",
    "# for i in range(10):\n",
    "# for iteration in range(30):\n",
    "    k = 3\n",
    "    kfold = KFold(n_splits=k)\n",
    "\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "\n",
    "    model = MLPClassifier(hidden_layer_sizes=(t+1,4), \n",
    "                    activation='logistic',\n",
    "                    solver='adam',\n",
    "                    alpha=0.0001,\n",
    "                    max_iter=160, tol=1e-6,\n",
    "                    random_state=1)\n",
    "    for train_idx, test_idx in kfold.split(X):\n",
    "        X_train, X_test = X[train_idx,:], X[test_idx,:]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = model.predict_proba(X_train)\n",
    "        pred_test = model.predict_proba(X_test)\n",
    "\n",
    "        # Score\n",
    "        score_train = model.score(X_train, y_train)\n",
    "        score_test = model.score(X_test, y_test)\n",
    "#         print(\"Train score: \", score_train)\n",
    "#         print(\"Test score: \", score_test)\n",
    "        train_scores.append(score_train)\n",
    "        test_scores.append(score_test)\n",
    "\n",
    "        # Log loss\n",
    "        log_loss_train = sklearn.metrics.log_loss(y_train,pred_train)\n",
    "        log_loss_test = sklearn.metrics.log_loss(y_test,pred_test)\n",
    "\n",
    "#         print(\"Train loss: \", log_loss_train)\n",
    "#         print(\"Test loss: \", log_loss_test)\n",
    "        train_loss.append(log_loss_train)\n",
    "        test_loss.append(log_loss_test)\n",
    "\n",
    "\n",
    "#         with warnings.catch_warnings(record=True) as warn_list:\n",
    "#             print('finished LBFGS run :loss %.3f' % (\n",
    "#              model.loss_))\n",
    "\n",
    "\n",
    "    print(\"For layers: \", 8)\n",
    "    print(\"For neurons: \", 4)\n",
    "    print(\"For iteration \", iteration)\n",
    "    print(\"\\nAverage train accuracy: \", np.average(score_train))\n",
    "    print(\"Average test accuracy: \", np.average(score_test))\n",
    "    print(\"\\nAverage train loss: \", np.average(train_loss))\n",
    "    print(\"Average test loss: \", np.average(test_loss))\n",
    "\n",
    "    print('------------------------------------------------\\n')\n",
    "\n",
    "    model_list.append(model)\n",
    "    aver_train_score.append(np.average(score_train))\n",
    "    aver_test_score.append(np.average(score_test))\n",
    "    aver_train_loss.append(np.average(train_loss))\n",
    "    aver_test_loss.append(np.average(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "received-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = min(aver_test_loss)\n",
    "index_N2 = aver_test_loss.index(min_loss)\n",
    "index_N2\n",
    "# best_C =  C_grid[index_N2]\n",
    "best_model = model_list[index_N2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-aside",
   "metadata": {},
   "source": [
    "## change  layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bound-manner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aver_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "close-pearl",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_layer_index = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "y_layer_averloss_train = [aver_train_loss[i-1] for i in x_layer_index]\n",
    "y_layer_averloss_test =  [aver_test_loss[i-1] for i in x_layer_index]\n",
    "\n",
    "y_layer_score_train = [aver_train_score[i-1] for i in x_layer_index]\n",
    "y_layer_score_test =  [aver_test_score[i-1] for i in x_layer_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "sublime-flavor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('layer number i');\n",
    "plt.ylabel('logistic loss');\n",
    "# plt.ylim([0.0, 1]);\n",
    "\n",
    "sns.lineplot(x = x_layer_index, y = y_layer_averloss_train, label = \"Train \", color = \"red\", marker='o')\n",
    "sns.lineplot(x = x_layer_index, y = y_layer_averloss_test,label = \"Test\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Test/Train loss on changing layers')\n",
    "plt.show()\n",
    "\n",
    "# print(\"Best C-value for LR: %.3f\" % best_C) \n",
    "# print(\"Test set log-loss at best C-value: %.4f\" % min_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "opposite-simon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('layer number i');\n",
    "plt.ylabel('Accuracy score');\n",
    "# plt.ylim([0.0, 1]);\n",
    "\n",
    "sns.lineplot(x = x_layer_index, y = y_layer_score_train, label = \"Train \", color = \"red\", marker='o')\n",
    "sns.lineplot(x = x_layer_index, y = y_layer_score_test,label = \"Test\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Test/Train accuracy on changing neuron per layer')\n",
    "plt.show()\n",
    "\n",
    "# print(\"Best C-value for LR: %.3f\" % best_C) \n",
    "# print(\"Test set log-loss at best C-value: %.4f\" % min_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-manufacturer",
   "metadata": {},
   "source": [
    "## change neuron per layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "administrative-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_neuron_index = np.array([2,3,4,5,6,7,8,9,10,11])\n",
    "y_neuron_averloss_train = [aver_train_loss[i-2] for i in x_neuron_index]\n",
    "y_neuron_averloss_test =  [aver_test_loss[i-2] for i in x_neuron_index]\n",
    "\n",
    "y_neuron_score_train = [aver_train_score[i-2] for i in x_neuron_index]\n",
    "y_neuron_score_test =  [aver_test_score[2115+30*(i-2)] for i in x_neuron_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "demonstrated-folder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('neuron per layer');\n",
    "plt.ylabel('logistic loss');\n",
    "plt.ylim([0.0, 1]);\n",
    "\n",
    "sns.lineplot(x = x_neuron_index, y = y_neuron_averloss_train, label = \"Train Loss\", color = \"red\", marker='o')\n",
    "sns.lineplot(x = x_neuron_index, y = y_neuron_averloss_test, label = \"Test Loss\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Test/Train loss on changing neuron per layer')\n",
    "plt.show()\n",
    "\n",
    "# print(\"Best C-value for LR: %.3f\" % best_C) \n",
    "# print(\"Test set log-loss at best C-value: %.4f\" % min_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "described-diabetes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('neuron per layer');\n",
    "plt.ylabel('Accuracy score');\n",
    "# plt.ylim([0.0, 1]);\n",
    "\n",
    "\n",
    "sns.lineplot(x = x_neuron_index, y = y_neuron_averloss_train, label = \"Train\", color = \"red\", marker='o')\n",
    "sns.lineplot(x = x_neuron_index, y = aver_test_score, label = \"Test\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Average accuracy score on Test/Validation set')\n",
    "plt.show()\n",
    "\n",
    "# print(\"Best C-value for LR: %.3f\" % best_C) \n",
    "# print(\"Test set log-loss at best C-value: %.4f\" % min_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-transcript",
   "metadata": {},
   "source": [
    "## change iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "green-point",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aver_train_los' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-9ce872acfb1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maver_train_los\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'aver_train_los' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-administrator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "continuing-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_iteration_index = np.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30])\n",
    "# y_iteration_averloss_train = [aver_train_loss[2130+i] for i in x_iteration_index]\n",
    "# y_iteration_averloss_test =  [aver_test_loss[2130+i] for i in x_iteration_index]\n",
    "\n",
    "\n",
    "y_iteration_score_train = [aver_train_score[i-1] for i in x_iteration_index]\n",
    "y_iteration_score_test = [aver_test_score[i-1] for i in x_iteration_index]\n",
    "\n",
    "# y_iteration_score_train = np.array([0.5,0.5,0.5,0.834375,0.916875,0.93, 0.933125,0.9425,0.95,0.956875,0.961875,0.96875,0.973125,0.975625, 0.979375,0.98375,0.98625,0.98875,0.98875,0.989375,0.99,0.991875,0.99375,0.994375, 0.995,0.995625, 0.996875,0.996875,0.9975])\n",
    "\n",
    "# y_iteration_score_test =  np.array([0.5,0.5,0.5,0.62875,0.72875,0.73875,0.73875,0.74,0.7425,0.7375,0.73625,0.73875,0.74125,0.7425,0.7425,0.73875,0.73375,0.7325,0.72625,0.72375,0.7275,0.72625,0.725,0.7225,0.72375,0.7225,0.7225, 0.72125,0.7225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "marked-romania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Max iteration');\n",
    "plt.ylabel('logistic loss');\n",
    "plt.ylim([0.0, 1]);\n",
    "\n",
    "sns.lineplot(x = x_iteration_index*10, y = y_iteration_averloss_train, label = \"Train Loss\", color = \"red\", marker='o')\n",
    "sns.lineplot(x = x_iteration_index*10, y = y_iteration_averloss_test, label = \"Test Loss\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Test/Train loss on changing max iteration')\n",
    "plt.show()\n",
    "\n",
    "# print(\"Best C-value for LR: %.3f\" % best_C) \n",
    "# print(\"Test set log-loss at best C-value: %.4f\" % min_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "opponent-audio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Max iteration');\n",
    "plt.ylabel('Accuracy');\n",
    "# plt.ylim([0.0, 1]);\n",
    "\n",
    "sns.lineplot(x = x_iteration_index*10, y = y_iteration_score_train, label = \"Train\", color = \"red\", marker='o')\n",
    "sns.lineplot(x = x_iteration_index*10, y = y_iteration_score_test, label = \"Test\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Test/Train Accuracy on changing max iteration')\n",
    "plt.show()\n",
    "\n",
    "# print(\"Best C-value for LR: %.3f\" % best_C) \n",
    "# print(\"Test set log-loss at best C-value: %.4f\" % min_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "competent-description",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i_range = [2,3,4,5,6,7,8,9,10,11]\n",
    "layer_range = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "\n",
    "for i in i_range:\n",
    "    for l in layer_range:\n",
    "        x_i = \n",
    "plt.xlabel('Neuron number i');\n",
    "plt.ylabel('logistic loss');\n",
    "plt.ylim([0.0, 1]);\n",
    "\n",
    "sns.lineplot(x = i_range, y = aver_train_score, label = \"Train Loss\", color = \"red\", marker='o')\n",
    "sns.lineplot(x = i_range, y = aver_test_score,label = \"Test Loss\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Best number of neuron in 1 layer')\n",
    "plt.show()\n",
    "\n",
    "# print(\"Best C-value for LR: %.3f\" % best_C) \n",
    "# print(\"Test set log-loss at best C-value: %.4f\" % min_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-moisture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "christian-haiti",
   "metadata": {},
   "source": [
    "## Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-control",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "perfect-lightweight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i_range = [2,3,4,5,6,7,8,9,10,11]\n",
    "layer_range = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "\n",
    "for i in i_range:\n",
    "    for l in layer_range:\n",
    "        x_i = \n",
    "plt.xlabel('Neuron number i');\n",
    "plt.ylabel('logistic loss');\n",
    "plt.ylim([0.0, 1]);\n",
    "\n",
    "sns.lineplot(x = i_range, y = aver_train_loss, label = \"Train Loss\", color = \"red\", marker='o')\n",
    "sns.lineplot(x = i_range, y = aver_test_loss,label = \"Test Loss\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Best number of neuron in 1 layer')\n",
    "plt.show()\n",
    "\n",
    "# print(\"Best C-value for LR: %.3f\" % best_C) \n",
    "# print(\"Test set log-loss at best C-value: %.4f\" % min_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_range = 20\n",
    "model_list = []\n",
    "aver_train_score = []\n",
    "aver_test_score = []\n",
    "aver_train_loss = []\n",
    "aver_test_loss = []\n",
    "\n",
    "\n",
    "for t in range(10):\n",
    "    for i in range(10):\n",
    "        for iteration in range(30):\n",
    "            k = 3\n",
    "            kfold = KFold(n_splits=k)\n",
    "\n",
    "            train_scores = []\n",
    "            test_scores = []\n",
    "            train_loss = []\n",
    "            test_loss = []\n",
    "\n",
    "            model = MLPClassifier(hidden_layer_sizes=(t+1,i+2), \n",
    "                            activation='relu',\n",
    "                            solver='adam',\n",
    "                            alpha=0.0001,\n",
    "                            max_iter=(iteration+1)*10, tol=1e-6,\n",
    "                            random_state=1)\n",
    "            for train_idx, test_idx in kfold.split(X):\n",
    "                X_train, X_test = X[train_idx,:], X[test_idx,:]\n",
    "                y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "                pred_train = model.predict_proba(X_train)\n",
    "                pred_test = model.predict_proba(X_test)\n",
    "\n",
    "                # Score\n",
    "                score_train = model.score(X_train, y_train)\n",
    "                score_test = model.score(X_test, y_test)\n",
    "        #         print(\"Train score: \", score_train)\n",
    "        #         print(\"Test score: \", score_test)\n",
    "                train_scores.append(score_train)\n",
    "                test_scores.append(score_test)\n",
    "\n",
    "                # Log loss\n",
    "                log_loss_train = sklearn.metrics.log_loss(y_train,pred_train)\n",
    "                log_loss_test = sklearn.metrics.log_loss(y_test,pred_test)\n",
    "\n",
    "        #         print(\"Train loss: \", log_loss_train)\n",
    "        #         print(\"Test loss: \", log_loss_test)\n",
    "                train_loss.append(log_loss_train)\n",
    "                test_loss.append(log_loss_test)\n",
    "\n",
    "        #         with warnings.catch_warnings(record=True) as warn_list:\n",
    "        #             print('finished LBFGS run :loss %.3f' % (\n",
    "        #              model.loss_))\n",
    "\n",
    "\n",
    "            print(\"For layers: \", t+1)\n",
    "            print(\"For neurons: \", i+2)\n",
    "            print(\"For iteration \", iteration)\n",
    "            print(\"\\nAverage train accuracy: \", np.average(score_train))\n",
    "            print(\"Average test accuracy: \", np.average(score_test))\n",
    "            print(\"\\nAverage train loss: \", np.average(train_loss))\n",
    "            print(\"Average test loss: \", np.average(test_loss))\n",
    "\n",
    "            print('------------------------------------------------\\n')\n",
    "\n",
    "            model_list.append(model)\n",
    "            aver_train_score.append(np.average(score_train))\n",
    "            aver_test_score.append(np.average(score_test))\n",
    "            aver_train_loss.append(np.average(train_loss))\n",
    "            aver_test_loss.append(np.average(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-marriage",
   "metadata": {},
   "source": [
    "# Cross Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-wound",
   "metadata": {},
   "source": [
    "### stability over k folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "written-orlando",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Classify with base data, 5 folds\n",
      "-----------------\n",
      "\n",
      "Average train accuracy:  0.9108333333333334\n",
      "Average test accuracy:  0.8933333333333333\n",
      "Average train loss:  0.2855729771739258\n",
      "Average test loss:  0.29108663560482273\n",
      "\n",
      "Average train accuracy:  0.8975\n",
      "Average test accuracy:  0.91125\n",
      "Average train loss:  0.28926782520393757\n",
      "Average test loss:  0.2864537687602477\n",
      "\n",
      "Average train accuracy:  0.9\n",
      "Average test accuracy:  0.9083333333333333\n",
      "Average train loss:  0.2871247872285715\n",
      "Average test loss:  0.29194486387178264\n",
      "\n",
      "Average train accuracy:  0.9046875\n",
      "Average test accuracy:  0.8916666666666667\n",
      "Average train loss:  0.2880740786474457\n",
      "Average test loss:  0.2893527173570883\n",
      "\n",
      "Average train accuracy:  0.9047619047619048\n",
      "Average test accuracy:  0.8833333333333333\n",
      "Average train loss:  0.2880419294442421\n",
      "Average test loss:  0.29034494500529956\n",
      "\n",
      "Average train accuracy:  0.9013888888888889\n",
      "Average test accuracy:  0.9083333333333333\n",
      "Average train loss:  0.2887668867616243\n",
      "Average test loss:  0.2843960830391238\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------\\nClassify with base data, 5 folds\\n-----------------\")\n",
    "\n",
    "K = [2,3,4,5,8,10]\n",
    "K_train_loss = []\n",
    "K_test_loss = []\n",
    "for k in K:\n",
    "    kfold = KFold(n_splits=k)\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    \n",
    "    for train_idx, test_idx in kfold.split(X):\n",
    "        shuffler = np.random.permutation(len(X))\n",
    "        X_shuffled = X[shuffler]\n",
    "        y_shuffled = y[shuffler]\n",
    "        X_train, X_test = X_shuffled[train_idx,:], X_shuffled[test_idx,:]\n",
    "        y_train, y_test = y_shuffled[train_idx], y_shuffled[test_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = best_model.predict_proba(X_train)\n",
    "        pred_test = best_model.predict_proba(X_test)\n",
    "\n",
    "        score_train = best_model.score(X_train, y_train)\n",
    "        score_test = best_model.score(X_test, y_test)\n",
    "        train_scores.append(score_train)\n",
    "        test_scores.append(score_test)\n",
    "        \n",
    "        log_loss_train = sklearn.metrics.log_loss(y_train,pred_train)\n",
    "        log_loss_test = sklearn.metrics.log_loss(y_test,pred_test)\n",
    "        \n",
    "        train_loss.append(log_loss_train)\n",
    "        test_loss.append(log_loss_test)\n",
    "\n",
    "    print(\"\\nAverage train accuracy: \", np.average(score_train))\n",
    "    print(\"Average test accuracy: \", np.average(score_test))\n",
    "    print(\"Average train loss: \", np.average(train_loss))\n",
    "    print(\"Average test loss: \", np.average(test_loss))\n",
    "    \n",
    "    K_train_loss.append(np.average(train_loss))\n",
    "    K_test_loss.append(np.average(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "editorial-bubble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAETCAYAAADH1SqlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABYWklEQVR4nO3dd3gU1frA8e/MbjabkBAQIhYUROXYIkqTFhNEDEHwYqfaEEEFBfXaCxauFURABcSCoNjxghKKQgpVUVRQOcj1evWnqJQQ0rfN74/ZkE1I2SS72c3mfJ4nT7IzszPvbpJ593TNMAwURVEUpSZ6qANQFEVRwp9KFoqiKEqtVLJQFEVRaqWShaIoilIrlSwURVGUWqlkoSiKotRKJQul0QghOgohCoJ4fkMI0TZY5w9nQog3hBB3+TxOEEJkCyE+EEJEB+D8mUKIKxp6HqXpUslCUSKMEOJoYB3wHXCVlLI0xCEpEcAa6gAUBcxPwsCLwDmAAWQA90spXUKIwcDTgBv4BrgQ6Cel/KWG8z0EjABcwC5gopTyTyHEZcCDgMd7vn9KKbOr217pnC2Al4FTgTZAPjBSSimFEMcAc4HTvOeYK6WcJYTIBA54t78MLPV+7whowEIp5bNCCCswG+gLOIGfgeuBkqq2SymrLKEJIU4EVgOLpJTTqjlmIzBdSvmh9/HT3l2PVff6fJ7bEdghpYyr5vFY4BbMD6L7ve/7TiFEP2AGYMH8/T5Zdn2laVAlCyVczMK8uSQB3YEuwF1CiDbAImC0lPIczE/Mx9d0IiHE9UA60ENKeTawA3jDu/tZ4BYpZXfgISC1lu2+0oGDUsreUsrOwJfARO++l4BdUsrTgN7ATUKIU7z7cqWUZ0gpZwNvAeuklEmYCWC0EGK49zmpQBcpZTfMpHB2DdurfOnAeiAaeL6Gt+gVzESEEMICjAYW1PL6aiWESAGuBZKllOcCz2AmR4BHgRne13ADcIG/51XCgypZKOEiHegrpTSAUiHEXGAyIIEfpJTfAkgpFwohZvlxrtellIXexy8ADwghbMA7wFIhxKfAGswbGjVsP0xK+YEQ4mchxCTgFMyb+Cbv7guBu73H5QFnAQghAHK8P7fATBAXlR0nhHjDG+/tmCWaLUKIVcCHUsovhBCtqtpezeseBVwN3Ip58x9ZzXHvAs95S0NdMZPcT8BPNbw+f1zsfd5G7+sGaC2EOAp4D3hRCDEU+Ay4vw7nVcKAKlko4ULHrJ7wfRyFWY2kVTrWU8u5yqo6fM9lBTQp5QNAP2ArcB2QDVDddl9CiJuBV4Ei4G1giU9sLt9rCiE6CSFaeh+WVRnpVbwWHYiSUh7EW5rCTA7vCiFuqW57Na97mpRyOWZJIVkIcUdVB0kpi4D3MZPJ9ZiJpbbXV8aotM3m87MFs/rrHG8psCtmKTFXSjkPs9S4BkgDvhNC2Kt5HUoYUslCCRergIlCCM3be+cmzBvLBqCzEOJsACHE5UArKiaDylYCN3g/yQPchnnzdwshfgFipZRzMevWzxZCRFe3vdJ504A3pJSvYpZ4hmLeIMH8tFxWtZMAfI5Z93+YlDIf2Iz5yb/suGuANUKIId7nbJRSTgXeBHpUt72a113qvc4+YDgwTQiRWs2xr2BWGfUFytoOanp9ZQ4CNiHEGd7HI3z2rQJGCCGO9T6e4I29rJ3kXCnlG5i/21bAMdXEpoQhlSyUxtZCCFFQ6SsJ84Z+NLDd+yUxPykfwLwhvSmE+BrzhubC/PRbnVcxb95fCCF+xPyEO0pK6cKs2nrbe673gRu8vYWq2+7rOWC8EOI7zKqlrzGrXcCs2z/du28DZgPuV1XENgoYIITYDnwBfITZnpIBfA/sEEJsBfpg1vNXt71GUsoNwMOYJZH2Vez/CrOk8oGUssSP11f2vDzM6rYMIcSXQLHPvtWYHRHWeM8xErjMW7V4N/CYEGIbkAk8WlMHBSX8aGqKciWceatyHgSmSimLhBBdgU+B47w3IUVRGoFKFkrYE0I8AVyK2XXUCdwhpcwJbVSK0ryoZKEoiqLUSrVZKIqiKLVSyUJRFEWpVUQOytu7N79BdWutW8eSm1tTZ5vQUHHVjYqrblRcdROJcSUmxlceV3OYKllUwWqt3LU8PKi46kbFVTcqrrppbnGpZKEoiqLUSiULRVEUpVYqWSiKoii1UslCURRFqVXQekMJIXTMOf67YE5wdqOUcrfP/hGY8/G4MVf0ugVzltHXgU7AIeBWKeVPQohzMBeAcXvPdY2U8q9gxa74z2rVD393uWqbDFZRlKYqmCWLYYBdStkbuBeYXrZDCBEDPAH0l1L2ARKAIcA4oEBK2QuYBMzxPuUFYJKUMhVz4rV7ghi34gdd13A4YsnIiGH8eMjIiMHhiEXXq+15pyhKExbMZNEPc6popJSbMee1L1MK9PHOqw9mCacEOANzlk28Szme7t0/XEr5TaVjlRAqKYkhPd3CqFE68+fDqFE66ekWSkpiQh2aoihBELS5oYQQCzBX9crwPv4V6OSdJtr3uEnAYO/XOOA84Ebv9w2ATUrp9h7bB3P66fOllHuru7bL5TbCtQ90pHjnHRgxourtV1/d+PEoihIQ1VYNBHME9yEg3uex7psovG0azwCdgcullIYQ4jXM0sQ6zETxlU+iuBp4ALi4pkQBNHhUZWJiPHv35jfoHMEQLnFFR1tZt85OVX9X69YZpKeXUFrqOvKJjSxc3q/KVFx105C4dF0joSQfPSsTLSsTIyUVT0oqefZ4PJ76fVCePft5pPyRvLxcCguLOO6442nVqjVPPPF0rc9dtOgNunXrzhlnnFXrsVdcMZS33vqA6OjKa3DVrCHvV2JifLX7gpksNmCutPWeEKIX5oI2vuZhVkcNk1KWtYz2ANZLKacIIboDJwMIIUYD44FU72I4Sgi53R5SUgzmzz8yWaSmGrjdqqFbCQ8JJflY09Ngu3n70ebPR09KIiFjFbm2uHqdc9KkKQDk5Kxhx46d3HzzJL+fO2bMdfW6ZjgIZrJYCgz0LqeoAdcLIUYCcZjrHI/FXI1rrXdx9xe8jx8XQtyFuXzjWCGEBZgF/Ap85D02S0r5SBBjV2rgcpnJIinp8P8gAElJkJxsqF5RSqNpMfVBopd/XPXOrl3R0y6q+EcKsH07luX/5qiMlbBt2xFPKx06jMKpT9Q5lmnTppKXl8ehQ3k8/fQMXn55Nn///Rd5eXn06tWHceNuZtq0qQwYcBEHDuxn06YNlJaW8Pvv/8eoUdcyePDQWq+Rn5/P448/RGFhIW63m3HjbqZbtx7Mm/ciX3+9FY/Hw7Bhl3DxxZfz0Ufvk5HxCbquc/bZ53DrrbfX+TX5Clqy8JYWJlTavNPn5+oa1y+sYttRAQlKCRiLpZhZs1ogJXz9tUaXLtCzpwe7vRiPyhVKGNA6doCvv65651dfoXXsiFFFsmiIbt26c/XVo9iz5w/OPDOJe+99iNLSUi67bDDjxt1c4djCwgJmzJjDb7/9yj33TPErWSxc+Crdu5/HVVeNYO/ev7nllht5992PWbVqBXPmzKdt20RyctYAsGLFciZP/idnnZXE0qUf4HK5sFrrf8uPyFlnleD76iuNIUM0Hn/cycsvRzFmjJtbb7WwerXGOeeoBbWUxlE49YlqSwFWq05CxjK0BQuO2GcMGEBe2lBcDz4e0HhOPLEDAC1btuTHH7/n66+30qJFCxwO5xHHnnJKZwCOProdDofDr/P/73//5aKLBgGQmHg0sbEtOHgwl6lTpzFv3hz279/PgAH9Abj//odZsmQxc+fO5swzkxr82tQIbqVesrPNzxnt27vQdbj88lIAHnkkGrX4ohIOXC4PnpRUs37UV1ISnuSUoFSXapp5S12x4hPi4uJ55JEnGD58NKWlJVTueappdR+T1KHDSXz77TcA7N37N/n5h4iLi2fdus+ZOvVfzJo1l6VLl/Lnn3tYtuxj7rrrPubMmc9PP0m2b/+2Qa9NlSyUesnOtqDrBn37mr2ekpPdpKW5WLXKyooVVi6+OPS9oRQlzx5PQsYq9JwstMxMjNRUPMkp5NnjoZ69ofzRrVsPpk69n++++wa73U779iewb1+NnTirdPPNYw8nlYED07jmmut58snHyMz8nNLSUu6++wFsNhstW7bkuutGEh8fT9++fWnX7hhOPvkUxo27hlatWpOYmOhXD6yaROQa3A1d/CgSuxAGUkEBCBHHWWd5WLWq6HBcu3drnH9+C044wSAnpxCbLbRxhsv7VZmKq24CEZfVqmOx6LjdnoCVKCLx/VKLHykBtWWLBadT4/zzK5YeTjnF4Nprnfz3vzqvvx4VougU5Ugul4fSUpfqqdcAKlkodZaVZdZenn+++4h9d93loGVLg+nTo8nNbezIFEUJFpUslDrLzrZgtxv06HFksmjTxmDKlFIOHtSYMaNuI08VRQlfKlkodbJ3r8YPP1jo2dON3V71MTfe6OTEEz289loUP/+sZqFVlEigkoVSJ+vXmxM0VlUFVSY6Gh5+uBSnU+Oxx1TpQlEigUoWSp1kZ5vJIiWl5q6xQ4e66NHDzYoVUWzapGYAVkLLatWJjrYeXqxLqTs1zkLxm2GYg/FatTI466yae5VoGjz2WAnp6S145JFoVq4sQlf/p0oj03WNkpIY1qzRyMrSSEkxSEkxvNPSNP6sswD/+c9u8vMPcc45XStsv+SSNJYtW1WvmBqDShaK3375ReO333SGDHFi8aOw0K2bh8suc/LRR1F8+KGVK69UA/WUxlW2SFfZXILz52skJZkrO9ps9VvKoCGzzgJkZn5OmzZtjkgW4U4lC8VvZVN81NReUdkDD5Ty6adWpk2L5uKLXcTGBis6pTmaOjWa5curvo117QppaVpVk86yfLlORkaLqiadZehQF1OnltYpDpfLxbPP/ov/+7/f8Hg8jBt3M127dq8wG+zAgWn0738hGRmfYLVG0bnzabWOqt6z5w+eeupxXC4XmqZx++13ceqpnZk2bSq///5/OBwORowYzYABFx2+lsWikZp6IVddNbJOr6E2Klkofitrr6g8GK8mJ5xgMH68g1mzopk3z8aUKf5NmKYoDdWxY42TztKxY5UzlNfL8uUfk5DQivvue5i8vIPceutNLF78XoXZYFesWE5i4tGkpw+hTZs2fk2/8eKLM7niiqtJTk7lp58kTz31OLNnz+Xrr7eyYMEiNE3jiy82Axy+1umnd2LhwrcD88J8qGSh+MXjgfXrrbRv7+Gkk+pW13v77Q7efjuKWbNsjBzppF27yJtiRgmNqVNLqy0FWK06GRkxLFhwZPftAQMM0tKKefDBwIzo/s9/dvPdd9v44YcdALjdLvLyDlaYDbZXrz51Pu8vv/xCly5mddWppwr+/vsvYmNbMGXK3TzzzDSKigq56KJ0gMPXys/Po2vXngF5Xb5UsqikrLeE1aqrqQF87Nihk5urkZ7upK6TZcbHw913O7j7bjvPPGNj+vS6FfEVpT4ac5GuDh06cvTRR3PNNTdQWlrCwoWvERMTe3g2WMMwGDPmKi68MA1d1/1uXO/YsSPffbeNfv1S+OknyVFHtWHfvn1I+SNPPvkcpaWlXH75xQwcOOjwtdq2jWPQoHQuvDCNY445NmCvUSULr4q9JiAlJabBvSYiSU1TfPhj9Ggnr74axVtvRTF2rJMzzlCJWAk+u72YjIwYcnI0MjM1UlMNkpONgC/S9Y9/XMbTTz/BxIk3UVhYwKWXXnnEbLA9evSiXbtjEOJ0XnrpBTp2PImuXbsfPkde3kHGjh1z+PHw4aO49dbJPP30EyxZshiXy8V99z1EmzZtOHBgP9dfP5KYmFiGDx9d4Vpt2rQ+fK1AUrPOejkcsRV6TQDeXhPueveaCLRQznJ55ZUxZGVZ2bGjgKOPrvj2+hvX559bGDEiltRUF++9VxysUOscV2NTcdWNmnW2boI162zQShZCCB14CegClAI3Sil3++wfAUwG3MB3wC1AFPA60Ak4BNwqpfzJ5znPA1JKOTeQsVqtOmvWVN1rIidHIy2teVdJlZTAF19YOP109xGJoi4uuMBNSoqLzEwra9dauOCC+pVSFKWuXK7AJYnmKpjDpIYBdillb+BeYHrZDiFEDPAE0F9K2QdIAIYA44ACKWUvYBIwx3t8ohAiA7gkGIFaLDpZWVUn1MxMDYuleY8m27rVQnGxVu8qqDKaBo8+WoquGzzySDQuNexCUZqMYN4F+wErAaSUm4HuPvtKgT5SyrL6HStQApwBZHifI4HTvfvjgKnAomAE6nabDWFVSU01cLub9ycSf6f48McZZ3gYOdKJlBbeekuteaEoTUXQ2iyEEAuAD6WUGd7HvwKdpJSuSsdNAgZ7v8YB5wE3er9vAGxSSrf32KnAn7VVQ7lcbsNqrdt8RH/9BQMHHtlrYs0aaNeuTqeKOOedZ/ZXz82FuLiGn+/PP+GUUyA2FnbvhpYtG35ORVECovHbLDDbHOJ9Huu+icLbpvEM0Bm4XEppCCFewyxNrMNMFF+VJYq6yM2te4O01aqRkRFDdrbG2rU63bsbDBniwWotZu/e8OgEEIoGtbw82Lo1jh493BQXF1NcRbt0XeOyWGDSJBtPPRXNww+X8sADwRmoF4kNkMGk4qqbSIwrMTG+2n3BrIbagFlaQAjRC6jUfMw8wA4M86mO6gGsl1KmAkuBn4MYXwUej4HNVsSgQcUIAa+/rvHHH6rb7IYNVjyehrdXVDZhgoPjjvMwd66N335Ta14oSrgLZrJYCpQIITYCzwNThBAjhRA3CSG6AmOBJGCtECJTCHEp8BNwsxBiE/A4cEcQ46uSy+UhIQG2bIGMDDUMpXyKj8Ami9hYuP/+UkpLNaZNU2teKEq4U+MsquDxxHPssQbnnedm2bLgjwfwVyiKvX36xLJnj86uXQVEVdMeXd+4PB5IS4vl228trFxZSNeuge1IEInVBMGk4qqbSIyrpnEWzbtPaDXatYMePdx88YWFvXubbxXJH39o7N5toU8fd7WJoiF0HR57zJz64+GHo4nAzy2KEjFUsqhGeroLj0dj9ermWxVVn1lm66p3bzeDBzv54gsrn3zSfN9rRQl3KllUIz3dvEE253aL+qxfUR8PP1yK1Wrw2GPRlKo5BhUlLKlkUY1OnQxOP91NVpaFgoJQR9P4zCVULSQmejjttOAOSuzUyWDsWCf/+5/Oa6+pgXqKEo5UsqhBerqL0lKNdeuaX+li1y6dv//WSU5213lK8vq4445SWrUymDEjmgMHgn89RVHqRiWLGpRVRa1Y0fySRSCn+PBH69Zw552l5OVpTJ+uutIqSrhRyaIGZ5/t4fjjPaxZY8XpDHU0jausvSI5ufFmhr3+eicnneTh9dej+M9/mm8vNEUJRypZ1EDTzNLFoUMaGzfWba6ppszlgg0bLHTq5KF9+8brz2qzmY3dLpfGo4+q0oWihBOVLGrRHKuitm3TKSjQgtpltjqDB7vo1cvFypVRbNjQfBK0UjXfZY6V0FK/gVr07u2mVSuDlSutAV2GMZw1VpfZqmhaxYF6zeU9VyrSdQ2HI5aMjBjGj4eMjBgcjlh0XVVPhopKFrWwWuGii1zs2aPz7bfN4+3KzragaQb9+oVmdaJzzvFwxRVOtm+38N57zadEp5QrKYkhPd3CqFE68+fDqFE66ekWSkpiQh1as9U87n4N1JwG6BUWmivjdenioVWr0MXxwAOl2O0GTz4ZTWFh6OJQGp+m6axdq1e7zLGqkgoN9a77oX9/FzExRrNot9iyxYLTGZr2Cl/HH29w880O9uzRefllW0hjUYLr4EH4/HMLTz1l4/LLY7j33liys9Uyx+Em8u9+ARAba443WLkyit27NU45JXJnvMvKCl17RWWTJjlYvDiKOXNsjB7t5JhjIvd9by4MA37+WePLLy2Hv3burNiR4fjj3QwYoLNgwZEJQy1zHDoqWfhp8GAzWWRkRDFpUnBWdgsH2dkWoqMNevQIfbKIi4N773Vw5512nnrKxsyZauKopqa4GL791sIXX1jYulXnyy8t7N9fXjKIjTVITnbRo4ebnj3ddO3qplUrcDhiSUqyHLHMcXKygculkkUoqGThp4ED3ei6QUaGNWKTxb59Gt9/byE52UVMmLQjjhzpZMGCKJYsieLGG52cdZa6UYSzv/7S+OKLsuRg4bvvdJzO8hLCCSd4SElx0qOHmx493JxxhgdrFXchu72YjIwYcnI01q3T6dIFzjvPg91erHrIhYhKFn5q08agd283GzZY+esvjXbtIq9KZP36sik+Ql+qKGOxwNSppVx9dSyPPBLNBx8UN8pcVUrt3G744Qe9QpXSr7+WlxqsVoOzz/YcTgzdu7s57jj//m/KljlOS9O56qoWXH21m8mTdbZsgfbtg/WKlJqoZFEH6ekuNmywsnKllWuvjbz5Pxpj/Yr66N/fzYABLj7/3Mpnn1kYODB8kllzcuiQ2VOuLDF89ZWFwsLyzN26tcFFF7no2dNMDl26uImNbdg1XS4Pug4pKQ4++CCGOXNsPPWUqo4MBbWsahWqW5bw1181uneP44ILXLzzTuMvtxrsZRy7d29BXp7Gzp0FWOoweLoxlpfcuVMnNTWWk0/2kJlZ5NfKfZG47GUw+cZlGPDLL2aVUnlDtI5hlCeHzp3dh0sNPXu6OflkIyilvsTEePbsyad37xb8+afGl18WhkVnh6bwe6zHc6v9DQatZCGE0IGXgC5AKXCjlHK3z/4RwGTADXwH3AJEAa8DnYBDwK1Syp+EEKcAbwAGsMO7vdFrLk880SApyU1OjoVDh6Bly8aOIHh++UXj1191Lr7YWadE0VhOO83DmDFOFi60sWhRFDfcEHklu1AqKYGNG2HVqqjDyWHfvvIqpZgYgz593BWqlFq3brz4rFa4/XYHd9xh58UXbTz+uCpdNLZgdlgeBtillL2Be4HpZTuEEDHAE0B/KWUfIAEYAowDCqSUvYBJwBzvU2YAD0opkwEN+EcQ465ReroLp1Pj888jqwYvlFN8+Ovuux3ExRk8+6yNQ4dCHU3T9vffGp9+amXq1GgGD47llFPi6NsXHnvMTkZGFDYbDBvmZNq0ElavLmT37gKWLi3m/vsdDBzYuImizFVXOWnf3sObb0axd69quGpswbzj9QNWAkgpNwshuvvsKwX6SCmLfOIoAc4AMrzPkUKI0737uwFZ3p8zgIuApdVduHXrWKzWhn08TkyMr3L7qFHwzDOwdm0MN93UoEvUS3VxNdSWLeb3Sy+1k5hor/PzgxVXxWvAAw/AffdpzJ8fz9NPh0dc9dGYcbnd8P33Zslh40bYsAF+/rl8v8UC55wDfftCnz7m1wkn6JifJcNj5cKy9+u+++DWW2Hhwji/fv/B1pz+voLWZiGEWAB8KKXM8D7+FegkpXRVOm4SMNj7NQ44D7jR+30DYAN+k1Ie5z3+AuAGKeXo6q4drDYLMOtye/RowYEDGj/+WEB0I86kHaw6Uo8HzjijBTEx8PXXhXWud27MutuSEujTpwV//62xYUMhHTpU/6uOxDplfxQUHNkQnZ9f/ktNSDAqtDWcc46bFi2axvtVUmL+/+Xna3z9dQFHHRUecYWTJtdmgdnm4JvedN9E4W3TeAboDFwupTSEEK8BpwPrMBPFV1JKtxDCt30iHjgYxLhrpGnmAL25c22sX29hwIDwrbbx1/ff6xw4oDNihDPsu6Xa7fDgg6VMmBDDtGnRzJ9fEuqQQsowzI4XX35pOdwY/eOPOh5P+S/ylFPcDBniOZwcTjnF7GHUFNntMHGig4cesjN/vo17743MMU/hKJjJYgMwFHhPCNELqDQtGPMwq6OG+TRW9wDWSymneKutTvZu3yaESJVSZgLpmMkkZMqSxYoV1ohIFllZ4dlltjqXXupi/nw3H38cxbhxDnr0aD6jtEpLYft2vUJy+Pvv8ju/3W5w3nm+DdEe2rQJfc+hQBozxskLL9h45RUbN9/sICEh1BE1D8FMFkuBgUKIjZiN0tcLIUYCccBWYCyQA6wVQgC84H38uBDiLszSw1jvue4EXhFC2IAfgQ+CGHetevRw07ath5UrrTz7bGmT/ZRWJhRLqDaEpsGjj5YydGgsDz9sZ8WKorAvEdXX3r2at0rJTBDffGOhtLT8xbZr52HoUOfhsQ1nneXBFuHzLsbGws03O3n88WgWLLBx552qdNEYgpYsvKWFCZU27/T5ubpb7IVVnGsXkBKg0BrMYoG0NBdvvWVj61adnj2b7ifb0lJzptnTT3dz9NFN5xPoeee5GTrUyfLlUSxbZuUf/2gapaKaeDywa5deYWzDzz+X/5vousGZZ3oqtDe0bx+csQ3h7vrrHcyZY2P+fBvjxzuIiwt1RJEvsvp/NqL0dDNZZGRE0bNn0+3zvXWrheJiLay7zFbnwQdLWbXKyuOPR5OW5sJe905cIVVQANu2lVcnbd1q4dCh8jt/y5YGF1zgOpwcunZ1q5uiV1wcjB/v4KmnonntNRu33aZKF8GmkkU9JSe7iY0117h4+OHSJvvpLlyn+PDHSScZjB3r5OWXbSxYEMXEieE7UM8w4P/+z2yI3r4dsrNj+f77ig3RJ53kIT29PDkI0XQbohvDjTc6eOklG3PnRjF2rIMWLUIdUWRTyaKeYmLgggtcfPJJFLt26VTssNV0ZGdbsVrNSRKbojvuKOXdd608/3w0w4e7aNs2PKrSHA7YsaN8kr0vvrDw55/ld/7oaJ3u3d3etgYP3bu7SUwMj9ibipYtzYQxY0Y0ixZFMWFC+H5YiAQqWTTA4MFmslixwooQTa8YnJcH27aZN62mWr2RkAB33eXg/vvtPPdc6CaZO3CACrOvbttmoaSkvNSQmOjh4ovNqbnT0uy0b9+4Y3Qi1fjxDubNs/Hiizauu87Z5KoimxKVLBrgwgtdWK3mGhdTpjS9ZLFxoxWPp2m2V/i69lonr75qY+FCc86ozp2DW8rzeGD3bt+GaJ3du8tnDNA0gzPOqNgQfeKJ5Q3RiYl29u4NaojNRuvWcMMNDmbPjuatt6IYO1aVLoJFJYsGaNUK+vRxk51t5fffNY4/vmlVI5S3VzTtZBEVBY88UsI118Ty2GPRLF4c2BmBCwvhm28qNkQfPFheaoiLM0hJKZ+au1s3N/HhOQtERJowwcmCBTbmzLExZowz4rsOh4pKFg00eLCL7GxzjYum9qkmO9tCbKxB165NO1kApKW56dvXxerVVrKzLQ1KgL//rlVoa9ixQ8ftLk8OHTp4uPDC8uRw2mmesJypt7lITDS45hon8+bZePfdKMaMaVr/h02FShYNNGiQi3vvhRUrmlay2LNH46efLFx4oSsiPomVDdQbONDCI49Ek5VlTgNiteo1rtnsdJrTnfgmhz/+KG+IttkMzj23fKqM7t3dEblKYlM3caKDN96I4oUXbAwf7vRrvROlblSyaKDjjjM491w3GzdaOHjQrJpqCppyl9nqnH22hwkTXFxxRRTLl8eyaROkpMSQkmJ41242yM2Fr74qr1Lats1CUVF5qaFtWw/p6WVrRHvo0sWtGk2bgHbtDEaNcvLaazY+/NDK8OGR83cdLlSyCID0dBfbtkWzZo2VK68Mzh+p1aof/l7TJ2V/NYX1K+rjnnt0hg6F7dvNBDB/vk5SErz+eiwjRxrs2lWxIfq008obonv0cHPSSc1zRHQkmDTJwaJFUbzwQjRXXulSVYMBppJFAAwe7OJf/4pmxYrAJwtd10goyUdfkwlZmSSkpOJJSSXPHo/HU7/qEMMwSxZt23o4/fSmOT6kKlarzoYNGtsrTVm5fTts2aJz7LEG7dpVbIhWk9BFjuOPNxg+3MmiRTb+/W8rl12mSheBpJJFAJx6qoeTT/awbp2V4mJzwF6gJJTkY01Po+wOqM+fj56URELGKnJt9Rsc8dNPOn/9pXPZZeE/JXldWCw6WVlVv6BvvzX4+OMSnE51A4lkt93m4O23o5g508awYS41Aj6A1FsZAJoG6elOioq0w20BgWC16uhZmVT1UVnPyTpcNVVXkdheAeB2e0hJqbq01b+/gWFETilKqVqHDgZXXuli504Ln36qPgsHkkoWATJ4sHnjzcgI3B+oxaKjZWVWuU/LzMRiaWiyiKz2CpfLTBZJSRW3JyVBcrIRkLYeJfxNnlyKrhvMmGEjSAuBNksqWQRI164ejj7aw6pVVlwB+sDudnswUlKr3GekpuJ21/3m53LBhg1WTjrJQ/v2kfefZLcXk5HhZskSD+PHw5IlHjIy3NjtgR2op4SvTp0Mhg1z8f33FlatUq3cgaKSRYDoujnmYv9+s89+ILhcHjz9kqnqo7InOaVen5S/+UYnP1+LuCqoMh6Pgc1WRFpaMXPnQlpaMTZbUb07AyhN05QpDjTNYMaMaFW6CJBak4UQ4ighxIXen+8TQrwvhDi5tuc1R2VVUStWBK4qqmTZcpg5E89rr8P48RgvvogxZw6HHPWrUonULrOVlSVSVfXUPAnhYcgQF998Y2HdOlW6CAR/ShZLgHO8CeNKYBmwIKhRNVH9+rmJjzcnFgzIpxnDwP7SixhpaRxKuRDmzqVEs6KlpBB7z131OmV2tgVNM+jXLzJLFopSpmxyz+nTVekiEPz5CNxaSvmcEGI28IaUcpEQ4vbaniSE0IGXgC5AKXCjlHK3z/4RwGTADXwH3AJYgIVAR+/2cVLKnUKIrsBc73m+AW73LtsaVmw2cybapUuj+P57nbPOaliI1m1fYf3xe0ovvgRnvDkgoGDYlVhfmYf9/XcovfgSHIOH+H2+wkJzGu2zz/bQunWDQlOUsHfWWR4GDXKycmUU69dbmswa8+HKn5KFLoToBgwDPhFCnIN/SWYYYJdS9gbuBaaX7RBCxABPAP2llH2ABGAIMBiwerc9BkzzPmU+MFlKmQzkASP9uH5IpKcHrleUffFCAIrHXFu+0Wolf/Y8jOho4u+6HW3fPr/Pt2WLBaczctsrFKWyO+4wSxczZkTABGgh5s8d7R7gWeA5KeXPQojNwBQ/ntcPWAkgpdwshOjus68U6COlLPKJowT4DbB6SyUtgbKZ+dpLKTd6f94A/ANYXN2FW7eOxWptWD1lYmL95pi++mqYOBHWrInmmWcasLpNfj4s/QBOPJFWV/yDsrkLEhPjIbE7TJuGdtddtH34bnjvPfwZXbd1q/n9kkuiSUwM7Mo79X2/gk3FVTeRFtfAgTBoEKxcaUXKePr1C4+4gi0YcdWaLKSUnwsh1kspS4UQpwCPA1l+nLslZimgjFsIYZVSurxVSH8BCCEmAXHAGqA9ZhXUTqAtZmkD4GchRIqUMgsYCtS42m5ublFNu2uVmBjP3r359X5+cnIMn39uZevWAjp0qF9lqX3xQuILCym85TaKDhQdGdeosbR6/0OiPviAQ6+8QemlV9R6zpUrY4mO1uncuSCgi+809P0KFhVX3URqXBMn6qxc2YKHHnLx3nuB60Idie9XTUnGn95QDwFvCCFOBLIx2xme9+O6hwDfK+tSysP1H0IIXQjxHDAQuFxKaWCWWFZJKTtjtnUsFELYgeuB+4QQnwJ/A/7XvYRAWVXUypX1r4qyL34DQ9cpGTmm6gMsFg7NehkjNpa4e+5A/+vPGs+3b5/Gjh0WevZ0B3Q6EkUJdz17ekhOdpGZaeXrryN7tIDvhKOB5s8ZhwE3YLYTLJZSDgT6+vG8DZhtEAghegGV5qxgHmAHhvlUR+VSXho5AERhNnpfDNwgpbwYaINZCglbaWkuNM2od7uF5fsdRH39FY4LLsRzfPtqj/Oc1ImChx9HP3iQuDtvo6YuHxs2ROaobUXxR3nbRWQufK7rGq0dBSRkLIPx40nIWEZrRwG6HrjJ3/y5m+lSymIhxBDgQW97Qo3VQF5LgYFCiI2ABlwvhBiJWeW0FRgL5ABrhRAAL2CWWF4TQuQANuB+KWWhEOInYIUQoghYJ6VcUbeX2bjatTPo3t3D5s0W9u/XaNOmblVR9rfMhu2SUdfWciSUXDeW6E+XE716JdHvvEXpiNFVHhep80Epij/69HFz3nnmSorbt+skJYVdZ8oGCcaEo5X5kyw+F0LsAIowq6GyMMda1MjbLjGh0uadPj9XV6q5qopzLQeW+xFr2EhPd/Lll3ZWr7YwYkQdbtDFxdjffxdP4tE4LhpU+/G6Tv4LL9L6/F7EPXgvzuQUPO1POOKwrCwrCQkGZ58dWf8kiuIPTTNLF1dfbWXGDBuvv14S6pACxmrVzSUMqptwNG1oQAan1loNJaW8C7M6qZc3AUySUt7T4CtHuPpOLBj96TL0vIOUjBiNv2tDetqfQMG0p9HzDxE/eSJ4Kv5h/PKLxq+/6vTtqxaEUZqv1FQ3Xbu6+fTTKH78sem3XWh5B7GtyiD24w/R1q2t+pgGTDhamT8N3InAc8DfQoiDwCNCiHYBuXoE69TJ4LTT3GRmWiks9P95h8dWVNewXY3S4aMovWgQtux12N94tcK+nJzmMcWHotTELF2UAjBzZtMbd1GWHFo8fD+tLjyfNp07kDDmaqLnvwznnlvlc+o74WhV/Ek584AvgE6Y3Vo3Aa/W9ATFlJ7uoqREY906/0oXlv/8hG3jehz9zsfTqY7Tb2kaBdNn4WnVirjHHkL/78+Hd5W1V6SkqPYKpXkbONBNUpKbjz+2snt3eK/8pR3MxbZyBS0euo9WA5IPJ4fYuXOw7vwBZ68+FN55DwfvfhD3Jf8I6ISjVfHnLtZJSnmZz+NnhBB1+9jbTKWnu3j++WgyMqwMGVL7jdr+1iIASkbX3rBdFU+7Yyh4ajotJ4yl5W03c/DjFXg0Czk5Fo47zkOnTmqCHKV50zRzzqgbbohh5sxo5swJn7YL7WAuUZs3EbUhh6iN67Hu+A7N28PRsNlw9uqDs08/nH2TcXbrUWFJzjxdIyFjFXpOFnpmJp7UVDzJKeTZ4yFAMy77kywMIcQJUsrfALzjLZy1PEcBunTxcNxxHtasseJ01tIE4XBgf+ctPK1bUzp4aL2vWXrpFZR+upzo5R8TM/9lvuh3GwcO6AwfHllLqCpKfQ0e7OL00918+KGVu+7S6NgxNB+itNwDZnLYmEPUhvVYv99eMTn07lueHLp2r3G9Zo/HINcWhzVtKK2HDycvt9AsUQRwan5/ksVDwCYhxBbMLrDnATcFLIIIZi636uLVV21s3lzzRGa2VRno+/ZSdNPNYLc36KL5T88gatN6WvzrUdaPHQ20UF1mFcVL12HyZAfjx8cwa5aNGTNKG+W6NSaH6Og6JYfqBHNqfn+m+/hECHEu0BOzjWOClPLvgEcSocqSxYoV1hqTRUwdxlbUxmjblvznZpFw3Ug2LPoNOEHNuKkoPi65xMWzz7p5990o7rjDEZRVI7XcA0Rt2kjUxhxsG9Zj+WFHxeTQp1/F5NCQD4mNoNpkIYR4uJpd5wohkFI+FqSYIkrv3m5atTJHc//rX6VVVgXpv/1K1LrPcXbrgfv0MwJyXcfgIeRdNpqcj87h9LZ/0a5dbEDOqyiRwGKB2293MGlSDLNn23j66YaXLiItOVRWU8lC1XAHQFQUDBzo4v33o/juO50uXY4sHtrfXoRmGJSMuS6g18687DmKP4pl4IEFWHZ0x31WUu1PUpRm4vLLXTz3nIe3345iyhQHxxxTx9LF/v3YPl11ODlYf9hxeJcRHW0mhbLkcG63JpccKqs2WUgpH23MQCJZerqZLFassNKli6PiTrcb+5LFeOLiKbnk0oBeN/vrVgAM9Kym5cRXyF2daa7QpCgKVqvZdjFlip0XX7Tx+OM1ly60A/srlBz4YQcJ3n2G3Y6j3/kRlRwqC9xi0Uq1+vd3YbebVVH33VcxWdjWfYblj98pHnM9xAVmDpcyWVlWLBaDHlecgPXdT4md/hRF91VXu6gozc+VVzqZPt3GwoVRTJrk4Oijy0sX2v79RG3aUF5y+PH7w/sMux0uuIDCHr3Lk0N0ZE5SWEYli0bQogWkpLhZtcrKzz9rFcY72Bd5G7bHNLxh29ehQ7Btm063bh4sTz6Ee1MGsbOex5E2GFfX7rWfQFGaAZsNJk1ycM89dubOcPFE30+wbcwhauOGI5KDIzmlQskhsX1bisJwPYtg8We6D4sQ4hLvz22FEDcIIVR7Rh0NHmwOTfGdK0r76y9sqzNwnnU2ri5VD9evr40bLXg85hKqRlw8+TNfRHO7iZ80AYoDtwCMojRV2r592Jb/m3E/3Mlx1r94/TUrzrGTiXl1PpZffsaRnErhvQ+Su2wV+376jbwPl1N05z04e/WJ+FJEVfwpWbyCuaZE2Uyz/THHWowPVlCRaOBAN7pusGJFFLfeaiYO+7tvobndlIy6xq9lUesiO9v81aakmF1mnf3Op2jcBGJfmUuLp56g8NFpNT1dUSKOtm8fUZvWY9uQQ9SmDVh//OHwvn9GxTCF53imzwfcd68D17ldm2VCqIk/yaKHlDIJQEq5DxgjhPguuGFFnrZtDc47z83mzRb++kujXaKbmMULMWJiKL3iiFnZGyw720JsrEHXruXjKwofmIrt8zXEzJ2DI/1i8xOSokQobe9eojZvMJPDxvVYd/54eJ8RE4Pj/P44+/bD0SeZS0/ryrTeHuZuT+Gm0wtIUHniCH4tfiSEOFZKuQdACHE0oBZFqIfBg11s2mRl9WorN5yUheWX/1Jy1QiMhFYBvc6ePRq7dlkYMMBVsfNTbCz5s+bS6pI04idN4MC6jQFvVA8XvstLBmM0q9I46vJ71PburVhy8E0OsbE4Uvrj7GMmB9e5XSv0DIwFbrnFwWOP2XnlFRt33eWo4grNmz/JYhqwTQix3vv4POD24IUUuQYNcvHQQ7BihZVbEt4A6j9pYE1ycqpfFc/V8zyKb72d2NnPE/f4wxQ8PSPg1w8lXddIKMk3F4PJyiQhJRVPSip59ng8AZwnRwkuf36PFZLDxvVYZfnaaoeTQ99kMzmcc26t3cavu87JnDk25s+3MX68g/j4YL7Cpsef6T7eFkJkAr0xJxCcVFbKUOqmQweDM890k5NtoZR1WE/tjPO83gG/Tll7RXXrVxTefT+2NSuJeX0BpYOH4kzpH/AYQqW65SVbfbSU/B93Y2g66Jo5QZDPl8GR29A17/G62aZU+Tla+XG+x5Rvr/SlaQFvm4pU1f4e33sfx9PPmiWHyskh9YLykoMfyaGyuDgYP97Jk09G8/rrNm67TZUufNU03cdNUsr5VUz7cY4/03141+p+CegClAI3Sil3++wfAUwG3MB3wC2YDekLMdfNcAPjpJQ7hRDnAHMBF7DLe64mWbeQnu7i+++jWcUFDB51TsBvHoZhtle0bevh9NOreYuio8mfPZdW6QOIn3wruVmbMFomVH1sE2K16uir11W5vKRl9SpavfkmbNkSmuB86Tptq008ujl3wuGfdYxqks4R232PP5zctMPb0SudS9O8273H2G20dHnKjy9LflWc5/B2rfJ2reJ1NP2IRGvoWoXzlMVieI/XTzwB3ULVv8e1nxPz4w6M337FkXoBDu8oaVeXuieHqowd6+Cll2y8/HIUY8c6aNGiwaeMGP5M91HV3cyf8vwwwC6l7C2E6AVMB/4BIISIAZ4AkqSURUKIJcAQ77WsUso+QoiBmFVglwOPAI9JKVcIId4CLqaJrcldZvBgJ889F83H2mVccNV5AT//Tz/p/PmnzqWXOtFr6Bjt6nIuRZPvosVzT9HiofsoeOGlgMfS2Gy7d6Flrqtyn/Htt5ROuh1376/RPB5z6VnDML97PGCY3w/v8xjmNu8x5dt9jzfAMCruM8p/Lr8OFbbbLBquUmfF4w0qPafi9bSyeH1i1irs831NxpHbfc9lVP/vGxbtuqNHVzv62fj2W4rmLqDo6OP8Xna4Llq2hBtvdDB9ejRvvhnFzTer1RjK1DTdxzzvj79IKRf67hNC3OrHufsBK73n2iyE8B0JVgr0kVIW+cRRAvwGWL2lkpaUr5uxDTjKO74jnia8nkaX4i10pBOfWobybEsPgZ58o7y9ovZZZoum/BPbqgxilizGcfFQHBelBziaxqEdyqPF1AeJ2S0xRo+u8hijf3+K04biumhII0d3pMTEeA6GejCXb6L0fiW2acG+v/MqJVKf5FQ58ZQlUqPicRWOP+I6xpHnMipew3JUK2L3/I6+YMGRYffvj6PDSRDETgs33eRg7lwbL75o47rrnPWZKTwi1VQNNRnzhj1BCNGh0nNGAS/Wcu6WQJ7PY7cQwiqldHmrkP7yXmcSEAesAdpjVkHtBNpiljYAfvJe70HvOTNrunDr1rFYrZZawqtZYmKQWrc+fJthnMVM1xR27IC0tMDGtXmz+X3YMDuJiX7MTfP2YujWjYS7bocdA6BNm7oF5GdcQfPJJzBhAvz+O5x9NtrFF8O8eRWrMJKS0Pv3p3Xr8KlTCNn7VYu2J4XJe/TXX+YyoSH4PSYmwqRJ8NRTGsuWxTNxYk3HhufvMRhxaUY1RVIhxMVAd2ACZntBGReQLaXMqenEQogZwGYp5Xvex/8npWzvs18HngE6A8O91VEzgFIp5X1CiBOAtUAS8CvQX0r5vbdUc4aUstrSzd69+Q3q9pKYGM/eIHzy0/IP0SapM5lxF3PB3+9x7bUOnn3W/6mRa4vL5QIh4mjTxuCLLwr9Pm/MrOeJe+IRSi67gvy5r/n9PH/jCgZt/37iHrgb+0fvY0RFUXTH3RRNmoJujzZ70VSxvGS49IYKxfvlj3CK63BvqBD9Hvft0+jevQWtWhls2VJY5fi8cHq/fDUkrsTE+GobUaut1ZZSfuqdefYCKeWj3p+fBz6uLVF4bQAGA3jbLCq1VjEPsAPDfKqjcikvjRwAojAbvQ8Ah7zb/wBa+3H9sBO99EO0oiK6Xnc6bdp4WLnSiieApelvvtHJz9fqvCpe8a234ezWA/tHH2BbtjRwAQWDYRD97484KrkH9o/ex3luV3I/y6HoznvAZju8vGRe2lCYO5e8tKHk2uLCJlEo/gn177FtW4NrrnHyxx86774b+LaRpqjWuaGAPkKIN4QQicAPwAdCiPv9eN5SoEQIsREzyUwRQowUQtwkhOgKjMUsNawVQmQKIS71HtdVCJGDWaq4X0pZCNwIvCOEyMLsNeXP9cOOffEbGLqOa9RILrrIzV9/6Xz9tT+/Av/k5FSc4sNvFgv5c+ZixMQQf/cUtL/DcyFE/a8/aXndKFqOuw6toICCR57g4KefVblgVDCXl1QaTyh/j7fe6iA62mDWLBvOJttKGjj+DMq7BbPtYATwb8wBeZuBf9X0JG+7xIRKm3f6/FzdXfKIuS+klOuBvn7EGrYs278j6pttlF40CM+xx5Ge7mTJkigyMqx07x6Y/tzZ2RY0zaBv37qvt+0++VQKH5xK3AP3EP/PyRx6463wGRNgGES/+zZxD92HnncQR+++FDw/G3enU0IdmRLB2rUzGD3ayauv2vjwQyvDhzfvdez9+ljrHYQ3GPhUSukCVP+AOjq8xvbo6wDz039srFFhFtqGKCyEL7+0kJTk4aij6neO4rHjcfRNJjrjE6LffycgcTWU/tuvJAy/jJa33QwuF/lPzyBv6acqUSiNYuJEB1FRBjNnRuNu5svY+5MsvhdCfAJ0Aj4TQrwLfBncsCJMURHRH7yHu90xOC68CICYGHNRpN27Leza1fCqqC1bLDgcdW+vqEDXyZ/5Ip4WccTdfzf6H783OK5683iwvzqf1uf3wrbucxz9B5Cbs4WS62+kxgEkihJAxx9vMHy4k59/1vn44+a9/I8//3U3YPZa6iWldACLMdsbFD9FL/8Y/VAeJSNGm2s5eqWnmzf2QJQuytor/BlfURNPh44UPjoN/VAe8VMmmn3gG5nlPz+RMGww8ffdBVYrh2a9TN47H+Fpf0Kjx6Iot93mwGIxmDnTFtAOKU1NtclCCHGT98f7gVRgonfqj3OBB4IfWuSwv/UmACUjx1TYftFFLiyWwFRFZWdbsNkMevZseFm5ZMx1OPoPwLbuc+yLF9b+hEBxuYiZ8wKt+/fFtnkjpYOHkrv+C0qHjwqf9hOl2enQweDKK11IaeHTT5tv6aKmkoXvdB9VfSl+sPy0C9vmjTjO74+n40kV9rVqBX36uPn6awt79tT/Ld2/X2P7dgs9e7qJjW1gwACaRv7zc/C0TKDFw/ej/++XAJy0ZpYfvqfV4AHEPfYQRlw8eQsWcuj1xXjaHRP0aytKbSZPLkXXDWbMsIWisB0Wap3uwzu+Qqmnsk/mJaOvqXL/4MEucnKsZGRYueGG+vXP27DB/yk+/OU57ngK/vUMLSeOJ/72W8j76JPgtBU4HMS+MJ3Ymc+hOZ2UXHE1BU88hXFU/UaSK0owdOpkMGyYi48+imLVKguDBjW/1m5/1uD+TQjhFkLs936V/fyldzZYpToOB/b33sZz1FGUplc9J9GgQQ1vt8jKqn79ioYovXI4pYMuxrZxPTGvzqv9CXVk/eZrWg9MocWzT+Jpm0jeW++R/9IrKlEoYWnKFAeaZjBjRnSzLF3481ExC7hcStlGStkGc8zFMuAmap8fqlmzrfwUff9+Sq4aWe16vscfb3DOOW42bLCQl1flIbXKzrbSsqVBly4Bbn3TNPKfewHPUUfR4ompWP7zU2DOW1xMi8ceptWgC7D++D3FY64nN2cLjoGDAnN+RQkCITwMHerim28srF3bsLnnmiJ/ksVZUsqPyx5IKTOAs6WU21DjLWoUs+gNoPbV8NLTXbhcGmvW1L108b//afzvfzp9+7qwBOHv1zj6aPKfnYlWXEz8xAk0tLN51OaNtO7fh9g5M/G0P5GDHy6nYPoLEbGehhL5pkwxB9BOn978Shf+JIuDQojxQogWQoh4IcQE4IAQ4jQ/n98s6f/7BVvWOpw9e+HuLGo8tiFdaAPVZbYmjqHDKLn0cqK++pKYF2fV6xxaQT5x995Jq0sGYfnvzxSNv4UDWZtwJqcEOFpFCZ4zz/QwaJCTrVstrF0b6mgalz83+1HAQMwJ/H4B+gPXeLfdG7TImjj7kkUAFPuxxrYQHjp18vD551ZKSup2nezswDduV6XgyedwH92OFs9Mw/LjD3V6blTmWlqn9CbmtVdwndqZg5+spvDxp1DLkClN0Z13mqWLxx8PcSCNrNZkIaX8HXNeqH7AhcAoKeUeKeVsKeXKYAfYJLlc2N9ejCe+JaVDh9V6uKaZpYuiIu3w4kX+8HjMxY6OPdbDKacEd7SQcVQbCmbMQnM4iJ84Hn9mVtMO5hJ3+y20umoY+h+/Uzj5LnI/X4+rR+BXCFSUxtKli4cBA1xkZcHmzc2n7cKf3lDdMRcfegN4DfhVCKH+22tgW7sGy597KL38Sr8/PaenmzffFSv8r4r6/nud/ft1zj/f3Shj1hwXpVM8YjRR278lduZzNR5ry/iU1snnEbNkMc6zzubg6kyK7n+42uUyFaUpueMOcx2a6dMDvdZl+PKnGuoF4GopZTcp5bnAZcDs4IbVtB0eWzHmOr+f0727h8RED6tWWf1uQy5fQrXxZsMsfPxJ3Me3J/b5Z7F+uw2r1fwTKvuu7dtH/E3XkXDtCPTcAxTe9xAHV63DldSl0WJUlGDr0cPDgAGQlWXlq6+aR9OtP68yTkq5peyBlHIz5qJFShX0P/dgW7MK59nn1OkGqevmmIt9+3S+/NK/om12tlkKSU5uvAFCRssE8me+iNauHa1iLCRkLIPx40nIWMZR+37nqKsuwf7xRzi79SD38/UUTfknRKnFY5TI89BD5vcZM6ruFh9p/EkWB4QQ/yh7IIQYBuwPWkRNnP2dt9Dc7lq7y1Zl8GD/e0WVlpr1pUK4OeaYxu3D50zpj2fZcrSbb0YfNRLmz0cfNRLL1VehzZpFweNPcvCT1bjFaY0al6I0ppQU6NXLxZo1Vr77LvJLF/68wvHA/WUjuDEnFqy8qJEC5rTai9/EiI012yvqqF8/N3FxBitWWGvtw/3VVxaKirSg94KqitWqw48/wvZKK+Vu347xxx6ct04iKIM+FCXM3HGH2TNqxozIb7vwpzfULinlecCJQEcpZU8ppQx+aE1PVE4Wll9/ofSSSzHiW9b5+dHRcOGFLv73P50ff6z5V1PeZbbxV++yWHS07Kwq92k52Vgskf8pS1HAXMSsWzc3K1ZE8cMPkf13X219hxBiHXDE51shzAFmUsoLajqxEEIHXgK6AKXAjVLK3T77RwCTATfwHebyrRZgIdDRu32clHKnEOIdoGz60Y7AZinlcD9eX6Oye1fDK/auhlcf6ekuPv7YXG71jDOqX241O9uKxWLQp0/jlyzcbg9GSira/PlH7DNSU3G7m/Gk/0qzomlmz6hRo2KZOdPG/Pl1HCjVhNRUOT61geceBtillL2FEL2A6cA/AIQQMcATQJKUskgIsQRzzikNsEop+wghBgLTMOelGu59XmtgHTClgbEFnLZ/P9ErPsHVWeDq0bPe5xkwwEVUlFkVVTb4p7JDh2DbNp1zz/UQH1/vS9Wby+XBk5KKnpRUsSoqKQlPcgoul0oWSvNx4YVuzj7bzb//beWf/9Q59dTI/PuvaYryqusZ/NcPWOk912bveI0ypUAfKWWRTxwlwG+A1VsqaQlUHvn1KDDbuyZ4WLG/twTN4TAbthsw6KFlS7PtYt06K7/9pnHCCUc2XmzcaMHtbuASqg2UZ48nIWMVek4WemYmntRUPMkp5NnjwdPMJs1RmjVNM+eMuv76GGbOtPHii5FZutCMIM2GJYRYAHzonXgQIcSvQCcppavScZOAwd6v9sC/gTigLTBESrnRe9zRmKWKs6WUNda9uFxuw2ptxAZWw4Azz4T//Ad+/x3atm3Q6ebNgwkT4IUX4Lbbjtx/++0waxZkZcH55zfoUoqiBIDHA126mP0+pISTTw51RPVW7SfdYK4ReAjwrSTRfROFt/TwDNAZs6rJEEJMAVZJKe8TQpwArBVCJEkpS4ArgLdrSxQAublFtR1So8TEePbuzff7eOuWzbT+8UdKhl1GvhENdXhuVfr21YA43n/fxYgRxUfEtWpVLLGxOiefXMDevQ26VEDU9f1qLCquulFx1U3luG67zcpNN8XwyCMOnn++NGziqutzqxPM5vsNmKUFvG0WlfpZMg9zcN8wn+qoXKBsVYcDQBRmozeY81JlBDHeeotZ/AYAJQ1o2PbVrp1Bt25uNm2ycOBAxX1//qkhpYVevdzYIr+3nqI0GUOHujjlFDfvvhvFb79F3srTwUwWS4ESIcRG4HlgihBipBDiJiFEV2AskIRZesgUQlzqPa6rECIHWAvcL6Us9J5PAD8HMd560Q7lEb1sKe4OHXH2C1yd0ODBLtxujdWrKxb+QtllVlGU6lksMHmyA5dLY/bsyPskF7RqKCmlhyMH7+30+bm6RHVVNec7MxBxBVr0h++jFRdTMuqagK5RPXiwk8cfjyYjw8rw4eWJoWz9isac4kNRFP9cdpmL557z8PbbUUyZ4uDYYyOns0dkjyJpBPbFCzEsFkpGjA7oeU8+2aBzZzeZmVaKvJV0hmGWLNq08XDmmZHZPU9RmjKrFW6/3YHDofHii5FVulDJogGs331D1PZvcQwchKfdMbU/oY7S010UF2tkZpqlCSlhzx6d5GR3IAsxiqIE0JVXOmnf3sObb0bx99+R03ahbjkNYF/knYp89DVBOX/liQU//9zcHor5oBRF8Y/NBpMmOSgp0Xj55cgpXahkUV+FhUR/+B7uY4/DccHAoFyiSxcPxx7rYfVqKy4XfPaZuT05WTVuK0o4GzHCyTHHeHj99Sj274+M0oVKFvUUvfxj9IJ8s63CGpx+AmVrXOTmamzYYGHdOujQwUOHDpHTaKYokchuh4kTHRQVacybFxnruahkUU8xi97A0DRKRo4J6nXKqqI+/TSaoUPhhhtUFZSiNAWjRztJTPSwYIGNgwdDHU3DqWRRDxa5k6gvt5iLAJ3YIajX6tfPw7p1Bt27W7Db4cQTrTgcseh6ZBRtFSVSxcbCLbc4KCjQeOWVpt92oZJFPZStsV1chzW268vtjuG22zQmToQFC+D66zXS0y2UlMQE/dqKojTMtdc6OeooD/Pn28gPvxlL6kQli7oqLcX+/hI8bdviSBsc1EtZrTpZWVpVC9KRk6OZK9YpihK24uJgwgQneXkar73WtEsX6m5TR9EZn6AfOEDJVSMJ9uRMFouZLKqSmampFekUpQkYO9ZBQoLB3LlRFBbWfny4UnebOiofW3Ft0K/ldntISam651NqqqFWpFOUJiA+HsaNc7B/v87ChU23Z5RKFnWg//dnbDmZOHr1wX3KqUG/nstlJoukpIrbk5IgOdlQK9IpShNx000O4uIMXnzRRnFx7ceHI5Us6sC+ZDHQOKWKw9e0F5OR4WbJEg/jx8OSJR4yMtzY7U30L05RmqFWrczqqL17dd56q2mWLlSy8JfLhX3JYjwtEygdOqzRLuvxGNhsRaSlFTN3LqSlFWOzFeFRS5cqSpMyfryT2FiD2bNtlIZubaR6U8nCT7Y1q7D89SelV1wFMY3fbbWsyklVPSlK09S2rcG11zrZs0fnnXeaXulCJQs/2d/yjq0I0Gp4iqI0P7fc4sBuN0sXTmeoo6kblSz8oP/xO7bPVuM8tyvus5Jqf4KiKEoV2rUzGD3aya+/6nzwQdDWngsKlSz8YF+yGM3joWRU4zVsK4oSmSZOdGCzGcycGY2rCU0gHbTUJoTQgZeALkApcKOUcrfP/hHAZMANfAfcAliAhUBH7/ZxUsqdQoijgVeA1t5jrpFS/idYsVfg8WB/exFGbAtKL7uiUS6pKErkOu44g+HDnbz5po2PP7ZyxRVNI2MEs2QxDLBLKXsD9wLTy3YIIWKAJ4D+Uso+QAIwBBgMWL3bHgOmeZ/yDPCWlPJ84EHgtCDGXUFU1josv/1KyaWXY8TFN9ZlFUWJYLfd5sBqNZg504anifRZCWay6AesBJBSbga6++wrBfpIKb2rS2MFSoBdgNVbKmkJlDUB9QXaCyE+A0YBmUGMu4IY76SBJaOCsxqeoijNz4knGlx5pYtduyx88knTaLvQDCM4/fWFEAuAD6WUGd7HvwKdpJSuSsdNwixRDAbaA/8G4oC2wBAp5UYhhBO4SUr5uhDiYczSx8PVXdvlchtWq6XhL+Lvv6F9exACvvsONDUtuKIogbF7t3lrOess2LbNXOwsDFR7kwtmSjsE+Nbb6L6Jwlt6eAboDFwupTSEEFOAVVLK+4QQJwBrhRBJwH5gmfepyymvnqpSbm5RTbtrlZgYz969+cS89ApxTicFI8ZQvK+gQecMhLK4wo2Kq25UXHUTqXElJMCll9r58MMoFi8uJj09MG0XDYkrMbH6qvZg5rINmKUFhBC9gEoTbTMPsAPDfKqjcoE8788HgCjMBu31ZecCzge+D17YXoaB/a2FGNHRlFxxddAvpyhK8zNligNNM5gxw0aQKnkCJpgli6XAQCHERsyizfVCiJGYVUxbgbFADmbpAeAF4HngNSFEDmAD7pdSFgoh7gQWCCFuxkwmI4MYNwBRWzZh3f0TJZddidH6qGBfTlGUZqhzZw9Dh7pYtiyKtWstDBgQvssmBy1ZSCk9wIRKm3f6/FxdqeaqKs71P2BggELzi33RGwCUNMJqeIqiNF9TpjhYtiyK6dOjueCCorBtGg2PJpVwk5tL9PKPcZ3UCWeffqGORlGUCHbmmR4GDXKydauFnJwAdMwJEpUsqvL222glJeaI7XBN84qiRIw773QAMH16+C69qpJFJVaLDn/8gdGvHyVXB71pRFEUhS5dPAwY4GLTJiubNoVn6UIlCy9d12jtKCDh04/M8RXXXEOr1i3QdVWyUBQl+O64w1zkIlxLF01j6GAjSCjJx5qeBtvNHr7aggVYk5JIyFhFri0uxNEpihLpevTwcP75LrKzrWzdqtO9e3jNA6JKFoDVqqNnZR5OFIdt346ek4XVqt4mRVGCr6ztYsaM6BBHciR1FwQsFh0tK7PKfVpmJhaLepsURQm+3r3d9O7t4rPPrHz7bXjdd8IrmhBxuz0YKalV7jNSU3G7w6s4qChK5LrjjrLSRXi1XahkgbmutSclFZIqrYKXlIQnOUWte60oSqM5/3w33bq5yciI4vvvw+cWHT6RhFiePR5Xxio8S5bA+PF4lizBlbGKPLtaw0JRlMajaXDnnWbPqJkzw6d0oZKFl8djkGuLIy9tKMydS17aUHJtcXg8YT67l6IoEWfAADddurhZtszKrl3hcZsOjyjCSFmVk6p6UhQlVDTNnDPKMLSwKV2oZKEoihKGBg1ycfrpbj76yMrPP4d+cLBKFoqiKGFI182eUR6PxqxZoS9dqGShKIoSpoYMcXHqqW7eey+KX38NbelCJQtFUZQwZbHA5MkOXC6N2bNDW7pQyUJRFCWMXXqpi44dPSxZEsWePaErXahkoSiKEsasVpg8uRSHQ2POnNCVLoI266wQQgdeAroApcCNUsrdPvtHAJMBN/AdcAtgARYCHb3bx0kpdwohugLLgZ+8T39ZSvlusGJXFEUJJ1de6WL6dA+LFkVx220O2rVr/PFfwSxZDAPsUsrewL3A9LIdQogY4Amgv5SyD5AADAEGA1bvtseAad6ndAVmSClTvV8qUSiK0mxERcGkSQ5KSjRefjk0pYtgJot+wEoAKeVmoLvPvlKgj5SyyPvYCpQAuwCrt1TSEnB693cDLhZCZAshXhVCqDk4FEVpVkaMcHLssR7eeCOK/fsbv+0imIsftQTyfB67hRBWKaVLSukB/gIQQkwC4oA1QHvMKqidQFvM0gbAF8ACKeVXQogHgEeAu6q7cOvWsVitDVuaMDExPPORiqtuVFx1o+Kqm8aO69574fbbYdGiOKZNq/64YMQVzGRxCPCNWJdSusoeeEsPzwCdgcullIYQYgqwSkp5nxDiBGCtECIJWCqlPOh96lJgdk0Xzs0tqml3rRIT49m7N79B5wgGFVfdqLjqRsVVN6GIa9gweOKJFsyapXHddQW0ahXYuGpKMsGshtqA2QaBEKIXUGkZOuYBdmCYT3VULuWlkQNAFGaj9yohRE/v9gHAV0GMW1EUJSzFxMAttzgoKNCYP79x2y40wwhOq7pPb6izAQ24HrOhOg7Y6v3KAcoCeAGzKuo14FjABrwgpXzb2xtqDuAA/gRuklIequ7ae/fmN+hFqU8ydaPiqhsVV92ouCoqKIDu3Vvgdmt8/XUB8ZUKAw0sWVTbGBK0aihvu8SESpt3+vxcXanmqirO9TXQJ0ChKYqiNFlxcTBhgpN//SuaV1+1MXmyo1GuqwblKYqiNDFjxzpISDCYOzeKgoLGuaZKFoqiKE1MfDzcdJODAwd0Fi6MapRrqmShKIrSBI0b5yAuzuCll2wUFwf/eipZKIqiNEGtWsGNNzrYu1dn8eLgly5UslAURWmixo93EhtrMGeOjdLS4F5LJQtFUZQmqk0bg+uuc7Jnj86SJcEtXahkoSiK0oTdfLMDu91g9mwbTmftx9eXShaKoihNWLt2BmPGOPntN52cHHNUt9Ua+Fu7ShaKoihN3JQpTtauNThwwMb48ZCREYPDEYuuB2522mBOJKgoiqI0gpYt7Vx9tcZ27wx88+frJCWZScNma9jEqmVUyUJRFKUJs1p1srLKE0WZ7dshJ0cLWJWUShaKoihNmMViJouqZGZqWCwqWSiKojR7breHlJSqJ9pOTTVwuz0BuY5KFoqiKE2Yy2Umi6SkituTkiA52cDlCkyyUA3ciqIoTZzdXkxGRgw5ORqZmTqpqR6Skw3s9mI8gckVKlkoiqI0dR6Pgc1WRFqazvDhLcjNLcbl8gQsUYCqhlIURYkYZVVOgap68qWShaIoilIrlSwURVGUWqlkoSiKotRKJQtFURSlVpphVD2YQ1EURVHKqJKFoiiKUiuVLBRFUZRaqWShKIqi1EolC0VRFKVWKlkoiqIotVLJQlEURamVShaKoihKrdSss15CiCjgNaAjEA08IaVcFtKgACGEBXgFEIAbuF5K+Z/QRlVOCHE08BUwUEq5M9TxAAghtgF53of/lVJeH8p4yggh7gMuAWzAS1LKV0McEgBCiOuA67wP7cA5wDFSyoOhicjk/Z9ciPk/6QbGhcPfmBAiGngd6AQcAm6VUv4U4pjOA56WUqYKIU4B3gAMYIc3vgbPLKhKFuVGA/ullMlAOjAnxPGUGQogpewLPAzMCG045bz/zPOA4lDHUkYIYQeQUqZ6v8IlUaQCfYC+QApwQkgD8iGlfKPs/cJM/LeFOlF4DQasUso+wGPAtBDHU2YcUCCl7AVMIsT3CiHE3cACzEQP5j3iQe+9TAP+EYjrqGRR7n3gIZ/HrlAF4ktK+TFwk/dhB+Cv0EVzhOeAucAfoQ7ERxcgVgixWgixVgjRK9QBeaUB24GlwHLgk9CGcyQhRHfgTCnl/FDH4rULsAohdKAl4AxxPGXOADIApJQSOD204fAf4DKfx92ALO/PGcCFgbiIShZeUsoCKWW+ECIe+AB4MNQxlZFSuoQQC4HZmLGFnLfqYq+UclWoY6mkCDOJpQETgLeEEOFQ3doW6A5cSXlcWmhDOsL9wKOhDsJHAWYV1E7MqthZIY2m3DfAECGE5v0wcry3ujgkpJQfUjGRalLKsnmc8oGEQFxHJQsfQogTgHXAIinl26GOx5eU8lqgM/CKEKJFqOMBbgAGCiEyMeu43xRCHBPSiEy7gMVSSkNKuQvYDxwb4pjAjGOVlNLh/TRaAiSGOKbDhBCtgNOklOtCHYuPKZjvWWfMEuPCsmrGEHsNs61iHWY18VdSSndoQ6rAt30iHjgYiJOqZOElhGgHrAbukVK+Fup4ygghxngbRsH81OzBbOwLKSnl+VLKFG899zfANVLKP0MbFWAmsekAQojjMKsv9oQ0ItN6YJD30+hxQAvMBBIuzgc+C3UQleRS3lHhABAFhOwTvI8ewHrv3/5S4OfQhnOEbd42MjDbX3MCcdJwKJ6Hi/uB1sBDQoiytot0KWWoG28/Al4XQmRj/rNMllKWhDimcPYq8IYQYj1mb5AbpJQhb3+SUn4ihDgf+ALzQ9qtYfZpVBB+N73ngdeEEDmYPcjul1IWhjgmgJ+Ax4UQd2F+ah8b2nCOcCdmDYQN+JEAVV2rKcoVRVGUWqlqKEVRFKVWKlkoiqIotVLJQlEURamVShaKoihKrVSyUBRFUWqlkoXS7AghUr2DCcsexwshNgshpldx7DghxO9CiGdrOF+mT7923+1veEe6NyTWqUKIqQ05h6IEghpnoTRrQog4YCWQKaW8t4pDRmDO9Lu6cSNTlPCikoXSbHmnTVkBrJVSPlTF/oeBnsBLQojbMEcRv4A5u+c+YLyUcrfP8Rrm6PEhmJMrWoDMSuecAfwupSwbZf4hsBhzoNdsIA44GnhSSjm30nMNKaXm/fk6IFVKeZ0QogfmALZYn7j+K4S4A7gWc9T/F1LK8fV8qxRFVUMpzVYs5syvSZg32iNIKR8DtgI3Yk6F8Q4wUUrZBXO23SWVnnI5cC5wJuaEgadUcdpFmKUVvJNW9gY+9V7jCSllD6A/UG21ly/vKN0FwEgpZVfMZPWKd2K7+zAnL+wG2IQQx/tzTkWpikoWSnPVA/gcMwEs8OP4zkCulPJLACnl+8ApQgjfGT1TgY+klE4p5V7MUksFUsptgN27QM2lwHIppQNziga7dx6wJzBLGP7oDJwMLBNCfAM8DXTyTiWyEfgSeASYLqX83c9zKsoRVLJQmqtNUsonMG/SZwkhJtRyfFX/KxoVJ7YzvNvKVDcn1WLgau/XYu+29zCTxw/AA9UF4TOteZT3uwX4WUp5jpTyHMxSRD/vvmHAzd6YVgohUqo7r6LURiULpblyAEgpi4AxwDNCiDNqOF4CbbztAwghrgL+J6U84HPMZ8BVQohoIURrYFA153oLM1GcgjkbLcBA4GEp5b8xZwotW1LX1z7gTG/CuMS7bSdwlBAi2fv4BuBtIUQiZuLZLqV8GHNG5bNreH2KUiOVLJRmT0q5BbPd4p3q1kuQUpZi3uDnCCF2ABO9j32P+Tdmg/YOYBnmzbqqc/2GeeP/wGeRmqnAeiHED0Ay8AtwUqWn3ovZzrIJM3mVxXUlMF0I8R1mg/ZYbzXYfOBLIcRXmI3yYTP1vtL0qFlnFUVRlFqpkoWiKIpSK5UsFEVRlFqpZKEoiqLUSiULRVEUpVYqWSiKoii1UslCURRFqZVKFoqiKEqt/h+cQhS6mtrijwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard deviation for training set: 0.001  \n",
      "standard deviation for testing set: 0.003  \n"
     ]
    }
   ],
   "source": [
    "plt.xlabel('K fold values');\n",
    "plt.ylabel('logistic loss');\n",
    "\n",
    "sns.lineplot(x = K, y = K_train_loss, label = \"Train Loss\", color = \"red\", marker='o')\n",
    "sns.lineplot(x = K, y = K_test_loss, label = \"Test Loss\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Log loss across K values')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('standard deviation for training set: %.3f  ' %np.std(K_train_loss))\n",
    "print('standard deviation for testing set: %.3f  ' %np.std(K_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-colony",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beginning-sally",
   "metadata": {},
   "source": [
    "### CV with the best C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the results in clear tabular format\n",
    "pd.DataFrame(np.transpose([aver_train_score, aver_test_score, aver_train_loss, aver_test_loss]), columns=['train accuracy', 'test accuracy', 'train loss', 'test loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-quest",
   "metadata": {},
   "source": [
    "#### Best Log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = min(aver_test_loss)\n",
    "index_N2 = aver_test_loss.index(min_loss)\n",
    "best_C =  C_grid[index_N2]\n",
    "best_model = model_list[index_N2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-monday",
   "metadata": {},
   "source": [
    "#### stability across Kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-senior",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------\\nClassify with base data, 5 folds\\n-----------------\")\n",
    "\n",
    "K = [2,3,4,5,6,7,8,9,10,11,12]\n",
    "K_train_loss = []\n",
    "K_test_loss = []\n",
    "for k in K:\n",
    "    kfold = KFold(n_splits=k)\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    \n",
    "    for train_idx, test_idx in kfold.split(X):\n",
    "        shuffler = np.random.permutation(len(X))\n",
    "        X_shuffled = X[shuffler]\n",
    "        y_shuffled = y[shuffler]\n",
    "        X_train, X_test = X_shuffled[train_idx,:], X_shuffled[test_idx,:]\n",
    "        y_train, y_test = y_shuffled[train_idx], y_shuffled[test_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = best_model.predict_proba(X_train)\n",
    "        pred_test = best_model.predict_proba(X_test)\n",
    "\n",
    "        score_train = best_model.score(X_train, y_train)\n",
    "        score_test = best_model.score(X_test, y_test)\n",
    "        train_scores.append(score_train)\n",
    "        test_scores.append(score_test)\n",
    "        \n",
    "        log_loss_train = sklearn.metrics.log_loss(y_train,pred_train)\n",
    "        log_loss_test = sklearn.metrics.log_loss(y_test,pred_test)\n",
    "        \n",
    "        train_loss.append(log_loss_train)\n",
    "        test_loss.append(log_loss_test)\n",
    "\n",
    "    print(\"\\nAverage train accuracy: \", np.average(score_train))\n",
    "    print(\"Average test accuracy: \", np.average(score_test))\n",
    "    print(\"Average train loss: \", np.average(train_loss))\n",
    "    print(\"Average test loss: \", np.average(test_loss))\n",
    "    \n",
    "    K_train_loss.append(np.average(train_loss))\n",
    "    K_test_loss.append(np.average(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('K from 2 to 12');\n",
    "plt.ylabel('logistic loss');\n",
    "\n",
    "sns.lineplot(x = K, y = K_train_loss, label = \"Train Loss\", color = \"red\", marker='o')\n",
    "sns.lineplot(x = K, y = K_test_loss, label = \"Test Loss\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Log loss across K values')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('standard deviation for training set: %.3f  ' %np.std(K_train_loss))\n",
    "print('standard deviation for testing set: %.3f  ' %np.std(K_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('log10(C)');\n",
    "plt.ylabel('logistic loss');\n",
    "plt.ylim([0.0, 1]);\n",
    "\n",
    "sns.lineplot(x = np.log10(C_grid), y = aver_train_loss, label = \"Train Loss\", color = \"red\", marker='o')\n",
    "sns.lineplot(x = np.log10(C_grid), y = aver_test_loss,label = \"Test Loss\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Logistic loss on C-grid')\n",
    "plt.show()\n",
    "\n",
    "print(\"Best C-value for LR: %.3f\" % best_C) \n",
    "print(\"Test set log-loss at best C-value: %.4f\" % min_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-satin",
   "metadata": {},
   "source": [
    "#### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "judicial-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "yproba1_test = best_model.predict_proba(x_te)[:, 1] \n",
    "np.savetxt('yproba1_test.txt', yproba1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-circuit",
   "metadata": {},
   "source": [
    "# Neuronetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from MLPClassifierWithSolverLBFGS import MLPClassifierLBFGS\n",
    "\n",
    "from viz_tools_for_binary_classifier import plot_pretty_probabilities_for_clf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 16\n",
    "tr_classifierLBFS = list()\n",
    "\n",
    "for i in range(n_runs):\n",
    "    start_time_sec = time.time()\n",
    "    mlp_lbfgs = MLPClassifier(\n",
    "        hidden_layer_sizes=[2],\n",
    "        activation='relu',\n",
    "        alpha=0.0001,\n",
    "        max_iter=200, tol=1e-6,\n",
    "        random_state=i,\n",
    "        )\n",
    "    with warnings.catch_warnings(record=True) as warn_list:\n",
    "        clf = mlp_lbfgs.fit(x_tr_N2, y_tr_N)\n",
    "    elapsed_time_sec = time.time() - start_time_sec\n",
    "    print('finished LBFGS run %2d/%d after %6.1f sec | %3d iters | %s | loss %.3f' % (\n",
    "        i+1, n_runs, elapsed_time_sec,\n",
    "        len(mlp_lbfgs.loss_curve_),\n",
    "        'converged   ' if mlp_lbfgs.did_converge else 'NOT converged',\n",
    "        mlp_lbfgs.loss_))\n",
    "        \n",
    "    tr_classifierLBFS.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "conditional-commodity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([2.47359045]),\n",
       " 'std_fit_time': array([0.26363435]),\n",
       " 'mean_score_time': array([0.01352191]),\n",
       " 'std_score_time': array([0.01492832]),\n",
       " 'params': [{}],\n",
       " 'split0_test_score': array([0.6775]),\n",
       " 'split1_test_score': array([0.665]),\n",
       " 'split2_test_score': array([0.66375]),\n",
       " 'mean_test_score': array([0.66875]),\n",
       " 'std_test_score': array([0.00620819]),\n",
       " 'rank_test_score': array([1], dtype=int32)}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {}\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(8,4), \n",
    "                            activation='relu',\n",
    "                            solver='adam',\n",
    "                            alpha=0.0001,\n",
    "                            max_iter=160, tol=1e-6,\n",
    "                            random_state=1)\n",
    "\n",
    "clf = GridSearchCV(model, parameters,cv=3)\n",
    "clf.fit(X,y)\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-layer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

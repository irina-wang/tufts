{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "formed-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unnecessary-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn') # pretty matplotlib plots\n",
    "\n",
    "x_train_df = pd.read_csv('../data/data_reviews/x_train.csv')\n",
    "y_train_df = pd.read_csv('../data/data_reviews/y_train.csv')\n",
    "x_test_df = pd.read_csv('../data/data_reviews/x_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wanted-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_df['text'] \n",
    "x_test = x_test_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "israeli-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_i = np.where(x_train_df['website_name']=='amazon')\n",
    "imdb_i = np.where(x_train_df['website_name']=='imdb')\n",
    "yelp_i =  np.where(x_train_df['website_name']=='yelp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-registration",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "social-census",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autocorrect in /Users/mac/opt/anaconda3/envs/ml135_env/lib/python3.8/site-packages (2.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "conscious-melbourne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'absolute'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autocorrect import Speller\n",
    "spell = Speller()\n",
    "spell('absoluel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "nuclear-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "becoming-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = pd.read_csv('../data/data_reviews/modified_stopword.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-jordan",
   "metadata": {},
   "source": [
    "### Build your own tokenizer ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "formal-quarterly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/mac/.local/lib/python3.8/site-packages (3.6.2)\n",
      "Requirement already satisfied: click in /Users/mac/opt/anaconda3/envs/ml135_env/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /Users/mac/opt/anaconda3/envs/ml135_env/lib/python3.8/site-packages (from nltk) (4.60.0)\n",
      "Requirement already satisfied: joblib in /Users/mac/opt/anaconda3/envs/ml135_env/lib/python3.8/site-packages (from nltk) (1.0.0)\n",
      "Requirement already satisfied: regex in /Users/mac/opt/anaconda3/envs/ml135_env/lib/python3.8/site-packages (from nltk) (2021.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "logical-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "porterstemmer = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ongoing-empire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "busi\n",
      "bu\n",
      "busi\n",
      "busi\n"
     ]
    }
   ],
   "source": [
    "# same stem \n",
    "print(porterstemmer.stem('business'))\n",
    "print(porterstemmer.stem('bus'))\n",
    "print(porterstemmer.stem('businesses'))\n",
    "print(porterstemmer.stem('busy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-survey",
   "metadata": {},
   "source": [
    "# STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "oriental-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "# def decontracted(phrase):\n",
    "#     # specific\n",
    "#     phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "#     phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "#     # general\n",
    "#     phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "#     phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "#     phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "#     phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "#     phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "#     phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "#     phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "#     phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "#     return phrase\n",
    "\n",
    "def stemming_tokenizer(str_input):\n",
    "#     words = decontracted(str_input)\n",
    "    words = re.sub(r\"[^A-Za-z\\-]\", \" \", str_input).lower().split()\n",
    "    \n",
    "    # autocorrect\n",
    "    test_names = words\n",
    "    test_names_len = len(words)\n",
    "    words = [spell(test_names[i]) for i in range(test_names_len)]\n",
    "\n",
    "    # prune words\n",
    "#     def prune_food(w):\n",
    "#         if w == 'bones' or w == 'bone' or w == 'fish' or w == 'worms' or w == 'worm':\n",
    "#             w = 'food'\n",
    "#         return w\n",
    "    \n",
    "#     words = [prune_food(word) for word in words]\n",
    "    \n",
    "    # stemming \n",
    "    porter_stemmer = PorterStemmer()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    \n",
    "    #remove non important words\n",
    "    non_important = ['film', 'movie','apple', 'juice']\n",
    "    words = [w for w in words if w not in non_important]\n",
    "    \n",
    "    stop_words = common_words['words']\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-broadway",
   "metadata": {},
   "source": [
    "**Note: tense, persons**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-precipitation",
   "metadata": {},
   "source": [
    "## TF/IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adverse-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "complicated-grant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3429"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectorizer = TfidfVectorizer(tokenizer=stemming_tokenizer, use_idf = True)\n",
    "x = tf_vectorizer.fit_transform(x_train)\n",
    "x_te = tf_vectorizer.transform(x_test)\n",
    "features = tf_vectorizer.get_feature_names()\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-advantage",
   "metadata": {},
   "source": [
    "# NeuroNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "concerned-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from MLPClassifierWithSolverLBFGS import MLPClassifierLBFGS\n",
    "\n",
    "from viz_tools_for_binary_classifier import plot_pretty_probabilities_for_clf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "revised-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x.toarray()\n",
    "y = y_train_df['is_positive_sentiment'].to_numpy()\n",
    "feat_num = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-worker",
   "metadata": {},
   "source": [
    "### Problem 2: MLP size [2] with activation Logistic and L-BFGS solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "tamil-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-lincoln",
   "metadata": {},
   "source": [
    "### iteration - best at 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "instructional-camping",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For 1 hidden layers :  10\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  17.269521463693707\n",
      "Average test loss:  17.269521463693707\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  20\n",
      "\n",
      "Average train accuracy:  0.84875\n",
      "Average test accuracy:  0.76125\n",
      "\n",
      "Average train loss:  9.253547825360604\n",
      "Average test loss:  12.318879222860742\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  30\n",
      "\n",
      "Average train accuracy:  0.93125\n",
      "Average test accuracy:  0.7775\n",
      "\n",
      "Average train loss:  3.439522797709811\n",
      "Average test loss:  8.908219698053164\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  40\n",
      "\n",
      "Average train accuracy:  0.9825\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.9714087499219944\n",
      "Average test loss:  8.663565367604205\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  50\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.75875\n",
      "\n",
      "Average train loss:  0.4101489691863531\n",
      "Average test loss:  9.124083718865398\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  60\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.2806280579570441\n",
      "Average test loss:  9.037734445718952\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  70\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.22306293088379917\n",
      "Average test loss:  9.296780599330315\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  80\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.21586751905099075\n",
      "Average test loss:  9.138477874186975\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  90\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.21586751905099075\n",
      "Average test loss:  9.282396772142214\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  100\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.21586751905099075\n",
      "Average test loss:  9.354357220616619\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  110\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.21586735246819277\n",
      "Average test loss:  9.253616457473363\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  120\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.21586751905099075\n",
      "Average test loss:  9.124094046998872\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  130\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.21586751905099075\n",
      "Average test loss:  9.26800794747017\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  140\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.21586751905099075\n",
      "Average test loss:  9.03774344119004\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  150\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.21586768563378866\n",
      "Average test loss:  9.268011279126132\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  160\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.20867194063538433\n",
      "Average test loss:  9.196055161804471\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  170\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.20867177405258638\n",
      "Average test loss:  9.138486203326872\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  180\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.22306526304297056\n",
      "Average test loss:  9.268006281642192\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  190\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.1726963807165238\n",
      "Average test loss:  9.354351889967086\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  200\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.14391356730570434\n",
      "Average test loss:  9.224831811651766\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  210\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.10073959706367208\n",
      "Average test loss:  9.181662005979684\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  220\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.10073943048087412\n",
      "Average test loss:  9.181657008495746\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  230\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.06476070548885239\n",
      "Average test loss:  8.980176481706017\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  240\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.04317363707643731\n",
      "Average test loss:  9.023350951696445\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  250\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.04317347049363934\n",
      "Average test loss:  9.052133598524465\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  260\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.04317347049363934\n",
      "Average test loss:  9.109698559014914\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  270\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.04317347049363934\n",
      "Average test loss:  9.18165734166134\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  280\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.04317347049363934\n",
      "Average test loss:  9.167266184830128\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  290\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.04317347049363934\n",
      "Average test loss:  9.196049164823744\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "For 1 hidden layers :  300\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.04317347049363934\n",
      "Average test loss:  9.152874028502128\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_range = 20\n",
    "model_list = []\n",
    "aver_train_score = []\n",
    "aver_test_score = []\n",
    "aver_train_loss = []\n",
    "aver_test_loss = []\n",
    "\n",
    "for i in range(30):\n",
    "    k = 3\n",
    "    kfold = KFold(n_splits=k)\n",
    "    \n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "\n",
    "    model = MLPClassifier(hidden_layer_sizes=(1,8), \n",
    "                    activation='logistic',\n",
    "                    solver='lbfgs',\n",
    "                    alpha=0.0001,\n",
    "                    max_iter=10*(i+1), tol=1e-6,\n",
    "                    random_state=1 )\n",
    "    for train_idx, test_idx in kfold.split(X):\n",
    "        X_train, X_test = X[train_idx,:], X[test_idx,:]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = model.predict_proba(X_train)\n",
    "        pred_test = model.predict_proba(X_test)\n",
    "\n",
    "        # Score\n",
    "        score_train = model.score(X_train, y_train)\n",
    "        score_test = model.score(X_test, y_test)\n",
    "#         print(\"Train score: \", score_train)\n",
    "#         print(\"Test score: \", score_test)\n",
    "        train_scores.append(score_train)\n",
    "        test_scores.append(score_test)\n",
    "        \n",
    "        # Log loss\n",
    "        log_loss_train = sklearn.metrics.log_loss(y_train,pred_train)\n",
    "        log_loss_test = sklearn.metrics.log_loss(y_test,pred_test)\n",
    "    \n",
    "#         print(\"Train loss: \", log_loss_train)\n",
    "#         print(\"Test loss: \", log_loss_test)\n",
    "        train_loss.append(log_loss_train)\n",
    "        test_loss.append(log_loss_test)\n",
    "        \n",
    "#         with warnings.catch_warnings(record=True) as warn_list:\n",
    "#             print('finished LBFGS run :loss %.3f' % (\n",
    "#              model.loss_))\n",
    "        \n",
    "    print(\"\\nFor 1 hidden layers : \", 10*(i+1))\n",
    "    print(\"\\nAverage train accuracy: \", np.average(score_train))\n",
    "    print(\"Average test accuracy: \", np.average(score_test))\n",
    "    print(\"\\nAverage train loss: \", np.average(train_loss))\n",
    "    print(\"Average test loss: \", np.average(test_loss))\n",
    "    \n",
    "    print('------------------------------------------------\\n')\n",
    "    \n",
    "#     model_list.append(model)\n",
    "#     aver_train_score.append(np.average(score_train))\n",
    "#     aver_test_score.append(np.average(score_test))\n",
    "#     aver_train_loss.append(np.average(train_loss))\n",
    "#     aver_test_loss.append(np.average(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-somerset",
   "metadata": {},
   "source": [
    "### Best neuron number - i (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "standing-colon",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7005294554338972\n",
      "Average test loss:  0.7005398440372136\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6957233108161484\n",
      "Average test loss:  0.6957286117000571\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6938723701812856\n",
      "Average test loss:  0.693883888794815\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6932433797865557\n",
      "Average test loss:  0.6932881942626573\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.69292300016579\n",
      "Average test loss:  0.6930888303354078\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6924003417996186\n",
      "Average test loss:  0.692881927822655\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9075\n",
      "Average test accuracy:  0.69375\n",
      "\n",
      "Average train loss:  0.6914279546658816\n",
      "Average test loss:  0.6925268317815814\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.898125\n",
      "Average test accuracy:  0.70625\n",
      "\n",
      "Average train loss:  0.6897618722151027\n",
      "Average test loss:  0.6919196575699932\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.909375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.6869672351753842\n",
      "Average test loss:  0.690895148935784\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.92875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.6823511369927587\n",
      "Average test loss:  0.6891886068765808\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.6749840532410255\n",
      "Average test loss:  0.6864384350942926\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.6639569432431491\n",
      "Average test loss:  0.6822807715354978\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.6488145976005503\n",
      "Average test loss:  0.6765337211421296\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.6297032270606883\n",
      "Average test loss:  0.6692171276294471\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.6072270572948039\n",
      "Average test loss:  0.6605884067418885\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.75875\n",
      "\n",
      "Average train loss:  0.5820891932481121\n",
      "Average test loss:  0.6509172135787094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.5551574441561433\n",
      "Average test loss:  0.6405452030638608\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.5272252900463144\n",
      "Average test loss:  0.6298759610508388\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.49901532355267547\n",
      "Average test loss:  0.6190780497105758\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.4711622182797246\n",
      "Average test loss:  0.6085702170866506\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.96625\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.44406246496604923\n",
      "Average test loss:  0.5984979845804712\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.4180045011844388\n",
      "Average test loss:  0.5890039745113681\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3931430714549789\n",
      "Average test loss:  0.5801864718146271\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.36959168101468975\n",
      "Average test loss:  0.5721099725666168\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3473941929727913\n",
      "Average test loss:  0.5646620615157288\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.32654758069161316\n",
      "Average test loss:  0.5580838862457184\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.30702694446868944\n",
      "Average test loss:  0.5521766739357026\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.28878074680872695\n",
      "Average test loss:  0.5471768788986817\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.271752116819798\n",
      "Average test loss:  0.5428452551930484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.25587699027953237\n",
      "Average test loss:  0.5391414055850984\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7017459810458083\n",
      "Average test loss:  0.7017874629299974\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6950656967741399\n",
      "Average test loss:  0.695161069251197\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6930698117287917\n",
      "Average test loss:  0.6933490401044473\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6918711257360842\n",
      "Average test loss:  0.6927308190840703\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.735\n",
      "Average test accuracy:  0.56625\n",
      "\n",
      "Average train loss:  0.689915393155277\n",
      "Average test loss:  0.6920038510804752\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6869099155121708\n",
      "Average test loss:  0.6909341116385498\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.89\n",
      "Average test accuracy:  0.6725\n",
      "\n",
      "Average train loss:  0.6828395097499823\n",
      "Average test loss:  0.6894863434883324\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.8675\n",
      "Average test accuracy:  0.6225\n",
      "\n",
      "Average train loss:  0.6776511699907527\n",
      "Average test loss:  0.6876431186887094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.86875\n",
      "Average test accuracy:  0.62375\n",
      "\n",
      "Average train loss:  0.6711284758114199\n",
      "Average test loss:  0.6853083616460499\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.880625\n",
      "Average test accuracy:  0.6325\n",
      "\n",
      "Average train loss:  0.6629037288957935\n",
      "Average test loss:  0.6823552386081749\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.896875\n",
      "Average test accuracy:  0.66625\n",
      "\n",
      "Average train loss:  0.6524341714786962\n",
      "Average test loss:  0.6785421836183242\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.91\n",
      "Average test accuracy:  0.6875\n",
      "\n",
      "Average train loss:  0.63909927554148\n",
      "Average test loss:  0.6736597119148057\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.7125\n",
      "\n",
      "Average train loss:  0.6223565535916874\n",
      "Average test loss:  0.6674206546959397\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.94125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.6018944734243061\n",
      "Average test loss:  0.6597922203883599\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.5778989480746972\n",
      "Average test loss:  0.650789772219996\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.5510996751894053\n",
      "Average test loss:  0.6408158740067246\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5220648590196489\n",
      "Average test loss:  0.6300876375511023\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.958125\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.4916647894442859\n",
      "Average test loss:  0.6189473927298889\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.46068949368686374\n",
      "Average test loss:  0.6077818776415354\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.4299076979933048\n",
      "Average test loss:  0.5968313935374918\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3999180332202758\n",
      "Average test loss:  0.5863922649896106\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.3711625436335508\n",
      "Average test loss:  0.5767344613683999\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.34400494851247077\n",
      "Average test loss:  0.568030904477045\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3185927569633206\n",
      "Average test loss:  0.5602229990889959\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2950033008494264\n",
      "Average test loss:  0.553694640334892\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.27318703552587215\n",
      "Average test loss:  0.5479846786911868\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.25311106210337697\n",
      "Average test loss:  0.5433360138546028\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.23467783147248256\n",
      "Average test loss:  0.5395091827202345\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.21779856704212094\n",
      "Average test loss:  0.5368094097895747\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.20234579841839098\n",
      "Average test loss:  0.534645924991742\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6982820562332842\n",
      "Average test loss:  0.6983915288591721\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6933338488376656\n",
      "Average test loss:  0.6936944301470566\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6918869168294853\n",
      "Average test loss:  0.6927501754864592\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.915\n",
      "Average test accuracy:  0.68125\n",
      "\n",
      "Average train loss:  0.6903597288351895\n",
      "Average test loss:  0.6921791637516207\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6878417159809903\n",
      "Average test loss:  0.6912919817475394\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.94375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.6839442896931308\n",
      "Average test loss:  0.6899135041970706\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6783100673958469\n",
      "Average test loss:  0.6879005622217803\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6704440726968119\n",
      "Average test loss:  0.6850680495423931\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.6596857019150905\n",
      "Average test loss:  0.6811624364034614\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.6453238585426988\n",
      "Average test loss:  0.6759301367521999\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.6266430574580806\n",
      "Average test loss:  0.6690618978057348\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.6034038414721389\n",
      "Average test loss:  0.6605098459485128\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.575675283402601\n",
      "Average test loss:  0.6502343946307992\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.5441206850060811\n",
      "Average test loss:  0.6386249589127551\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.5097629024264306\n",
      "Average test loss:  0.6260881869619405\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.4739570696645874\n",
      "Average test loss:  0.6131862312315367\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.4379017393609253\n",
      "Average test loss:  0.6003241774937309\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.4026712525737594\n",
      "Average test loss:  0.5881587851326255\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3690593910592603\n",
      "Average test loss:  0.5769475248677269\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.966875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.3375474011442637\n",
      "Average test loss:  0.5669392739989525\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.308420398900793\n",
      "Average test loss:  0.5581006196182613\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2817824131896938\n",
      "Average test loss:  0.5508302785342779\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.25759252158008245\n",
      "Average test loss:  0.5446990102418523\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.23574101584949983\n",
      "Average test loss:  0.5403214923063983\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.21605198114217436\n",
      "Average test loss:  0.5365816435510261\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.19833110771618276\n",
      "Average test loss:  0.5343190335711073\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.18237904473975544\n",
      "Average test loss:  0.532996199095119\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.16801550945904922\n",
      "Average test loss:  0.5326528628516788\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.15507521725063114\n",
      "Average test loss:  0.5330682437107455\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.14339220397774657\n",
      "Average test loss:  0.5343860218341836\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6986740284939855\n",
      "Average test loss:  0.699062002573962\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6926601111020734\n",
      "Average test loss:  0.6934756881901977\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6911365585324938\n",
      "Average test loss:  0.6924997868607283\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.796875\n",
      "Average test accuracy:  0.545\n",
      "\n",
      "Average train loss:  0.6898589158097317\n",
      "Average test loss:  0.6920123269596131\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.876875\n",
      "Average test accuracy:  0.6125\n",
      "\n",
      "Average train loss:  0.6880255740096466\n",
      "Average test loss:  0.6913705794921472\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.875\n",
      "Average test accuracy:  0.6125\n",
      "\n",
      "Average train loss:  0.6852987454137739\n",
      "Average test loss:  0.6904197045514966\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.88625\n",
      "Average test accuracy:  0.6325\n",
      "\n",
      "Average train loss:  0.6812983585040261\n",
      "Average test loss:  0.6890203017576191\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.8875\n",
      "Average test accuracy:  0.63875\n",
      "\n",
      "Average train loss:  0.675523736709729\n",
      "Average test loss:  0.6869990221927567\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.890625\n",
      "Average test accuracy:  0.6525\n",
      "\n",
      "Average train loss:  0.6673803238449144\n",
      "Average test loss:  0.6841455234945321\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9\n",
      "Average test accuracy:  0.6675\n",
      "\n",
      "Average train loss:  0.6560762517402328\n",
      "Average test loss:  0.680172174248535\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.9075\n",
      "Average test accuracy:  0.68625\n",
      "\n",
      "Average train loss:  0.6407889967459997\n",
      "Average test loss:  0.6747683691504983\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.925625\n",
      "Average test accuracy:  0.70375\n",
      "\n",
      "Average train loss:  0.620790759864598\n",
      "Average test loss:  0.6676858536746971\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.5958386650293223\n",
      "Average test loss:  0.6588075922817508\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.936875\n",
      "Average test accuracy:  0.71375\n",
      "\n",
      "Average train loss:  0.5662987919546167\n",
      "Average test loss:  0.648473502478819\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.715\n",
      "\n",
      "Average train loss:  0.5328540630739459\n",
      "Average test loss:  0.636696865462314\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.4968642882138932\n",
      "Average test loss:  0.6242371400995038\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.955\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.4597279550049671\n",
      "Average test loss:  0.6114153818790556\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.4226693528047611\n",
      "Average test loss:  0.5989760494360666\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.386833898037686\n",
      "Average test loss:  0.5871416578227912\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3530025487112778\n",
      "Average test loss:  0.5767072899340123\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.3216007337893912\n",
      "Average test loss:  0.5673384063619504\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.29283679087837394\n",
      "Average test loss:  0.5592409133905049\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2667592043104434\n",
      "Average test loss:  0.5526714986845548\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.24323779399081077\n",
      "Average test loss:  0.5478213014932719\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2221030075099432\n",
      "Average test loss:  0.5439568455392559\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2031551260412645\n",
      "Average test loss:  0.5413957689920994\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1861794331503629\n",
      "Average test loss:  0.5401143506561344\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.17096430142398342\n",
      "Average test loss:  0.5395081400131999\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.15731488613829006\n",
      "Average test loss:  0.5400562060423595\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.14505596240792154\n",
      "Average test loss:  0.5414270933752853\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6938432282308608\n",
      "Average test loss:  0.694123309774367\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6921018743823355\n",
      "Average test loss:  0.6927993649999218\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.81125\n",
      "Average test accuracy:  0.635\n",
      "\n",
      "Average train loss:  0.6910264554060855\n",
      "Average test loss:  0.6924142995773112\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.818125\n",
      "Average test accuracy:  0.63875\n",
      "\n",
      "Average train loss:  0.6892008984017487\n",
      "Average test loss:  0.6917796099301766\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6862044992439621\n",
      "Average test loss:  0.6907301429493766\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6815282037035914\n",
      "Average test loss:  0.6890838261228991\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.6744819306563681\n",
      "Average test loss:  0.6865897663912608\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6641303944189053\n",
      "Average test loss:  0.6828960096056682\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6492329687519879\n",
      "Average test loss:  0.6775412207779942\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6285818359919378\n",
      "Average test loss:  0.6700819764020854\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.6013680461880332\n",
      "Average test loss:  0.6602201255756038\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.5678290494160384\n",
      "Average test loss:  0.6479996167294857\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.529037464560802\n",
      "Average test loss:  0.6340023136572438\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.4870103992022674\n",
      "Average test loss:  0.6190040092377497\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.443750867663482\n",
      "Average test loss:  0.6038287383660198\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.40116535429253136\n",
      "Average test loss:  0.5892785034231237\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3608515305740792\n",
      "Average test loss:  0.5760887700835728\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.32370866170944934\n",
      "Average test loss:  0.5645433725085479\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.29015582714944455\n",
      "Average test loss:  0.5550832233122124\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.26022590768329623\n",
      "Average test loss:  0.5476572058460555\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.23375816384356082\n",
      "Average test loss:  0.5417785815201223\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.21046457550792133\n",
      "Average test loss:  0.5377748719782566\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.18999817337592773\n",
      "Average test loss:  0.5355434545871322\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.17202357508027136\n",
      "Average test loss:  0.5343991155491205\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.15621539094008677\n",
      "Average test loss:  0.5347337765576106\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.14226886593137203\n",
      "Average test loss:  0.5360509968905758\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1299616027696747\n",
      "Average test loss:  0.5381172866990679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.11904767845325637\n",
      "Average test loss:  0.5413307880736378\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.10933963573098743\n",
      "Average test loss:  0.5451206269134198\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.10068541356261018\n",
      "Average test loss:  0.549574690461608\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6964048028479414\n",
      "Average test loss:  0.6966777699440069\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6923326919951288\n",
      "Average test loss:  0.6929862688497708\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.7775\n",
      "Average test accuracy:  0.53125\n",
      "\n",
      "Average train loss:  0.6912471772431396\n",
      "Average test loss:  0.6924927370157518\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6897215761348813\n",
      "Average test loss:  0.6919582926864004\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.910625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.6871974179098609\n",
      "Average test loss:  0.6910737186519365\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6831486839848226\n",
      "Average test loss:  0.6896495576035346\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6768517784479685\n",
      "Average test loss:  0.6874230770614186\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6672326660526983\n",
      "Average test loss:  0.6839974035488998\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.945625\n",
      "Average test accuracy:  0.7575\n",
      "\n",
      "Average train loss:  0.6529648279500696\n",
      "Average test loss:  0.6788893747576928\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.6327032749361551\n",
      "Average test loss:  0.6715786731154388\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.6053901834517518\n",
      "Average test loss:  0.6616836024675469\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.5709294485911997\n",
      "Average test loss:  0.6492181246814406\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.5301925059988134\n",
      "Average test loss:  0.6345265030831562\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.4853497129354524\n",
      "Average test loss:  0.618615074379905\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.4390258676620357\n",
      "Average test loss:  0.6024460753414312\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3936629378912811\n",
      "Average test loss:  0.5872606718302374\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.35110654965749366\n",
      "Average test loss:  0.5734111912236011\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.31236111611079515\n",
      "Average test loss:  0.5617897867697278\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.27783094956571824\n",
      "Average test loss:  0.5523267462097475\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.24747772937207135\n",
      "Average test loss:  0.5451326112822642\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.22099276219272235\n",
      "Average test loss:  0.5401306829865541\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.19795816613144948\n",
      "Average test loss:  0.5370187531829643\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1779282240326069\n",
      "Average test loss:  0.5353493054081694\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.16049765112159634\n",
      "Average test loss:  0.5352702623728484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.14530008445038115\n",
      "Average test loss:  0.5362642028309876\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1319859404459862\n",
      "Average test loss:  0.5386961673478461\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.12028917079409833\n",
      "Average test loss:  0.5416551750865083\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.1099719964290729\n",
      "Average test loss:  0.5456999465176495\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.10084091989401811\n",
      "Average test loss:  0.5503061042669896\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.09272365631325992\n",
      "Average test loss:  0.555578185074637\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6929797147110236\n",
      "Average test loss:  0.6930898307985885\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.664375\n",
      "Average test accuracy:  0.54375\n",
      "\n",
      "Average train loss:  0.6924934791982884\n",
      "Average test loss:  0.6929206361020065\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.92375\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.6912289983673326\n",
      "Average test loss:  0.6924812258374996\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.839375\n",
      "Average test accuracy:  0.58625\n",
      "\n",
      "Average train loss:  0.6886416249218875\n",
      "Average test loss:  0.691586013314215\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.9275\n",
      "Average test accuracy:  0.71375\n",
      "\n",
      "Average train loss:  0.684213041642975\n",
      "Average test loss:  0.6900314836915928\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.89875\n",
      "Average test accuracy:  0.67875\n",
      "\n",
      "Average train loss:  0.6771274136766583\n",
      "Average test loss:  0.6875598165776058\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.925625\n",
      "Average test accuracy:  0.70375\n",
      "\n",
      "Average train loss:  0.6661108829993664\n",
      "Average test loss:  0.6836606662102672\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.93375\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.6495883299827555\n",
      "Average test loss:  0.6777351409421994\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.6259169508235074\n",
      "Average test loss:  0.6692882012634634\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.5943225357931794\n",
      "Average test loss:  0.6579145528248338\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.5553238390360403\n",
      "Average test loss:  0.6439580932277528\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.5107242681706176\n",
      "Average test loss:  0.6280383377281703\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.4630676058423208\n",
      "Average test loss:  0.611556792721477\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.41530641000658575\n",
      "Average test loss:  0.5952147760253896\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.36969133785757274\n",
      "Average test loss:  0.5805453353372098\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3278242398080642\n",
      "Average test loss:  0.5674872310962206\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.29034919865859327\n",
      "Average test loss:  0.5569845315361489\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.25740482870815884\n",
      "Average test loss:  0.548776880873706\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.22868661580177077\n",
      "Average test loss:  0.543222794414231\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.20382183382667993\n",
      "Average test loss:  0.5393448835435452\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.1822977766833859\n",
      "Average test loss:  0.5371432851268564\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1636749111627489\n",
      "Average test loss:  0.5368929311258459\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.14750863328583178\n",
      "Average test loss:  0.5378231810763763\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13344113542734112\n",
      "Average test loss:  0.5401143345652949\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.12115317211227151\n",
      "Average test loss:  0.5431816579452332\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.11036835398861149\n",
      "Average test loss:  0.5471737223327502\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.10087070645129083\n",
      "Average test loss:  0.5519614315541534\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09247968937871615\n",
      "Average test loss:  0.557477029753625\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08502696866697247\n",
      "Average test loss:  0.5638562570381361\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07837757793806072\n",
      "Average test loss:  0.5701891374163082\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.800625\n",
      "Average test accuracy:  0.58375\n",
      "\n",
      "Average train loss:  0.6930901370677017\n",
      "Average test loss:  0.6931268885349545\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6926216158853378\n",
      "Average test loss:  0.6929645332385221\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.64625\n",
      "Average test accuracy:  0.505\n",
      "\n",
      "Average train loss:  0.6911212078408489\n",
      "Average test loss:  0.6924434322289633\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.901875\n",
      "Average test accuracy:  0.6925\n",
      "\n",
      "Average train loss:  0.6880430519126118\n",
      "Average test loss:  0.6913673268939052\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.9225\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.6828876487966227\n",
      "Average test loss:  0.6895595594037323\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.6747140000898016\n",
      "Average test loss:  0.6866650798216716\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.6620564960245211\n",
      "Average test loss:  0.6821667837314602\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.6430880964394845\n",
      "Average test loss:  0.6753896258774462\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6161724034268318\n",
      "Average test loss:  0.6656732586294344\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5807804585694664\n",
      "Average test loss:  0.6529133218684288\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5376609987578084\n",
      "Average test loss:  0.6374463228023766\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.4894282027264771\n",
      "Average test loss:  0.6202619612525828\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.43935320486563206\n",
      "Average test loss:  0.6028160136257288\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.3902578096466172\n",
      "Average test loss:  0.5861236187190438\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.3444151893514725\n",
      "Average test loss:  0.5717771572817993\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.96625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3031140849410245\n",
      "Average test loss:  0.5593039765604797\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2667935597171171\n",
      "Average test loss:  0.5498189553078786\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.23533426057580256\n",
      "Average test loss:  0.5429488355799076\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.20826162815836857\n",
      "Average test loss:  0.5385422301073496\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.18502327821538844\n",
      "Average test loss:  0.5360065873927433\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.165084479472444\n",
      "Average test loss:  0.5353686802291548\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.14796436077522782\n",
      "Average test loss:  0.5363838149836735\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13318972517284602\n",
      "Average test loss:  0.5386486315681557\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.12039974178985417\n",
      "Average test loss:  0.5420023003891986\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.10926405416275321\n",
      "Average test loss:  0.5463237458493145\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.09951880778024162\n",
      "Average test loss:  0.551409147711771\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09094420312154239\n",
      "Average test loss:  0.5573425822258377\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08338553455203818\n",
      "Average test loss:  0.5636054020163095\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07667712118452148\n",
      "Average test loss:  0.5706616965493121\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07070242983197365\n",
      "Average test loss:  0.5780118333740777\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6929778347439598\n",
      "Average test loss:  0.6930999782567108\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.534375\n",
      "Average test accuracy:  0.505\n",
      "\n",
      "Average train loss:  0.6925772016029755\n",
      "Average test loss:  0.6929475387882033\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.75125\n",
      "Average test accuracy:  0.57\n",
      "\n",
      "Average train loss:  0.69161735765431\n",
      "Average test loss:  0.6926137042448272\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.928125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.6895449607057098\n",
      "Average test loss:  0.6918914503737801\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.82625\n",
      "Average test accuracy:  0.63375\n",
      "\n",
      "Average train loss:  0.6858161242625607\n",
      "Average test loss:  0.690592612065951\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6796164632127343\n",
      "Average test loss:  0.6884026913795759\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.6696190153145111\n",
      "Average test loss:  0.68485465319065\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.653966375064886\n",
      "Average test loss:  0.6792580569194694\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.94375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6309345036120498\n",
      "Average test loss:  0.6709558530833145\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.598993076262492\n",
      "Average test loss:  0.659371716053828\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5583244151895369\n",
      "Average test loss:  0.6446111994885575\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.510532277985857\n",
      "Average test loss:  0.6273789719117889\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.955\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.4585202717218349\n",
      "Average test loss:  0.6088884777869147\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.40620903686580245\n",
      "Average test loss:  0.5908602150315977\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.356711224708051\n",
      "Average test loss:  0.5747033258684325\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.3119099797013527\n",
      "Average test loss:  0.5610023768144287\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2725705049698665\n",
      "Average test loss:  0.5502453478957562\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.23869054945503895\n",
      "Average test loss:  0.5426202883713771\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.20981634604141045\n",
      "Average test loss:  0.5374921522924682\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.18528621487649855\n",
      "Average test loss:  0.5347720946291451\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1644389124612353\n",
      "Average test loss:  0.5338792074238539\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.146666131402761\n",
      "Average test loss:  0.5348327077316362\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.13146001301330087\n",
      "Average test loss:  0.5373499957785218\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.11838218713900062\n",
      "Average test loss:  0.5410288686788337\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1070612458923822\n",
      "Average test loss:  0.5455526096106053\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09722280174569105\n",
      "Average test loss:  0.5509321307571353\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08862477011692077\n",
      "Average test loss:  0.5569626128050368\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.08106005568275841\n",
      "Average test loss:  0.5638196237420695\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07439027683781392\n",
      "Average test loss:  0.5708415721921557\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06846519451494977\n",
      "Average test loss:  0.5788478604783175\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6930369284691963\n",
      "Average test loss:  0.6931110772933748\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6925324962062143\n",
      "Average test loss:  0.6929377018015809\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.929375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.6909471210606455\n",
      "Average test loss:  0.6923846661261398\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.89375\n",
      "Average test accuracy:  0.69875\n",
      "\n",
      "Average train loss:  0.6875260585655746\n",
      "Average test loss:  0.6911933572152603\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6814511492183977\n",
      "Average test loss:  0.6890626460031104\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6714796848680984\n",
      "Average test loss:  0.6855442503856799\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.938125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6558890064467903\n",
      "Average test loss:  0.6800019364668254\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6325978353218327\n",
      "Average test loss:  0.6716850775122762\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.59997448967002\n",
      "Average test loss:  0.659959016021726\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.5576736715113841\n",
      "Average test loss:  0.6447147063455506\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5079727569591254\n",
      "Average test loss:  0.6269148853649393\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.955\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.45470405956056087\n",
      "Average test loss:  0.6081776639591542\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.40172884298359324\n",
      "Average test loss:  0.5899988125525943\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.35218126559449375\n",
      "Average test loss:  0.5737465759089183\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.30769466313170996\n",
      "Average test loss:  0.5602349638428851\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.966875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.26882436654843866\n",
      "Average test loss:  0.5499588150449976\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.2354822170219997\n",
      "Average test loss:  0.5424386802384362\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2071041636719179\n",
      "Average test loss:  0.5375453073901654\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1830231771339238\n",
      "Average test loss:  0.5351651880183966\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1625482780740425\n",
      "Average test loss:  0.5344479588814192\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1450745065655965\n",
      "Average test loss:  0.5353843584310206\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1301095086715979\n",
      "Average test loss:  0.537817155940724\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.11722155901757343\n",
      "Average test loss:  0.5418276177130923\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.1060552795298808\n",
      "Average test loss:  0.5462637943952403\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09634115811848813\n",
      "Average test loss:  0.5519044904627709\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08782791447318061\n",
      "Average test loss:  0.5580427632810703\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.08035190370292196\n",
      "Average test loss:  0.5647163761832056\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07373538819276214\n",
      "Average test loss:  0.5720619869046862\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06786139495857312\n",
      "Average test loss:  0.5799984058731843\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  1\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.0626243745551729\n",
      "Average test loss:  0.587931067783158\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7788961165185567\n",
      "Average test loss:  0.7792437597581422\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7521293142926392\n",
      "Average test loss:  0.7527860514929426\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7329588033959674\n",
      "Average test loss:  0.733838106152707\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7192320599585892\n",
      "Average test loss:  0.7202458766932772\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7093451614041859\n",
      "Average test loss:  0.7104512675072865\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7020174526915349\n",
      "Average test loss:  0.7032672123344068\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6965055902498737\n",
      "Average test loss:  0.698101765269661\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6921574384248331\n",
      "Average test loss:  0.6944990712090484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6882819102263884\n",
      "Average test loss:  0.691977006703781\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.68415240684979\n",
      "Average test loss:  0.6899854461656556\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.92875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.679087534773427\n",
      "Average test loss:  0.688002273587568\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9125\n",
      "Average test accuracy:  0.70625\n",
      "\n",
      "Average train loss:  0.6724403310348771\n",
      "Average test loss:  0.6856057918561232\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.889375\n",
      "Average test accuracy:  0.66625\n",
      "\n",
      "Average train loss:  0.6634474776242041\n",
      "Average test loss:  0.6823901117645205\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.89875\n",
      "Average test accuracy:  0.67\n",
      "\n",
      "Average train loss:  0.6512990984772872\n",
      "Average test loss:  0.6779862446320614\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.914375\n",
      "Average test accuracy:  0.68875\n",
      "\n",
      "Average train loss:  0.6352650737716753\n",
      "Average test loss:  0.672101132181499\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.928125\n",
      "Average test accuracy:  0.70625\n",
      "\n",
      "Average train loss:  0.6149960673258129\n",
      "Average test loss:  0.6645623125287562\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.94125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.5904491148271646\n",
      "Average test loss:  0.6553128848826386\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.5621955103888115\n",
      "Average test loss:  0.6445679109181522\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.5312884724365005\n",
      "Average test loss:  0.6327359194236751\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.4989673968032726\n",
      "Average test loss:  0.6203725534515917\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.76\n",
      "\n",
      "Average train loss:  0.4663963309057997\n",
      "Average test loss:  0.608082801565245\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.966875\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.4344596766479147\n",
      "Average test loss:  0.5961387769747506\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.4038934549325061\n",
      "Average test loss:  0.5849316486746331\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3750589802217883\n",
      "Average test loss:  0.5746457684577821\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.34818214573652156\n",
      "Average test loss:  0.5654556779972681\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.32332842665643496\n",
      "Average test loss:  0.5575058806918888\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.30046798704918315\n",
      "Average test loss:  0.5506223509898452\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.27949118628084896\n",
      "Average test loss:  0.5447255458078113\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.26028104938083735\n",
      "Average test loss:  0.5400106121371638\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2427042791201696\n",
      "Average test loss:  0.5361494240058431\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7437614764037438\n",
      "Average test loss:  0.7443730138488481\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7168074957276623\n",
      "Average test loss:  0.7180312509393275\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7017100413505245\n",
      "Average test loss:  0.7035534951257792\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6938158043281035\n",
      "Average test loss:  0.696350996229798\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6895869098517645\n",
      "Average test loss:  0.6929651738743624\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6868232206386855\n",
      "Average test loss:  0.691295973002947\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.503125\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6841994231909375\n",
      "Average test loss:  0.6901269738737511\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.8375\n",
      "Average test accuracy:  0.555\n",
      "\n",
      "Average train loss:  0.6810366107074716\n",
      "Average test loss:  0.6889048022271494\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9175\n",
      "Average test accuracy:  0.67375\n",
      "\n",
      "Average train loss:  0.6769173742497596\n",
      "Average test loss:  0.6873973673831285\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.715\n",
      "\n",
      "Average train loss:  0.6714161355681205\n",
      "Average test loss:  0.685387981346253\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.6640474300745657\n",
      "Average test loss:  0.6826886057245719\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.6542612932949078\n",
      "Average test loss:  0.6790845839466932\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6414692051505043\n",
      "Average test loss:  0.6743471926975152\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.6251391011095233\n",
      "Average test loss:  0.6682513888495144\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.6050307995566055\n",
      "Average test loss:  0.6607185735692426\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.5811619351156173\n",
      "Average test loss:  0.6517178224419076\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.5538928275211267\n",
      "Average test loss:  0.6414859375931338\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.5237837951181072\n",
      "Average test loss:  0.6302187324051207\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.4914850648445466\n",
      "Average test loss:  0.6181618981037723\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.4577612264499697\n",
      "Average test loss:  0.6058526453868831\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.4235691342279462\n",
      "Average test loss:  0.5936989527618861\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.38976942840413287\n",
      "Average test loss:  0.5820838124270532\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3571064674200591\n",
      "Average test loss:  0.5714040175634446\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.32624770150496546\n",
      "Average test loss:  0.5618827073652305\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.2975763432992545\n",
      "Average test loss:  0.5537124104478836\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2713491465134715\n",
      "Average test loss:  0.5470613001775827\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.24757754828001466\n",
      "Average test loss:  0.541764493824909\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.22617601058496617\n",
      "Average test loss:  0.5380077763778655\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.20698075145899322\n",
      "Average test loss:  0.5353970551740058\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1897945045414361\n",
      "Average test loss:  0.5341276808805666\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.916875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.6922817250022589\n",
      "Average test loss:  0.6928471358560424\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.81375\n",
      "Average test accuracy:  0.58375\n",
      "\n",
      "Average train loss:  0.6910137372232507\n",
      "Average test loss:  0.6924131052023011\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.77875\n",
      "Average test accuracy:  0.55125\n",
      "\n",
      "Average train loss:  0.6888954916318727\n",
      "Average test loss:  0.6916919979691123\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.75625\n",
      "Average test accuracy:  0.5425\n",
      "\n",
      "Average train loss:  0.6853505963076393\n",
      "Average test loss:  0.6904932801693012\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.805625\n",
      "Average test accuracy:  0.56\n",
      "\n",
      "Average train loss:  0.6797081032289837\n",
      "Average test loss:  0.6885764903941792\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.854375\n",
      "Average test accuracy:  0.59375\n",
      "\n",
      "Average train loss:  0.6708752738482241\n",
      "Average test loss:  0.6855601932179357\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.88\n",
      "Average test accuracy:  0.62125\n",
      "\n",
      "Average train loss:  0.6569185843059602\n",
      "Average test loss:  0.6807900026152858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.895\n",
      "Average test accuracy:  0.66375\n",
      "\n",
      "Average train loss:  0.6352934024808912\n",
      "Average test loss:  0.6734106330382971\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.916875\n",
      "Average test accuracy:  0.6975\n",
      "\n",
      "Average train loss:  0.604293340404834\n",
      "Average test loss:  0.662706317637423\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.7075\n",
      "\n",
      "Average train loss:  0.564189964662581\n",
      "Average test loss:  0.6487841455908118\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.94125\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.5177953342016209\n",
      "Average test loss:  0.6327100099912206\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.4689371576411358\n",
      "Average test loss:  0.6158534556694361\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.4210821315838653\n",
      "Average test loss:  0.5997027486077594\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.376362037014796\n",
      "Average test loss:  0.5852028926728763\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.3358340963043775\n",
      "Average test loss:  0.5729611092706771\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.29972138479208216\n",
      "Average test loss:  0.5623977672711454\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.2679208247116415\n",
      "Average test loss:  0.554379430965365\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.24009534174836222\n",
      "Average test loss:  0.5482062993740039\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.21579199344060748\n",
      "Average test loss:  0.5440908931052074\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.19456394110602984\n",
      "Average test loss:  0.5414819452960428\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1759928585942989\n",
      "Average test loss:  0.5401968030554025\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.15971037065064925\n",
      "Average test loss:  0.5402886142177026\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1453794104117636\n",
      "Average test loss:  0.5416539700203254\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.13273194570196198\n",
      "Average test loss:  0.5439692599502036\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.12152242188523694\n",
      "Average test loss:  0.5469923352641252\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.11155939417031313\n",
      "Average test loss:  0.5509228769992933\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.1026748936248572\n",
      "Average test loss:  0.555559611197146\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09472019530301158\n",
      "Average test loss:  0.5606222026370726\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.08758249716186232\n",
      "Average test loss:  0.5661974064416803\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.08115531146854328\n",
      "Average test loss:  0.5722382986303655\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.916875\n",
      "Average test accuracy:  0.6925\n",
      "\n",
      "Average train loss:  0.6924046889276657\n",
      "Average test loss:  0.692885977764683\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.6775\n",
      "Average test accuracy:  0.5575\n",
      "\n",
      "Average train loss:  0.6908881291910388\n",
      "Average test loss:  0.6923648632040376\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.88625\n",
      "Average test accuracy:  0.69125\n",
      "\n",
      "Average train loss:  0.6876006639932943\n",
      "Average test loss:  0.6912275464931845\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.8825\n",
      "Average test accuracy:  0.685\n",
      "\n",
      "Average train loss:  0.6816404154009112\n",
      "Average test loss:  0.6891623845236231\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.89\n",
      "Average test accuracy:  0.69\n",
      "\n",
      "Average train loss:  0.6719819244894915\n",
      "Average test loss:  0.6857896927304016\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.908125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.6572038093692164\n",
      "Average test loss:  0.6805844588005749\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.6358299391705545\n",
      "Average test loss:  0.6730018314821112\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.606554335959384\n",
      "Average test loss:  0.6625045316556387\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.940625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.569170743075241\n",
      "Average test loss:  0.649004658465442\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5255692589843916\n",
      "Average test loss:  0.6332169331313201\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.4789304283829423\n",
      "Average test loss:  0.6163487945496685\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.4322644423384121\n",
      "Average test loss:  0.5997366732844651\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.3877766946131705\n",
      "Average test loss:  0.5841425871521856\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.3468415147548174\n",
      "Average test loss:  0.5705285656595946\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.3100434976207121\n",
      "Average test loss:  0.5589925061544911\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.27737477456001347\n",
      "Average test loss:  0.5495853726765535\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.24857068374411773\n",
      "Average test loss:  0.5421856832637265\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.22325696677051435\n",
      "Average test loss:  0.536762179073408\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.20100948495449975\n",
      "Average test loss:  0.5331783160829424\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1814359837404517\n",
      "Average test loss:  0.5310989844897138\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.16415019743258244\n",
      "Average test loss:  0.5303092178435387\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.14886584300680825\n",
      "Average test loss:  0.5310373401838522\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.13531676250844413\n",
      "Average test loss:  0.5327161826487979\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.12326082219064939\n",
      "Average test loss:  0.5355528702933022\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.11253987801018084\n",
      "Average test loss:  0.5391492123466478\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.10296945526346213\n",
      "Average test loss:  0.5436191167656058\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.09442928004068964\n",
      "Average test loss:  0.5489108319249096\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.086788895339358\n",
      "Average test loss:  0.5548038471880751\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.07993691453435427\n",
      "Average test loss:  0.5612203145464508\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.07377567842875436\n",
      "Average test loss:  0.5680823958925448\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6923522299652065\n",
      "Average test loss:  0.6929335953529759\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.853125\n",
      "Average test accuracy:  0.65875\n",
      "\n",
      "Average train loss:  0.6908792480518442\n",
      "Average test loss:  0.692364597399727\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.90875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.6884168109352539\n",
      "Average test loss:  0.6915118411937256\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.861875\n",
      "Average test accuracy:  0.66\n",
      "\n",
      "Average train loss:  0.6840398216169555\n",
      "Average test loss:  0.6899952842143112\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.835\n",
      "Average test accuracy:  0.65\n",
      "\n",
      "Average train loss:  0.6764077555189111\n",
      "Average test loss:  0.6873516664117654\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.885\n",
      "Average test accuracy:  0.68125\n",
      "\n",
      "Average train loss:  0.6635401909786985\n",
      "Average test loss:  0.6828409834746361\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.90875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.6423634505050989\n",
      "Average test loss:  0.675344902942354\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.6098691835205204\n",
      "Average test loss:  0.663747425822757\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.5653547819219032\n",
      "Average test loss:  0.6477425824414996\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9475\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.5117082513450368\n",
      "Average test loss:  0.6284470082036612\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.4539348562585783\n",
      "Average test loss:  0.6078809840620365\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3974380287585045\n",
      "Average test loss:  0.5882920340454747\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3458231935996907\n",
      "Average test loss:  0.5713126809370576\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.3006142419672271\n",
      "Average test loss:  0.5576209285772478\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.26188304633254456\n",
      "Average test loss:  0.5472193571841989\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.22905130744810234\n",
      "Average test loss:  0.5398095391120646\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.20131073001768787\n",
      "Average test loss:  0.5352773578077292\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.17786747223210211\n",
      "Average test loss:  0.532879874413591\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.15797981286173915\n",
      "Average test loss:  0.5324990863053721\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.14100627237806015\n",
      "Average test loss:  0.5338175954280749\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.1264683937296285\n",
      "Average test loss:  0.5363780629507007\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.11391982659476696\n",
      "Average test loss:  0.5404977054927506\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.1030446275651189\n",
      "Average test loss:  0.5452621376677417\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.09356234814746293\n",
      "Average test loss:  0.551038229789708\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0852488792829122\n",
      "Average test loss:  0.5575662620449839\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07793026059878523\n",
      "Average test loss:  0.5645999142145969\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.07145390553962408\n",
      "Average test loss:  0.5722357146463305\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.06569453026196931\n",
      "Average test loss:  0.5802846217263785\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.060554428706590446\n",
      "Average test loss:  0.5886883562672193\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.055951446352681254\n",
      "Average test loss:  0.5972621052519062\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.528125\n",
      "Average test accuracy:  0.50125\n",
      "\n",
      "Average train loss:  0.6927891109908088\n",
      "Average test loss:  0.6930214311155126\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.619375\n",
      "Average test accuracy:  0.50375\n",
      "\n",
      "Average train loss:  0.6920537257661908\n",
      "Average test loss:  0.6927676328031923\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.88625\n",
      "Average test accuracy:  0.66125\n",
      "\n",
      "Average train loss:  0.6902976763336929\n",
      "Average test loss:  0.692158457235858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.8725\n",
      "Average test accuracy:  0.615\n",
      "\n",
      "Average train loss:  0.6865533363315138\n",
      "Average test loss:  0.6908652986223579\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.901875\n",
      "Average test accuracy:  0.68125\n",
      "\n",
      "Average train loss:  0.6791219687311764\n",
      "Average test loss:  0.6882812414089039\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.92125\n",
      "Average test accuracy:  0.7025\n",
      "\n",
      "Average train loss:  0.6653205828835779\n",
      "Average test loss:  0.6834661556570522\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.70875\n",
      "\n",
      "Average train loss:  0.641535755620378\n",
      "Average test loss:  0.6751548022569099\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.71125\n",
      "\n",
      "Average train loss:  0.6052339174579131\n",
      "Average test loss:  0.6624141703938612\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.5575946183672851\n",
      "Average test loss:  0.6456768739507291\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5017968161227148\n",
      "Average test loss:  0.6259874441631971\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.4433440108035051\n",
      "Average test loss:  0.6058664419769487\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.3868125508989447\n",
      "Average test loss:  0.5871939185056426\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.7575\n",
      "\n",
      "Average train loss:  0.3352531255360736\n",
      "Average test loss:  0.5708495340679928\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.290105335683057\n",
      "Average test loss:  0.5580705036940844\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.251519201995095\n",
      "Average test loss:  0.5487986773851482\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2189432202074939\n",
      "Average test loss:  0.5425103916545986\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.19157856783235025\n",
      "Average test loss:  0.5388573543465355\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.16856497756966984\n",
      "Average test loss:  0.5375007671154864\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1491237570634786\n",
      "Average test loss:  0.5382435440766196\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.9825\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.132654430481851\n",
      "Average test loss:  0.5407500802092707\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.11859854845063582\n",
      "Average test loss:  0.5446074204259396\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.10654167151701778\n",
      "Average test loss:  0.5492807053644196\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09612298406197838\n",
      "Average test loss:  0.5551373918762248\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.08708393016560222\n",
      "Average test loss:  0.5618760310641057\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07919108888386472\n",
      "Average test loss:  0.5691817995057047\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07226317204613715\n",
      "Average test loss:  0.5771264407138476\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.06616497472182305\n",
      "Average test loss:  0.5857297864749248\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06076473515256046\n",
      "Average test loss:  0.5941120191446867\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.05596390405715542\n",
      "Average test loss:  0.6033242907934026\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.05168883697646331\n",
      "Average test loss:  0.6124225430088641\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7308634594537943\n",
      "Average test loss:  0.7313004233078257\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7004767884512991\n",
      "Average test loss:  0.7013527078948606\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6921298022046095\n",
      "Average test loss:  0.6935976882344764\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6896129258894644\n",
      "Average test loss:  0.6919528700678678\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.793125\n",
      "Average test accuracy:  0.59375\n",
      "\n",
      "Average train loss:  0.6873954814951376\n",
      "Average test loss:  0.69109632149636\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.929375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.6838742871612994\n",
      "Average test loss:  0.689864176510392\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6778706095128619\n",
      "Average test loss:  0.6877622371836782\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.6679402638855964\n",
      "Average test loss:  0.6842594236555527\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.6521301121446194\n",
      "Average test loss:  0.678620021870218\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.6279431534952682\n",
      "Average test loss:  0.6698951756540389\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.5927990764998826\n",
      "Average test loss:  0.6571688735373936\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.5459433737751646\n",
      "Average test loss:  0.6400567198776551\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.49015923261121513\n",
      "Average test loss:  0.6198240357580106\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.4307588380917798\n",
      "Average test loss:  0.5987679501058846\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3732460028516498\n",
      "Average test loss:  0.5788869669263783\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.32126972802357173\n",
      "Average test loss:  0.5623883300627109\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.27631025079022026\n",
      "Average test loss:  0.5494794379095903\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2384019842402064\n",
      "Average test loss:  0.540496213188472\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.20677065775640321\n",
      "Average test loss:  0.5346839799002557\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1804367188545942\n",
      "Average test loss:  0.5320050065078581\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.15847859413981868\n",
      "Average test loss:  0.5316853796927771\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1400511358075259\n",
      "Average test loss:  0.5332597417759256\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.12449880855216892\n",
      "Average test loss:  0.536565561579243\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.11128543396356244\n",
      "Average test loss:  0.5410737954721291\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.099987904473213\n",
      "Average test loss:  0.5469786506655973\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.09024975288353554\n",
      "Average test loss:  0.5534103168680917\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.0818152497323013\n",
      "Average test loss:  0.5608185624373913\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07445131635485433\n",
      "Average test loss:  0.5687965919531592\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.06799794303909129\n",
      "Average test loss:  0.5773018457270308\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.06230671655037717\n",
      "Average test loss:  0.5860714943331847\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.92125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.6920682610200773\n",
      "Average test loss:  0.6927677462092086\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.863125\n",
      "Average test accuracy:  0.6225\n",
      "\n",
      "Average train loss:  0.690290641193723\n",
      "Average test loss:  0.6921571115917574\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.92\n",
      "Average test accuracy:  0.70375\n",
      "\n",
      "Average train loss:  0.6868481262554247\n",
      "Average test loss:  0.6909738538428671\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.7125\n",
      "\n",
      "Average train loss:  0.6804716084097291\n",
      "Average test loss:  0.688777347382663\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.931875\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.6693670145897036\n",
      "Average test loss:  0.6849517634497633\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.6510856679517119\n",
      "Average test loss:  0.6786176649673074\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.622973687707681\n",
      "Average test loss:  0.6687707736172404\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.5834548210887268\n",
      "Average test loss:  0.6548996446157788\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5334403220611893\n",
      "Average test loss:  0.637370887419185\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.47606689812071773\n",
      "Average test loss:  0.6173220602328672\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.41635865226252555\n",
      "Average test loss:  0.596966692906388\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.958125\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3592571982294445\n",
      "Average test loss:  0.578588744555339\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3079966569414639\n",
      "Average test loss:  0.5630107817998217\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.2637413010957936\n",
      "Average test loss:  0.5513403413916558\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.22651893773922094\n",
      "Average test loss:  0.5434110109398956\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.19559255237153253\n",
      "Average test loss:  0.5386576638611799\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.16992328110439295\n",
      "Average test loss:  0.5368757636208253\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.14859731984306757\n",
      "Average test loss:  0.5374141594019574\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.13078193821206563\n",
      "Average test loss:  0.5395142673246439\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.11580461563654026\n",
      "Average test loss:  0.5438905530511633\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10312244157713184\n",
      "Average test loss:  0.5489828487198446\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.09230279492593153\n",
      "Average test loss:  0.5554084946687071\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08301473269534451\n",
      "Average test loss:  0.5630075457815394\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07499868216442145\n",
      "Average test loss:  0.5708817249141419\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.06802550448277865\n",
      "Average test loss:  0.5796478431721713\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.06194403980670352\n",
      "Average test loss:  0.5890110909616514\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.05659597834221159\n",
      "Average test loss:  0.5986292805133989\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.05187737106761825\n",
      "Average test loss:  0.6083719030562347\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.04769687718210344\n",
      "Average test loss:  0.6186801146704295\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.04397439999605429\n",
      "Average test loss:  0.6292389888122791\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6926604754171723\n",
      "Average test loss:  0.6930500985475887\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.805\n",
      "Average test accuracy:  0.64\n",
      "\n",
      "Average train loss:  0.691398396535393\n",
      "Average test loss:  0.6925428707866099\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.93375\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.6884324193758719\n",
      "Average test loss:  0.6915152029127564\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6819241598312842\n",
      "Average test loss:  0.6892529216046831\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6699078793581292\n",
      "Average test loss:  0.6850640109287509\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.6494854530555093\n",
      "Average test loss:  0.677937497839801\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.616908155488254\n",
      "Average test loss:  0.6665098573316502\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.5701121975319285\n",
      "Average test loss:  0.6500019724251566\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5106885587795854\n",
      "Average test loss:  0.629282392250326\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.44441274426948096\n",
      "Average test loss:  0.6067239249951492\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.3788468872661957\n",
      "Average test loss:  0.5851280030341992\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.31975782903878686\n",
      "Average test loss:  0.5670697075201794\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.2696196728528657\n",
      "Average test loss:  0.5541152738119006\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.22836417648171872\n",
      "Average test loss:  0.5454035079776741\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1948343166971629\n",
      "Average test loss:  0.5403376064117865\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.16758698293817845\n",
      "Average test loss:  0.5388790997379416\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1453641547392817\n",
      "Average test loss:  0.539954872171937\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.12706604607393268\n",
      "Average test loss:  0.5433368197585813\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1118774455815875\n",
      "Average test loss:  0.5484492070079358\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.09915862804107252\n",
      "Average test loss:  0.5544310881865466\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08841082044022018\n",
      "Average test loss:  0.5619386652171304\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.07926652209864658\n",
      "Average test loss:  0.5704922669000628\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.0714079434268625\n",
      "Average test loss:  0.5792739079441823\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.06461941007552462\n",
      "Average test loss:  0.5887871041905028\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.058717931883099074\n",
      "Average test loss:  0.599298399086748\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.053554646002374695\n",
      "Average test loss:  0.6093349261434214\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04902174013497748\n",
      "Average test loss:  0.6204662839957167\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.045016524845078516\n",
      "Average test loss:  0.6312288850052304\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.041458721988131275\n",
      "Average test loss:  0.6423977239420698\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.038286989988193965\n",
      "Average test loss:  0.6537930399906527\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7004326236095583\n",
      "Average test loss:  0.7007251271443365\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6924834247542414\n",
      "Average test loss:  0.6931272734253925\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.55\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6912258896908718\n",
      "Average test loss:  0.6924911577649047\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.89625\n",
      "Average test accuracy:  0.62375\n",
      "\n",
      "Average train loss:  0.6893419124578264\n",
      "Average test loss:  0.6918295895396932\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.916875\n",
      "Average test accuracy:  0.695\n",
      "\n",
      "Average train loss:  0.6857123471928926\n",
      "Average test loss:  0.6905592735137969\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.923125\n",
      "Average test accuracy:  0.70625\n",
      "\n",
      "Average train loss:  0.6791213856701805\n",
      "Average test loss:  0.6882486910349046\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.916875\n",
      "Average test accuracy:  0.7\n",
      "\n",
      "Average train loss:  0.6677723873914657\n",
      "Average test loss:  0.6842791413385715\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.70875\n",
      "\n",
      "Average train loss:  0.6488452982610827\n",
      "Average test loss:  0.677605792224274\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.6181585400891328\n",
      "Average test loss:  0.6666805749186406\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.571595031619014\n",
      "Average test loss:  0.650239300158613\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.5091548951099346\n",
      "Average test loss:  0.628183590242444\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.4379252649345699\n",
      "Average test loss:  0.603700484818559\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.3680883611453148\n",
      "Average test loss:  0.5807915801910427\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.30661924808187385\n",
      "Average test loss:  0.56270334478826\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.25589333166723915\n",
      "Average test loss:  0.5495909507483407\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.21522830484591912\n",
      "Average test loss:  0.5420937031201573\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.18283614731237155\n",
      "Average test loss:  0.5384469428012172\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.15691443529679028\n",
      "Average test loss:  0.5384537347787198\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.13595970148548528\n",
      "Average test loss:  0.5409296729862423\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.11886595709818236\n",
      "Average test loss:  0.5457547488710869\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1047373062087899\n",
      "Average test loss:  0.5517158899020932\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.09294473481647121\n",
      "Average test loss:  0.5590081153152253\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08300894003400423\n",
      "Average test loss:  0.5670219666735128\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07455489808968048\n",
      "Average test loss:  0.5763599814868406\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06729400106893298\n",
      "Average test loss:  0.5860394422782226\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.06103374423025007\n",
      "Average test loss:  0.5959858074417519\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.0555841605723589\n",
      "Average test loss:  0.6066338246799884\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.05081798093285642\n",
      "Average test loss:  0.6175368111096746\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.04663507796116767\n",
      "Average test loss:  0.628483034222994\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  2\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.042937737598607\n",
      "Average test loss:  0.6395075857175109\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7059416207266623\n",
      "Average test loss:  0.7067622210128094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6948718065692082\n",
      "Average test loss:  0.6966000699192271\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6897345389688004\n",
      "Average test loss:  0.6926266820242963\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6862713292361197\n",
      "Average test loss:  0.6908443460955268\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.7025\n",
      "Average test accuracy:  0.5575\n",
      "\n",
      "Average train loss:  0.6821753038271986\n",
      "Average test loss:  0.6893092430088551\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.890625\n",
      "Average test accuracy:  0.69\n",
      "\n",
      "Average train loss:  0.6760642401505977\n",
      "Average test loss:  0.6871525665147687\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.918125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.6666811854438954\n",
      "Average test loss:  0.6838595007251179\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.9325\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.652643021806371\n",
      "Average test loss:  0.6788728874203148\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.6326908024839981\n",
      "Average test loss:  0.6716925224605544\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.945625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6062812900030862\n",
      "Average test loss:  0.6620463997769053\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5739925648451765\n",
      "Average test loss:  0.6501291275532424\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.5375150295041659\n",
      "Average test loss:  0.6365764537422842\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.955\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.49899848751377857\n",
      "Average test loss:  0.6222391631949911\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.4604642993626513\n",
      "Average test loss:  0.6080931551565221\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.4233865681016713\n",
      "Average test loss:  0.5946402246107672\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.966875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.38868356006213395\n",
      "Average test loss:  0.5823106517449058\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.356752735287931\n",
      "Average test loss:  0.5714140975797617\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.32770517958333506\n",
      "Average test loss:  0.5620462317899885\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3014114251537196\n",
      "Average test loss:  0.5541238592752205\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.27768300341384106\n",
      "Average test loss:  0.5474866348097615\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.2562984356948505\n",
      "Average test loss:  0.5421943100026487\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.23701847425219535\n",
      "Average test loss:  0.5381096645850728\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.9825\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.21961983761687023\n",
      "Average test loss:  0.5351388939860837\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.20390355753697306\n",
      "Average test loss:  0.5331203108399595\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.18967089404696488\n",
      "Average test loss:  0.5320063261674451\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.17675332759158344\n",
      "Average test loss:  0.5316028196800028\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.16500499768005947\n",
      "Average test loss:  0.5320013339851847\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.15429868698958593\n",
      "Average test loss:  0.5331338775579202\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.14451435815057517\n",
      "Average test loss:  0.5347604942754319\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.13556137777864072\n",
      "Average test loss:  0.5369161382896946\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7546487018803093\n",
      "Average test loss:  0.7549807926604489\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7256978283039343\n",
      "Average test loss:  0.7260915157412354\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7083654003844663\n",
      "Average test loss:  0.7087197826715218\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6989265065180247\n",
      "Average test loss:  0.6993828703187326\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6939703743647416\n",
      "Average test loss:  0.6949406922349572\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6905063276376624\n",
      "Average test loss:  0.6926878152178526\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6863260805326997\n",
      "Average test loss:  0.6908580852158382\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.903125\n",
      "Average test accuracy:  0.65625\n",
      "\n",
      "Average train loss:  0.6797081837247981\n",
      "Average test loss:  0.6883736046117007\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.6691701147644021\n",
      "Average test loss:  0.6845348233977688\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.6532362557512424\n",
      "Average test loss:  0.6787212307141867\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.929375\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.6306928721247543\n",
      "Average test loss:  0.6704203747600186\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.940625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.6009573473347629\n",
      "Average test loss:  0.6593043676407261\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.56473882154102\n",
      "Average test loss:  0.6455687963223654\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.955\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5238501482498841\n",
      "Average test loss:  0.6299422552611587\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.48072168335103244\n",
      "Average test loss:  0.6134788892985056\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.43767936954603676\n",
      "Average test loss:  0.5972639876942311\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3965256651028252\n",
      "Average test loss:  0.582130974392903\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.35834919262630077\n",
      "Average test loss:  0.5687328588045442\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.32366343610015086\n",
      "Average test loss:  0.5572871636219335\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.29258584920501934\n",
      "Average test loss:  0.547957488490717\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2649519762676227\n",
      "Average test loss:  0.5405250510494807\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.240476157317651\n",
      "Average test loss:  0.5350175469185618\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.21883041056611263\n",
      "Average test loss:  0.5311456215756571\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.19966273973812454\n",
      "Average test loss:  0.5287816206529214\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.18269473517248033\n",
      "Average test loss:  0.5277206826292784\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.16761560889698654\n",
      "Average test loss:  0.5278195648403142\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.15419947813744847\n",
      "Average test loss:  0.5290315840197093\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.1422227515330874\n",
      "Average test loss:  0.5310154756172465\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.131498911855338\n",
      "Average test loss:  0.5338264900355397\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.12185719921710614\n",
      "Average test loss:  0.5373078104216306\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7048522839283166\n",
      "Average test loss:  0.7050999175389924\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6952865832974543\n",
      "Average test loss:  0.6956541995155052\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6924135165947337\n",
      "Average test loss:  0.6931441629087893\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6909438485863536\n",
      "Average test loss:  0.6923871213132644\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.918125\n",
      "Average test accuracy:  0.70875\n",
      "\n",
      "Average train loss:  0.6891285520789493\n",
      "Average test loss:  0.6917393853977077\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.784375\n",
      "Average test accuracy:  0.5625\n",
      "\n",
      "Average train loss:  0.6861772631136618\n",
      "Average test loss:  0.6907288180003593\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.81625\n",
      "Average test accuracy:  0.5775\n",
      "\n",
      "Average train loss:  0.681115488749325\n",
      "Average test loss:  0.6889844917785687\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.88\n",
      "Average test accuracy:  0.63\n",
      "\n",
      "Average train loss:  0.6719669454619561\n",
      "Average test loss:  0.6858040264030124\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.90625\n",
      "Average test accuracy:  0.68875\n",
      "\n",
      "Average train loss:  0.6552501559427486\n",
      "Average test loss:  0.6799411977207535\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.6262342105661133\n",
      "Average test loss:  0.669566762679306\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.94375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.5817987607850582\n",
      "Average test loss:  0.6535313160012826\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5250152429016534\n",
      "Average test loss:  0.632891254022247\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.955\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.4636380415384636\n",
      "Average test loss:  0.6107794921104938\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.4045693468806844\n",
      "Average test loss:  0.5899547040123388\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3516592391221755\n",
      "Average test loss:  0.5721629410187689\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3060734564397008\n",
      "Average test loss:  0.5581603555474728\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.26749145127355417\n",
      "Average test loss:  0.5477033980624674\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.23501062712580922\n",
      "Average test loss:  0.5401963706936904\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.2076430811665665\n",
      "Average test loss:  0.5355825635572837\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.18450809711552574\n",
      "Average test loss:  0.5332405788739364\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.16482188220875402\n",
      "Average test loss:  0.5329258321200232\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.14798022657229393\n",
      "Average test loss:  0.5339117682100475\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.13347753574893176\n",
      "Average test loss:  0.5365644079174089\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.12089888593382236\n",
      "Average test loss:  0.5401385786622828\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.1099271009291382\n",
      "Average test loss:  0.544675011039204\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.10031000178346143\n",
      "Average test loss:  0.5502036955785187\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0918401690792197\n",
      "Average test loss:  0.5562207281428084\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.08434138350082408\n",
      "Average test loss:  0.5629819372890857\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0776777591107889\n",
      "Average test loss:  0.5699959642290054\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07173030009937237\n",
      "Average test loss:  0.5775898371250622\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7118447194401526\n",
      "Average test loss:  0.7126390159810759\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6936837847065207\n",
      "Average test loss:  0.6958939886383738\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.687096368174693\n",
      "Average test loss:  0.6912238037416786\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.925625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.682799461710656\n",
      "Average test loss:  0.689461163062214\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.8875\n",
      "Average test accuracy:  0.6875\n",
      "\n",
      "Average train loss:  0.6775147327010308\n",
      "Average test loss:  0.6876682421610024\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.885\n",
      "Average test accuracy:  0.665\n",
      "\n",
      "Average train loss:  0.6698813981136066\n",
      "Average test loss:  0.6850808620636538\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.903125\n",
      "Average test accuracy:  0.6925\n",
      "\n",
      "Average train loss:  0.6586110599287012\n",
      "Average test loss:  0.6811980980801161\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.921875\n",
      "Average test accuracy:  0.70375\n",
      "\n",
      "Average train loss:  0.6419613370867826\n",
      "Average test loss:  0.6754240827670092\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9325\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.6181069636283115\n",
      "Average test loss:  0.667035535074756\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.940625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.5856029815955036\n",
      "Average test loss:  0.6554318426314815\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.5445114455398716\n",
      "Average test loss:  0.6407466203770573\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.4969366490064326\n",
      "Average test loss:  0.6236818581974036\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.4463006090668407\n",
      "Average test loss:  0.6056392325671026\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.39615498649572906\n",
      "Average test loss:  0.588234385675552\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.3492310099392793\n",
      "Average test loss:  0.5725793771020009\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3070074081943446\n",
      "Average test loss:  0.5594888903576835\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.26998443808514666\n",
      "Average test loss:  0.5490982314034647\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.23795500227039276\n",
      "Average test loss:  0.5414667305852392\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.21045632128906752\n",
      "Average test loss:  0.5364335260728347\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.18692007471712177\n",
      "Average test loss:  0.5333368825297201\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.166712929166459\n",
      "Average test loss:  0.5322786144008594\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.14934334751389242\n",
      "Average test loss:  0.5329122473228779\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.13432859533974809\n",
      "Average test loss:  0.5348788363122222\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.12131010618519233\n",
      "Average test loss:  0.5380336880469923\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.10996198793045747\n",
      "Average test loss:  0.5421080944046484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.1000198908481143\n",
      "Average test loss:  0.547143307249927\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.09128138326125251\n",
      "Average test loss:  0.5529578572978372\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.08355507542766875\n",
      "Average test loss:  0.5593248229308583\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.07670368376658376\n",
      "Average test loss:  0.5662704948455999\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07060132272645599\n",
      "Average test loss:  0.5736804481371368\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7048233482501418\n",
      "Average test loss:  0.7051214753969552\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6927001112203265\n",
      "Average test loss:  0.6938448009321797\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.509375\n",
      "Average test accuracy:  0.5025\n",
      "\n",
      "Average train loss:  0.6892893426890256\n",
      "Average test loss:  0.6917947425030242\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.82625\n",
      "Average test accuracy:  0.5975\n",
      "\n",
      "Average train loss:  0.6861299127897212\n",
      "Average test loss:  0.6906955743647885\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.855\n",
      "Average test accuracy:  0.62\n",
      "\n",
      "Average train loss:  0.6812380559476926\n",
      "Average test loss:  0.6890195386754462\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.8775\n",
      "Average test accuracy:  0.6375\n",
      "\n",
      "Average train loss:  0.6735407858508412\n",
      "Average test loss:  0.6863796371963028\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.89875\n",
      "Average test accuracy:  0.675\n",
      "\n",
      "Average train loss:  0.6614422220171039\n",
      "Average test loss:  0.6821886239375289\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.9125\n",
      "Average test accuracy:  0.69375\n",
      "\n",
      "Average train loss:  0.6424352439455752\n",
      "Average test loss:  0.6756013717646675\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.931875\n",
      "Average test accuracy:  0.71375\n",
      "\n",
      "Average train loss:  0.6137710488584808\n",
      "Average test loss:  0.6654634007044805\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.5736534591543191\n",
      "Average test loss:  0.6513103342766097\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5232618597968869\n",
      "Average test loss:  0.6333920844173666\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.4668559257223924\n",
      "Average test loss:  0.6134765996729451\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.40961980551940463\n",
      "Average test loss:  0.5937298751252953\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.3559063659973308\n",
      "Average test loss:  0.5759755396382887\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3081289907200581\n",
      "Average test loss:  0.5615857123028523\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2669538577562551\n",
      "Average test loss:  0.5501638776905754\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.23207061732011647\n",
      "Average test loss:  0.5423981975778234\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2027792791298317\n",
      "Average test loss:  0.537598918902645\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.17814492264550388\n",
      "Average test loss:  0.5351616414762668\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.15737025625119483\n",
      "Average test loss:  0.5350435001466579\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.1397845560563491\n",
      "Average test loss:  0.5366316591477815\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.12481269265120909\n",
      "Average test loss:  0.5398074849302914\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.111987988593242\n",
      "Average test loss:  0.5442958960807897\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.1009306114710305\n",
      "Average test loss:  0.5493928193220932\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.09133791383481338\n",
      "Average test loss:  0.5557049859458875\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.08297849956727706\n",
      "Average test loss:  0.5626380289548771\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07564227244984088\n",
      "Average test loss:  0.5702555724954267\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.06918801815863362\n",
      "Average test loss:  0.5782562024104229\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06346984133912315\n",
      "Average test loss:  0.5867817843630284\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.058395231466275066\n",
      "Average test loss:  0.5956062758828683\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6927279093935952\n",
      "Average test loss:  0.693013099838625\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.581875\n",
      "Average test accuracy:  0.5025\n",
      "\n",
      "Average train loss:  0.6918444331355359\n",
      "Average test loss:  0.6927037712801587\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.635625\n",
      "Average test accuracy:  0.505\n",
      "\n",
      "Average train loss:  0.6895952690198136\n",
      "Average test loss:  0.691936341987449\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.7475\n",
      "Average test accuracy:  0.52875\n",
      "\n",
      "Average train loss:  0.6846042986226633\n",
      "Average test loss:  0.6902383105660173\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.913125\n",
      "Average test accuracy:  0.6975\n",
      "\n",
      "Average train loss:  0.6750418239510919\n",
      "Average test loss:  0.6869046243634968\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9325\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.6583151125099214\n",
      "Average test loss:  0.6810743131595093\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.6307992216029333\n",
      "Average test loss:  0.6714321869468503\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5895928279779388\n",
      "Average test loss:  0.6568546076055775\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.945625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.5350664764494305\n",
      "Average test loss:  0.6375707153226823\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.47120036226990963\n",
      "Average test loss:  0.6154314697047477\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.4057001437626218\n",
      "Average test loss:  0.5930082236387798\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3453398799218697\n",
      "Average test loss:  0.5736400733378036\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.2933140399765714\n",
      "Average test loss:  0.5587133259310312\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.24999439146307437\n",
      "Average test loss:  0.5475832415645278\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.21438079624312678\n",
      "Average test loss:  0.5406413127480119\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.18519934065441448\n",
      "Average test loss:  0.5371116932748378\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.16118487429945508\n",
      "Average test loss:  0.5361452648593507\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.14128841497677\n",
      "Average test loss:  0.5375585698780961\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.12468803858541173\n",
      "Average test loss:  0.5406233276630604\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.11070824404258235\n",
      "Average test loss:  0.545204988178444\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.09886543674772859\n",
      "Average test loss:  0.5512127784032489\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.08874037332120673\n",
      "Average test loss:  0.5581298299208627\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.08002743624630047\n",
      "Average test loss:  0.565894845708613\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.07248304614377199\n",
      "Average test loss:  0.5741574504410273\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.06589987257541295\n",
      "Average test loss:  0.5828200080054761\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.06013892428464817\n",
      "Average test loss:  0.5922448196791545\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.055065784256751925\n",
      "Average test loss:  0.6020649045984033\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.05057440277808619\n",
      "Average test loss:  0.6119294094412715\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.715\n",
      "\n",
      "Average train loss:  0.04658669138136939\n",
      "Average test loss:  0.6219371825812977\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.043039444113135206\n",
      "Average test loss:  0.6323193791346992\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7421089726476987\n",
      "Average test loss:  0.7423534344472783\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7042392944456649\n",
      "Average test loss:  0.7047066082866377\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6933888115641756\n",
      "Average test loss:  0.6943835114663169\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6903865027732222\n",
      "Average test loss:  0.6922967636001642\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.705\n",
      "\n",
      "Average train loss:  0.6879748141464086\n",
      "Average test loss:  0.691339633774728\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.92125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.68427932372584\n",
      "Average test loss:  0.6900248321510087\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.91\n",
      "Average test accuracy:  0.71375\n",
      "\n",
      "Average train loss:  0.6780585634199667\n",
      "Average test loss:  0.6878074953431587\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.6675700727703214\n",
      "Average test loss:  0.6840500319579674\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.940625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.6502244406432284\n",
      "Average test loss:  0.6777984461646757\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6225761497856718\n",
      "Average test loss:  0.6677688117317947\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.5812579938385051\n",
      "Average test loss:  0.652732369478391\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.525509467639646\n",
      "Average test loss:  0.6324730858233547\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.958125\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.45949892430299893\n",
      "Average test loss:  0.6089877517542533\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3913858819677733\n",
      "Average test loss:  0.585349275288742\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.32864986771798016\n",
      "Average test loss:  0.5653645615700597\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.27526478618630784\n",
      "Average test loss:  0.5502031202101914\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2316370852301867\n",
      "Average test loss:  0.5403262635607691\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.19655053628603547\n",
      "Average test loss:  0.535116423868378\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.16834150998661898\n",
      "Average test loss:  0.533432458567136\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.14555430391750387\n",
      "Average test loss:  0.5345850338680985\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.12695858913210653\n",
      "Average test loss:  0.5381598522964833\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.11162844040050812\n",
      "Average test loss:  0.543366535740194\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.09886831771904592\n",
      "Average test loss:  0.5500106058979243\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.08813269576958994\n",
      "Average test loss:  0.5576921572392435\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.07902609531516579\n",
      "Average test loss:  0.5663185077729861\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.07122743123060866\n",
      "Average test loss:  0.5754675111226754\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.06449241637152757\n",
      "Average test loss:  0.5853361179473259\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.058648187298241096\n",
      "Average test loss:  0.5956262232701747\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.053538220006173254\n",
      "Average test loss:  0.6061951833833961\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.049057522544869205\n",
      "Average test loss:  0.6171052764415742\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6933356956486962\n",
      "Average test loss:  0.6940943997252162\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.930625\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.6901009295590083\n",
      "Average test loss:  0.6921040752449246\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.765625\n",
      "Average test accuracy:  0.5975\n",
      "\n",
      "Average train loss:  0.6871762049223987\n",
      "Average test loss:  0.6910923011010706\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.7975\n",
      "Average test accuracy:  0.62125\n",
      "\n",
      "Average train loss:  0.6820334551000057\n",
      "Average test loss:  0.6893083560171821\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.885625\n",
      "Average test accuracy:  0.68375\n",
      "\n",
      "Average train loss:  0.6728951891215523\n",
      "Average test loss:  0.6861003598159585\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9325\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.6568720051444732\n",
      "Average test loss:  0.6804297117915343\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6298683229900356\n",
      "Average test loss:  0.6708282472439867\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5877005164302809\n",
      "Average test loss:  0.6558011239215741\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.5299730148089593\n",
      "Average test loss:  0.6354172386420913\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.46253661651697303\n",
      "Average test loss:  0.6120484752658345\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3943608550220043\n",
      "Average test loss:  0.5892354123354872\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3324258765722556\n",
      "Average test loss:  0.5701832833406105\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.27968848560405263\n",
      "Average test loss:  0.5556599376389284\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.23630973258650134\n",
      "Average test loss:  0.5462484240935964\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.20108986168972323\n",
      "Average test loss:  0.5408991983659456\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1725558372609167\n",
      "Average test loss:  0.5389261970967208\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.14931229195100945\n",
      "Average test loss:  0.5396596744423986\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.13023282106385323\n",
      "Average test loss:  0.5426515949027596\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.11442551831996615\n",
      "Average test loss:  0.5476060348708335\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.10122385007587892\n",
      "Average test loss:  0.5540662609298747\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.0900929447472079\n",
      "Average test loss:  0.5615831614314537\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.0806361929505247\n",
      "Average test loss:  0.5698658871069494\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.07254332604784079\n",
      "Average test loss:  0.5787889684333627\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.0655597027108669\n",
      "Average test loss:  0.5884302610323818\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.05951266508547771\n",
      "Average test loss:  0.5988087526522187\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.054228298738855076\n",
      "Average test loss:  0.6094236278770025\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.049597452971920135\n",
      "Average test loss:  0.620134474799993\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.04551227971858976\n",
      "Average test loss:  0.6309597592524053\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.04189881301483491\n",
      "Average test loss:  0.642403289990518\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.03867494100917498\n",
      "Average test loss:  0.6536036737937319\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6953256195010815\n",
      "Average test loss:  0.6954445478765431\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6922373640105253\n",
      "Average test loss:  0.6928372605452536\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6907656998769548\n",
      "Average test loss:  0.6923330810803386\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.515625\n",
      "Average test accuracy:  0.50375\n",
      "\n",
      "Average train loss:  0.6876184999144792\n",
      "Average test loss:  0.6912520774900646\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.669375\n",
      "Average test accuracy:  0.55\n",
      "\n",
      "Average train loss:  0.6811267789241011\n",
      "Average test loss:  0.6889846664330231\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.76875\n",
      "Average test accuracy:  0.58875\n",
      "\n",
      "Average train loss:  0.6685238011470428\n",
      "Average test loss:  0.6845862234361425\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.856875\n",
      "Average test accuracy:  0.6525\n",
      "\n",
      "Average train loss:  0.6452984985616839\n",
      "Average test loss:  0.6763623285951185\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.908125\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.6061327049506745\n",
      "Average test loss:  0.6622276366768335\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.5486046565242519\n",
      "Average test loss:  0.6413786596997569\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.4778923226486947\n",
      "Average test loss:  0.6158977414738219\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.40461637751549673\n",
      "Average test loss:  0.5901878802807852\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.33752392115572744\n",
      "Average test loss:  0.5682408114209966\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.2808455483058947\n",
      "Average test loss:  0.5519596052310468\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.2348979423383136\n",
      "Average test loss:  0.5409586565442339\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.1982370767555098\n",
      "Average test loss:  0.5351601974855414\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.1689699821956617\n",
      "Average test loss:  0.5332003824017325\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.14540108038112662\n",
      "Average test loss:  0.5344461057031464\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.12624514154647934\n",
      "Average test loss:  0.5379910064917505\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.11052383371769968\n",
      "Average test loss:  0.5433996783835419\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.09747662207691782\n",
      "Average test loss:  0.5505374304762989\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.08654932741571512\n",
      "Average test loss:  0.5584751781615744\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07730871499137149\n",
      "Average test loss:  0.5674909237735201\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06942126458989147\n",
      "Average test loss:  0.5772120457816173\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06265204315771637\n",
      "Average test loss:  0.5874907970378729\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.056785822778958224\n",
      "Average test loss:  0.5983714759528688\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.05166578510387685\n",
      "Average test loss:  0.6095385735641042\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.047176027326324525\n",
      "Average test loss:  0.6210518417494001\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04321977747847481\n",
      "Average test loss:  0.632676495980086\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.039715540262954326\n",
      "Average test loss:  0.6444939848401904\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.036595592893781975\n",
      "Average test loss:  0.6564499557399214\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6927625384238895\n",
      "Average test loss:  0.693011240875006\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.6916429904972482\n",
      "Average test loss:  0.6926231034372861\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.75375\n",
      "Average test accuracy:  0.5425\n",
      "\n",
      "Average train loss:  0.6883228642160658\n",
      "Average test loss:  0.6914827599285295\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.936875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6797527717960898\n",
      "Average test loss:  0.6884910803926246\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6586611777867346\n",
      "Average test loss:  0.6811293747489692\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6135319561566179\n",
      "Average test loss:  0.6652172238966142\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9475\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5390578713789519\n",
      "Average test loss:  0.638872616574001\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.44881021002375254\n",
      "Average test loss:  0.6073499194087454\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.3631030108886118\n",
      "Average test loss:  0.5787175735152607\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2925371220488843\n",
      "Average test loss:  0.5579299473868168\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.966875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.23783582015296947\n",
      "Average test loss:  0.5442640023746654\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.19612017863349399\n",
      "Average test loss:  0.537110171755535\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.16404889182798507\n",
      "Average test loss:  0.5353229585570057\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13900812994973186\n",
      "Average test loss:  0.5371856656480521\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.11915532058493515\n",
      "Average test loss:  0.5414300122390254\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10319225948690407\n",
      "Average test loss:  0.5478401570130339\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.09014995644906527\n",
      "Average test loss:  0.5564439170509675\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07939037633059925\n",
      "Average test loss:  0.5657476090647094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07038069701617992\n",
      "Average test loss:  0.575739758379913\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.06278063617714645\n",
      "Average test loss:  0.5870501188297638\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.0563148866785202\n",
      "Average test loss:  0.5989403500633207\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.05076260162638386\n",
      "Average test loss:  0.6109454015526025\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.04594846303772207\n",
      "Average test loss:  0.6232761955888512\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.04176494493987876\n",
      "Average test loss:  0.6363218047776331\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.038106310062299364\n",
      "Average test loss:  0.6489145614761705\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.034882264197836806\n",
      "Average test loss:  0.6618393443598994\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.03203998397583138\n",
      "Average test loss:  0.6753626275892666\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.029511292823417395\n",
      "Average test loss:  0.6879413472947213\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.027264488901887443\n",
      "Average test loss:  0.701060244864178\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  3\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.025253336057409693\n",
      "Average test loss:  0.7144291626792453\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6925653770382866\n",
      "Average test loss:  0.6932899113361146\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.690594495509511\n",
      "Average test loss:  0.6922931198569433\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.86\n",
      "Average test accuracy:  0.66625\n",
      "\n",
      "Average train loss:  0.6880330016204891\n",
      "Average test loss:  0.6913860461004037\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.921875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.683258135266759\n",
      "Average test loss:  0.6897441687214222\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6743400668509315\n",
      "Average test loss:  0.686668047578411\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6587062351473616\n",
      "Average test loss:  0.6812060035915949\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.94125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6341744379298542\n",
      "Average test loss:  0.6724748896197212\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6009470133179732\n",
      "Average test loss:  0.6604675953251192\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.5614430724033113\n",
      "Average test loss:  0.6459533891578725\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5192206499125697\n",
      "Average test loss:  0.6303595340412017\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.47708902318303464\n",
      "Average test loss:  0.6147225746160219\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.43694994800542974\n",
      "Average test loss:  0.6000094948189288\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.3997546071175244\n",
      "Average test loss:  0.5866741993121274\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.36589232602440597\n",
      "Average test loss:  0.5747849128664555\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3353286281035229\n",
      "Average test loss:  0.564658356843141\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3078653944505561\n",
      "Average test loss:  0.5561411510328546\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2832286779396593\n",
      "Average test loss:  0.5491487282961989\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2611303991948229\n",
      "Average test loss:  0.5434193951642681\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.24129222599004327\n",
      "Average test loss:  0.5391017586770185\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.22344349937957864\n",
      "Average test loss:  0.5359159903650499\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.2073652481940955\n",
      "Average test loss:  0.5338134998935871\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.19284308943961082\n",
      "Average test loss:  0.5327104171218443\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.1796897571020777\n",
      "Average test loss:  0.5323830269560448\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.16774706950509097\n",
      "Average test loss:  0.5328300953180888\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.15688073155860224\n",
      "Average test loss:  0.5339985169500076\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.1469762283709648\n",
      "Average test loss:  0.5359124071902805\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.13792065198937853\n",
      "Average test loss:  0.5381434843384079\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.1296394460131087\n",
      "Average test loss:  0.5410365294756371\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.12203716063238217\n",
      "Average test loss:  0.5442651557983599\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.11504605989118159\n",
      "Average test loss:  0.547974781531135\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6934818673925632\n",
      "Average test loss:  0.6943132778601209\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6902807382213266\n",
      "Average test loss:  0.6922139835647011\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.870625\n",
      "Average test accuracy:  0.68125\n",
      "\n",
      "Average train loss:  0.6873471824582581\n",
      "Average test loss:  0.691121043540206\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.68200332300844\n",
      "Average test loss:  0.6892607651597616\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6715981353890289\n",
      "Average test loss:  0.6856256300956746\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6524444278389545\n",
      "Average test loss:  0.6788732042429461\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.94375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.621239358357039\n",
      "Average test loss:  0.6677560052301659\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5778435857819146\n",
      "Average test loss:  0.6521123572633419\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.52637161135893\n",
      "Average test loss:  0.6333405231299158\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.4724978515369878\n",
      "Average test loss:  0.6137117261734453\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.4207783862725086\n",
      "Average test loss:  0.5951111923122765\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.3735737368673062\n",
      "Average test loss:  0.5787327603392951\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.33176369707760284\n",
      "Average test loss:  0.564881144799673\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.295282370118879\n",
      "Average test loss:  0.5538969543407365\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2636378757882975\n",
      "Average test loss:  0.5452311019582897\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.23625599984682658\n",
      "Average test loss:  0.5388847531879326\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.21251712301740602\n",
      "Average test loss:  0.5347253987671348\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.19188976619557288\n",
      "Average test loss:  0.5322927645020578\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.17389093955748672\n",
      "Average test loss:  0.531399999220029\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.15813582182336716\n",
      "Average test loss:  0.5318985582826606\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.14429057937850795\n",
      "Average test loss:  0.5337624021648518\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.1320756709418712\n",
      "Average test loss:  0.5363665844903549\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.12124282259734864\n",
      "Average test loss:  0.5400090610993779\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.11161422587954102\n",
      "Average test loss:  0.544130904143449\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.1030117123134019\n",
      "Average test loss:  0.5491466441023404\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.09531637234712555\n",
      "Average test loss:  0.5546595515392151\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.08839448294988968\n",
      "Average test loss:  0.5607693929875109\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.08215784570053612\n",
      "Average test loss:  0.5671515125455979\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07651988134741299\n",
      "Average test loss:  0.5740048468324924\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07139842966028777\n",
      "Average test loss:  0.5811394019265815\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6993966126643513\n",
      "Average test loss:  0.7001909841315115\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6919225530714955\n",
      "Average test loss:  0.6935332929783788\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6891041058455677\n",
      "Average test loss:  0.6918591989396136\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.851875\n",
      "Average test accuracy:  0.56125\n",
      "\n",
      "Average train loss:  0.6860607175508021\n",
      "Average test loss:  0.6907243352563359\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.919375\n",
      "Average test accuracy:  0.69\n",
      "\n",
      "Average train loss:  0.6808417460012565\n",
      "Average test loss:  0.6888978299661238\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.7125\n",
      "\n",
      "Average train loss:  0.6714299172615839\n",
      "Average test loss:  0.685601846917613\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.936875\n",
      "Average test accuracy:  0.71125\n",
      "\n",
      "Average train loss:  0.6544093198342583\n",
      "Average test loss:  0.6796181958952915\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.94125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.6247262933026718\n",
      "Average test loss:  0.669112085770511\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.5783985343163544\n",
      "Average test loss:  0.6525852310650553\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.5180896480521177\n",
      "Average test loss:  0.6309862583136795\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.4530169904047973\n",
      "Average test loss:  0.6078017154204213\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.3913890868352327\n",
      "Average test loss:  0.5864100762158789\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3372820584635397\n",
      "Average test loss:  0.5687386997405066\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.29145819389355904\n",
      "Average test loss:  0.5551348261368451\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.2532293990941863\n",
      "Average test loss:  0.5451428475458483\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.22138211119669102\n",
      "Average test loss:  0.5386824572978521\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.1947696388874729\n",
      "Average test loss:  0.5350579871576102\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1724137197695794\n",
      "Average test loss:  0.5337150194678526\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.15349765729462\n",
      "Average test loss:  0.5343321167431695\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.1373843862651051\n",
      "Average test loss:  0.5364491681955975\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.12356824448722896\n",
      "Average test loss:  0.5399494859021132\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.11164449715215435\n",
      "Average test loss:  0.5447128528206079\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.1012891771186528\n",
      "Average test loss:  0.5502914290478331\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.09224526423781192\n",
      "Average test loss:  0.5565962845809391\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08430353781476059\n",
      "Average test loss:  0.5635629403614634\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.07729567863639399\n",
      "Average test loss:  0.5711139453264306\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07107800762190665\n",
      "Average test loss:  0.5793070851779483\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.06555277354749094\n",
      "Average test loss:  0.5875973178479675\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.06061463385117325\n",
      "Average test loss:  0.5962582711067522\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.05619668044230807\n",
      "Average test loss:  0.6052190354221203\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.716555698582518\n",
      "Average test loss:  0.7168454263030064\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.697868907493551\n",
      "Average test loss:  0.6986812475816601\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6909559273091498\n",
      "Average test loss:  0.6928661790393326\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.85625\n",
      "Average test accuracy:  0.5625\n",
      "\n",
      "Average train loss:  0.6874369377400186\n",
      "Average test loss:  0.691171881538677\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.801875\n",
      "Average test accuracy:  0.625\n",
      "\n",
      "Average train loss:  0.6830390047208822\n",
      "Average test loss:  0.689613487878605\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.76125\n",
      "Average test accuracy:  0.58375\n",
      "\n",
      "Average train loss:  0.6759685992083398\n",
      "Average test loss:  0.687136104324532\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.809375\n",
      "Average test accuracy:  0.625\n",
      "\n",
      "Average train loss:  0.6641515201862311\n",
      "Average test loss:  0.6829463170320196\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.855625\n",
      "Average test accuracy:  0.65\n",
      "\n",
      "Average train loss:  0.6442653736862011\n",
      "Average test loss:  0.6758310139962167\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.899375\n",
      "Average test accuracy:  0.67875\n",
      "\n",
      "Average train loss:  0.6125064275406217\n",
      "Average test loss:  0.6643146862513585\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.920625\n",
      "Average test accuracy:  0.7125\n",
      "\n",
      "Average train loss:  0.5670435808568164\n",
      "Average test loss:  0.6476370188080858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.5108302841007547\n",
      "Average test loss:  0.6267611196553736\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.45004879777227424\n",
      "Average test loss:  0.6043185819550297\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.958125\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3909962694404728\n",
      "Average test loss:  0.5829562549563109\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.3377599558744056\n",
      "Average test loss:  0.5647281563388734\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.29194176322881743\n",
      "Average test loss:  0.5504248225421832\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.25342959774069806\n",
      "Average test loss:  0.5400811603591278\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.22126708637582437\n",
      "Average test loss:  0.5332311695274244\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.19438894666636194\n",
      "Average test loss:  0.529389002217921\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.17182924417491333\n",
      "Average test loss:  0.5280498887623616\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1527770092832377\n",
      "Average test loss:  0.5288199714970844\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1365970667238802\n",
      "Average test loss:  0.5313112354620656\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.12276342883513736\n",
      "Average test loss:  0.5351714989332769\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.11085171325241601\n",
      "Average test loss:  0.5401913463802838\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.10054700047548577\n",
      "Average test loss:  0.5462448723698964\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.09157222916797188\n",
      "Average test loss:  0.5529743529134787\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.08370837625626985\n",
      "Average test loss:  0.5602601565784991\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07676933730748912\n",
      "Average test loss:  0.5682786521184698\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.0706302971694184\n",
      "Average test loss:  0.5766614756414437\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.06516810013384443\n",
      "Average test loss:  0.5853351013970197\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.060270949053741786\n",
      "Average test loss:  0.5944830029232139\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6921151363741553\n",
      "Average test loss:  0.6927870017634904\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5975\n",
      "Average test accuracy:  0.50375\n",
      "\n",
      "Average train loss:  0.6894601607392578\n",
      "Average test loss:  0.691881355736199\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.7625\n",
      "Average test accuracy:  0.53875\n",
      "\n",
      "Average train loss:  0.6830664966579092\n",
      "Average test loss:  0.6897074658832322\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.8925\n",
      "Average test accuracy:  0.6575\n",
      "\n",
      "Average train loss:  0.6702674709463344\n",
      "Average test loss:  0.6853059801146267\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.919375\n",
      "Average test accuracy:  0.7075\n",
      "\n",
      "Average train loss:  0.6476823863725562\n",
      "Average test loss:  0.6775373593963927\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.6111670319722599\n",
      "Average test loss:  0.6648897448711518\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.940625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.5588394501096383\n",
      "Average test loss:  0.64665129267757\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.49411549514990166\n",
      "Average test loss:  0.624154407236628\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.42511593644222473\n",
      "Average test loss:  0.6006626252210072\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.359836475833237\n",
      "Average test loss:  0.5795861102639379\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3028444845171416\n",
      "Average test loss:  0.5623120235195984\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.2554901268855709\n",
      "Average test loss:  0.5500793336393764\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.2169055689944415\n",
      "Average test loss:  0.5423114285877025\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.18560430901793823\n",
      "Average test loss:  0.5381616605820332\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1601279269863615\n",
      "Average test loss:  0.5372698995473919\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13924245758729678\n",
      "Average test loss:  0.5387647467694343\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.12196063785183471\n",
      "Average test loss:  0.5422322847869201\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10755236949176716\n",
      "Average test loss:  0.5475154600707806\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09544627881590383\n",
      "Average test loss:  0.5541382663039442\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.0851701269053715\n",
      "Average test loss:  0.5617729413318951\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07639498536382876\n",
      "Average test loss:  0.5702215936466973\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.06884485424926005\n",
      "Average test loss:  0.5792151961775296\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.062308229391434995\n",
      "Average test loss:  0.5888963139960605\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.05661561011085439\n",
      "Average test loss:  0.5990364905571596\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.05163817728475154\n",
      "Average test loss:  0.6093575359506183\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.047263645914277175\n",
      "Average test loss:  0.6198143667583592\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04340633368882143\n",
      "Average test loss:  0.6310844035470436\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.03997615715936476\n",
      "Average test loss:  0.6420256463196025\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.0369254167490199\n",
      "Average test loss:  0.6531744491222599\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.034190539996713835\n",
      "Average test loss:  0.6644148849806197\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.901875\n",
      "Average test accuracy:  0.685\n",
      "\n",
      "Average train loss:  0.6926969391216559\n",
      "Average test loss:  0.6929853664491604\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.7625\n",
      "Average test accuracy:  0.5525\n",
      "\n",
      "Average train loss:  0.6913427824835253\n",
      "Average test loss:  0.6925150440230272\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6871514708957078\n",
      "Average test loss:  0.6910577180874548\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.910625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.6764970744097022\n",
      "Average test loss:  0.6873411869906456\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.929375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.653555288834077\n",
      "Average test loss:  0.679282813567054\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.93125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.610639319966933\n",
      "Average test loss:  0.6641118075421061\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.938125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.5450162015766221\n",
      "Average test loss:  0.6407372249803563\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.46666130516010185\n",
      "Average test loss:  0.6128220088241715\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.3896889599505478\n",
      "Average test loss:  0.5860352083322568\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.32300967180703605\n",
      "Average test loss:  0.5645503741630634\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.26875115336810407\n",
      "Average test loss:  0.5489927761187198\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.22557606988710055\n",
      "Average test loss:  0.539167515692997\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.19127776453406076\n",
      "Average test loss:  0.5338057529649315\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.16382555224162368\n",
      "Average test loss:  0.5321877525816819\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.14158955203489565\n",
      "Average test loss:  0.5333512518616362\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.12340815798593856\n",
      "Average test loss:  0.5369286918353509\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.1083739018350736\n",
      "Average test loss:  0.5422918179649701\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.09583019858667123\n",
      "Average test loss:  0.5491230778964782\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08525523840653985\n",
      "Average test loss:  0.5571584540629962\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.07626774277114114\n",
      "Average test loss:  0.5660931620133369\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.06854782812449027\n",
      "Average test loss:  0.5758233649877641\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.71375\n",
      "\n",
      "Average train loss:  0.06189159224951874\n",
      "Average test loss:  0.5863876336690099\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.05609231915178677\n",
      "Average test loss:  0.5970739411282878\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.05103093188266913\n",
      "Average test loss:  0.6082282155670015\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.04656784717254866\n",
      "Average test loss:  0.6196088266635291\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.04263442886615243\n",
      "Average test loss:  0.6313832001265406\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.039149902805739184\n",
      "Average test loss:  0.6431681296713788\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.036050202224351326\n",
      "Average test loss:  0.6552323731241644\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.03329892714974617\n",
      "Average test loss:  0.6673710011035704\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.030835627213504652\n",
      "Average test loss:  0.6790681694787767\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7090029441131636\n",
      "Average test loss:  0.7099322006189293\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6912593259304511\n",
      "Average test loss:  0.6936213378923596\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.58375\n",
      "Average test accuracy:  0.50125\n",
      "\n",
      "Average train loss:  0.686632168821931\n",
      "Average test loss:  0.6909587753182104\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.926875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.6818884386567524\n",
      "Average test loss:  0.6892445910524346\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.6739090291896801\n",
      "Average test loss:  0.6864358958273636\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6599181273466074\n",
      "Average test loss:  0.6814905994832081\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.6361654235343069\n",
      "Average test loss:  0.6730620299360832\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5983087984306031\n",
      "Average test loss:  0.6595290131291416\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.5443734448758647\n",
      "Average test loss:  0.6404345752112017\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.4776131763610221\n",
      "Average test loss:  0.6170141161844537\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.40644745694907236\n",
      "Average test loss:  0.5929176629340455\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.3397118911279227\n",
      "Average test loss:  0.5716540569556172\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2824912292058903\n",
      "Average test loss:  0.5560206944016121\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.23573065086466372\n",
      "Average test loss:  0.5452866344755015\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.19830049570695021\n",
      "Average test loss:  0.5397810825845862\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.16843998432481558\n",
      "Average test loss:  0.5383297800097252\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.14447522391595727\n",
      "Average test loss:  0.5397298515591311\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1250547582745574\n",
      "Average test loss:  0.543957566480609\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.10917249324160616\n",
      "Average test loss:  0.5497276338603094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.09604462449093919\n",
      "Average test loss:  0.5573104554024056\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.08507454998591586\n",
      "Average test loss:  0.5657225471876539\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.07582246913256269\n",
      "Average test loss:  0.5752302255396313\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06796449279705258\n",
      "Average test loss:  0.5854648308980552\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.06122924420374815\n",
      "Average test loss:  0.5963604792519969\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.055431129923341226\n",
      "Average test loss:  0.6074848122831621\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.05039368303434691\n",
      "Average test loss:  0.6188943357993689\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.04601336604940776\n",
      "Average test loss:  0.630694157171695\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.042169762781245866\n",
      "Average test loss:  0.6423977210415392\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.03879096136578345\n",
      "Average test loss:  0.6542323214582156\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.035800846648551043\n",
      "Average test loss:  0.6661306938197247\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7035017078522988\n",
      "Average test loss:  0.7039514433042978\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6927300045381651\n",
      "Average test loss:  0.6936056141260067\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6906178363382485\n",
      "Average test loss:  0.6923158890012755\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.92375\n",
      "Average test accuracy:  0.6875\n",
      "\n",
      "Average train loss:  0.6880157599283052\n",
      "Average test loss:  0.6913837230050784\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.915\n",
      "Average test accuracy:  0.68\n",
      "\n",
      "Average train loss:  0.6827951744519206\n",
      "Average test loss:  0.6895711216306003\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.92\n",
      "Average test accuracy:  0.7025\n",
      "\n",
      "Average train loss:  0.6724993281754129\n",
      "Average test loss:  0.6859899051651324\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.921875\n",
      "Average test accuracy:  0.70625\n",
      "\n",
      "Average train loss:  0.6530287573742051\n",
      "Average test loss:  0.6792361770979559\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.71375\n",
      "\n",
      "Average train loss:  0.6184991408374811\n",
      "Average test loss:  0.6672095211536165\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.5639498465263122\n",
      "Average test loss:  0.6483948351691703\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.49123816975171014\n",
      "Average test loss:  0.6232996147351016\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.41151957987714555\n",
      "Average test loss:  0.5967900271995498\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.3374952758706966\n",
      "Average test loss:  0.5732297001229626\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.27578960492679566\n",
      "Average test loss:  0.556437653519354\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.2269428138531576\n",
      "Average test loss:  0.5460524969594567\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.18891361610237042\n",
      "Average test loss:  0.5410983688881111\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1592168511479523\n",
      "Average test loss:  0.5407541775096691\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13578810167247127\n",
      "Average test loss:  0.5433493089549529\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.11703950872227631\n",
      "Average test loss:  0.5486309684597194\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1018395360365341\n",
      "Average test loss:  0.5556723225085457\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08936242352817088\n",
      "Average test loss:  0.5640485980532887\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.0789898927128953\n",
      "Average test loss:  0.5739299904414301\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07028606907020556\n",
      "Average test loss:  0.5841188000233873\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.06291571958798718\n",
      "Average test loss:  0.5950114554705833\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.056632529910207695\n",
      "Average test loss:  0.6070761682648126\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.05123754697926671\n",
      "Average test loss:  0.6187463613757473\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.046572462177165846\n",
      "Average test loss:  0.6305350829236634\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.04252120433215222\n",
      "Average test loss:  0.6429105721671484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.03898144498729989\n",
      "Average test loss:  0.6551765001892965\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.0358771290757463\n",
      "Average test loss:  0.6675320227373653\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.03313790469978565\n",
      "Average test loss:  0.6798132300604021\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.691588467673221\n",
      "Average test loss:  0.6926116941224468\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.9\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.6887289151279689\n",
      "Average test loss:  0.6916172239535129\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6823101509917979\n",
      "Average test loss:  0.6894003111178074\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.6680561693787211\n",
      "Average test loss:  0.684472420186327\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.6384338630998296\n",
      "Average test loss:  0.6742011116764971\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.5854981543255207\n",
      "Average test loss:  0.6559013609849905\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.5107833433848226\n",
      "Average test loss:  0.6303071230541804\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.42687364156874025\n",
      "Average test loss:  0.602453606867423\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.34824944329698937\n",
      "Average test loss:  0.5783394525565294\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.2826930328189377\n",
      "Average test loss:  0.5604356958041673\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.23089129603611858\n",
      "Average test loss:  0.5492070013246321\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.190658225759736\n",
      "Average test loss:  0.5439780747275679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.1594244928388486\n",
      "Average test loss:  0.5437590467010969\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.13491727754559366\n",
      "Average test loss:  0.5463759056325684\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.11545825593401927\n",
      "Average test loss:  0.5515596044227772\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.09981208478862931\n",
      "Average test loss:  0.5594654860933139\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.08704377513536038\n",
      "Average test loss:  0.5684027022416989\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.07651350507618275\n",
      "Average test loss:  0.5782027449391803\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.06771976105239665\n",
      "Average test loss:  0.5894956176052576\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06032461234286581\n",
      "Average test loss:  0.6011883554518954\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.05403543093819335\n",
      "Average test loss:  0.6136591900148484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.04865666718895206\n",
      "Average test loss:  0.6262472864750175\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.04401109581207504\n",
      "Average test loss:  0.6392260823319084\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.03998491976614743\n",
      "Average test loss:  0.6524206546198713\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.03645963759464176\n",
      "Average test loss:  0.6653621613141171\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.03336689000822247\n",
      "Average test loss:  0.6786889052017487\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.030622652655419715\n",
      "Average test loss:  0.6921046068623364\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.02818206360458557\n",
      "Average test loss:  0.705519515677091\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.025991051298680696\n",
      "Average test loss:  0.7184832980651318\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.02401925529229888\n",
      "Average test loss:  0.7317108043776025\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6916132019203837\n",
      "Average test loss:  0.692613890097852\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.850625\n",
      "Average test accuracy:  0.655\n",
      "\n",
      "Average train loss:  0.688748686373093\n",
      "Average test loss:  0.6916185003611943\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.8925\n",
      "Average test accuracy:  0.69375\n",
      "\n",
      "Average train loss:  0.68242737480301\n",
      "Average test loss:  0.6894269406811969\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.89375\n",
      "Average test accuracy:  0.7\n",
      "\n",
      "Average train loss:  0.6692111810262028\n",
      "Average test loss:  0.6848306385015324\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.924375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.643685016084404\n",
      "Average test loss:  0.6758540329013826\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.5993940271873625\n",
      "Average test loss:  0.6602171049373832\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.945625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5344177025142551\n",
      "Average test loss:  0.6373736439928477\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.45707748798718967\n",
      "Average test loss:  0.6106120131776994\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.38013049182792463\n",
      "Average test loss:  0.5853480313078587\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.31271206808329316\n",
      "Average test loss:  0.565021140065805\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2575129151497692\n",
      "Average test loss:  0.5509865195091104\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.21357660753697758\n",
      "Average test loss:  0.5425499279318361\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1789085444108184\n",
      "Average test loss:  0.5390027541007526\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.15146476564541256\n",
      "Average test loss:  0.5391797951383731\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.12954390095431725\n",
      "Average test loss:  0.5422513491546038\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.11184469184988323\n",
      "Average test loss:  0.5476844068945613\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.0973991769588431\n",
      "Average test loss:  0.5549597985550445\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.08546260164012075\n",
      "Average test loss:  0.5634515878400773\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.07551918813517006\n",
      "Average test loss:  0.5733714239757297\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.06716086947691276\n",
      "Average test loss:  0.5836805854101451\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.060061769026287626\n",
      "Average test loss:  0.594869947586877\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.0539862916963576\n",
      "Average test loss:  0.6066236518529823\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.048739649813223256\n",
      "Average test loss:  0.6187107512513318\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.0441900389114561\n",
      "Average test loss:  0.6312885895088228\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.040208473111981544\n",
      "Average test loss:  0.643836241023514\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.03671620644314645\n",
      "Average test loss:  0.6565378468969939\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.03362733111445551\n",
      "Average test loss:  0.6693495149124998\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.030877126158720142\n",
      "Average test loss:  0.6824456466974937\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.02842383703515929\n",
      "Average test loss:  0.695489934941686\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  4\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.026235503429872815\n",
      "Average test loss:  0.7085232985295494\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.836875\n",
      "Average test accuracy:  0.645\n",
      "\n",
      "Average train loss:  0.6917273895147774\n",
      "Average test loss:  0.6926649785337661\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.9275\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.6892758672235746\n",
      "Average test loss:  0.6918286555394445\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.915\n",
      "Average test accuracy:  0.7\n",
      "\n",
      "Average train loss:  0.6844201372235533\n",
      "Average test loss:  0.690176784357908\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.901875\n",
      "Average test accuracy:  0.6725\n",
      "\n",
      "Average train loss:  0.6754878719764229\n",
      "Average test loss:  0.68714370459998\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.906875\n",
      "Average test accuracy:  0.67875\n",
      "\n",
      "Average train loss:  0.6608363643845611\n",
      "Average test loss:  0.6821524496425395\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.901875\n",
      "Average test accuracy:  0.665\n",
      "\n",
      "Average train loss:  0.6389144791030325\n",
      "Average test loss:  0.6747798033079294\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.91375\n",
      "Average test accuracy:  0.68625\n",
      "\n",
      "Average train loss:  0.609331363915022\n",
      "Average test loss:  0.6646545439523116\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.92625\n",
      "Average test accuracy:  0.70375\n",
      "\n",
      "Average train loss:  0.5728902465859976\n",
      "Average test loss:  0.6522673380764513\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.71125\n",
      "\n",
      "Average train loss:  0.5318952394985763\n",
      "Average test loss:  0.6381625705160671\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.489121590706836\n",
      "Average test loss:  0.6234461802469432\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.44717643815697006\n",
      "Average test loss:  0.6091309467811278\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.958125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.4076898254392776\n",
      "Average test loss:  0.595747025498974\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.3714859370285221\n",
      "Average test loss:  0.5836958771645174\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.33884844889769883\n",
      "Average test loss:  0.5734825741072123\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3096667121996817\n",
      "Average test loss:  0.5646436536277474\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.2836575301754858\n",
      "Average test loss:  0.5580020772783126\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.260480470520617\n",
      "Average test loss:  0.5522344236184249\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.23981792584335512\n",
      "Average test loss:  0.5480897550417722\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2213519324037653\n",
      "Average test loss:  0.5447799002134235\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.20481587429354833\n",
      "Average test loss:  0.543005589027931\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.1899647147738558\n",
      "Average test loss:  0.5420622919706379\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1765902103300158\n",
      "Average test loss:  0.5421425796751512\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.16450816921576836\n",
      "Average test loss:  0.5429464957120556\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.15356348750683083\n",
      "Average test loss:  0.5445015958793026\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.1436171074644849\n",
      "Average test loss:  0.5465932295033881\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.13455629341397726\n",
      "Average test loss:  0.549190395534737\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.1262764535904248\n",
      "Average test loss:  0.5524837999978874\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.11868893987700378\n",
      "Average test loss:  0.5561555239160527\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.11172458892654374\n",
      "Average test loss:  0.5602764219632114\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.10531433485819879\n",
      "Average test loss:  0.564716528374051\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7034900046479131\n",
      "Average test loss:  0.7040546246204089\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6942730581522208\n",
      "Average test loss:  0.6953054494772797\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6910953521282645\n",
      "Average test loss:  0.6927751831559515\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6890213543896598\n",
      "Average test loss:  0.6917610575127756\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.625625\n",
      "Average test accuracy:  0.53\n",
      "\n",
      "Average train loss:  0.6861670071020614\n",
      "Average test loss:  0.6907128279000005\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.814375\n",
      "Average test accuracy:  0.615\n",
      "\n",
      "Average train loss:  0.6811742705092921\n",
      "Average test loss:  0.6889581906909895\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.875\n",
      "Average test accuracy:  0.67125\n",
      "\n",
      "Average train loss:  0.6718286282769065\n",
      "Average test loss:  0.6856600582224478\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.900625\n",
      "Average test accuracy:  0.70625\n",
      "\n",
      "Average train loss:  0.6543205506957173\n",
      "Average test loss:  0.6793970319585343\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.924375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.6240593997281172\n",
      "Average test loss:  0.6683996639109644\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.940625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.5789479286375115\n",
      "Average test loss:  0.6516924524833062\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5228473502605052\n",
      "Average test loss:  0.6306378946379628\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.46358551389147634\n",
      "Average test loss:  0.6083802905256969\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.40773119317021395\n",
      "Average test loss:  0.587765840112774\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.35821571268062874\n",
      "Average test loss:  0.5704061721620609\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.31558760049426676\n",
      "Average test loss:  0.5563566556767485\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2792847239338339\n",
      "Average test loss:  0.5458810473191039\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.24841903858561576\n",
      "Average test loss:  0.5381978213401809\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.22209423415886587\n",
      "Average test loss:  0.5331653353708021\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.19953996647840622\n",
      "Average test loss:  0.5302528409774899\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1801085377588889\n",
      "Average test loss:  0.5292582607073113\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.1632935921247044\n",
      "Average test loss:  0.5299686763720083\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.14863161820264828\n",
      "Average test loss:  0.5317394352119723\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.13579774554245427\n",
      "Average test loss:  0.5346508100630698\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.12450436276885024\n",
      "Average test loss:  0.5385665069331061\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.11451205479653799\n",
      "Average test loss:  0.5430429253356764\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.10564334465560443\n",
      "Average test loss:  0.5485734019773064\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.09773371914349821\n",
      "Average test loss:  0.5543217584293917\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.09066604110060324\n",
      "Average test loss:  0.5606422973052001\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08432623311845315\n",
      "Average test loss:  0.567509115710715\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07861603175404326\n",
      "Average test loss:  0.5746925024595332\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.764375\n",
      "Average test accuracy:  0.5425\n",
      "\n",
      "Average train loss:  0.692390360596476\n",
      "Average test loss:  0.6928798852180336\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.88875\n",
      "Average test accuracy:  0.66375\n",
      "\n",
      "Average train loss:  0.6907673835186183\n",
      "Average test loss:  0.6923149222240509\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.93125\n",
      "Average test accuracy:  0.715\n",
      "\n",
      "Average train loss:  0.6867743798451663\n",
      "Average test loss:  0.6909215636692565\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.90125\n",
      "Average test accuracy:  0.6825\n",
      "\n",
      "Average train loss:  0.677871853808978\n",
      "Average test loss:  0.6878321446210652\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.895625\n",
      "Average test accuracy:  0.68\n",
      "\n",
      "Average train loss:  0.6591656740066406\n",
      "Average test loss:  0.6813761056003954\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.91125\n",
      "Average test accuracy:  0.69875\n",
      "\n",
      "Average train loss:  0.6247451061616454\n",
      "Average test loss:  0.6694586033159422\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.93375\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.5725828974366505\n",
      "Average test loss:  0.6514011913236429\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.940625\n",
      "Average test accuracy:  0.71375\n",
      "\n",
      "Average train loss:  0.5093051647526089\n",
      "Average test loss:  0.6294836825668215\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.4444446096964929\n",
      "Average test loss:  0.6074119961369626\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.384616981535006\n",
      "Average test loss:  0.5876785156181203\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.3323611643170136\n",
      "Average test loss:  0.5714225073274605\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.28799205881931167\n",
      "Average test loss:  0.5588715943711473\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.25077915776516907\n",
      "Average test loss:  0.5499582909122279\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2196178635765739\n",
      "Average test loss:  0.5441417534917982\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1934614268434414\n",
      "Average test loss:  0.5410997529412419\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.17138203257606097\n",
      "Average test loss:  0.5402437221437693\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1526591104476343\n",
      "Average test loss:  0.541374174514085\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1366681947905145\n",
      "Average test loss:  0.5437200127651596\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.12292711036609112\n",
      "Average test loss:  0.54784788775006\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.11105254883646777\n",
      "Average test loss:  0.5531175835040933\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.10071618294138839\n",
      "Average test loss:  0.5590558444043682\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09168937647098778\n",
      "Average test loss:  0.5655981071849304\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.0837618932301396\n",
      "Average test loss:  0.5729715555030293\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.07677118376831966\n",
      "Average test loss:  0.5810400339138905\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.07058234273991432\n",
      "Average test loss:  0.5891937192682413\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.06508185731742062\n",
      "Average test loss:  0.597993587304187\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.06018813578948712\n",
      "Average test loss:  0.6069260061447315\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.0558152034700932\n",
      "Average test loss:  0.615798824178156\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.05190894096457951\n",
      "Average test loss:  0.6250383889768734\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.048390146855502865\n",
      "Average test loss:  0.6343730471409089\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6990970255758767\n",
      "Average test loss:  0.7002355659105358\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.689405508250288\n",
      "Average test loss:  0.6922511703176882\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.6851957878933814\n",
      "Average test loss:  0.69040387925241\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.88125\n",
      "Average test accuracy:  0.6775\n",
      "\n",
      "Average train loss:  0.6794737661901166\n",
      "Average test loss:  0.6883885132272146\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.8875\n",
      "Average test accuracy:  0.67875\n",
      "\n",
      "Average train loss:  0.6693532489620121\n",
      "Average test loss:  0.6848223333445459\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.915625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.6510589909548999\n",
      "Average test loss:  0.6783056400458275\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.93125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.61970740920991\n",
      "Average test loss:  0.6670591788213939\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.571911128981672\n",
      "Average test loss:  0.6498179538683858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.5102948163563066\n",
      "Average test loss:  0.6275985247832094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.4428319454013608\n",
      "Average test loss:  0.6035863500067061\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.37806772744363487\n",
      "Average test loss:  0.5814151269186599\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.96625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.32098544569379744\n",
      "Average test loss:  0.5631959336229976\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.27298408163195126\n",
      "Average test loss:  0.5495885940611248\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2334546605909448\n",
      "Average test loss:  0.5405481111598168\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.20105958623632567\n",
      "Average test loss:  0.535361330708383\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.17445905743817583\n",
      "Average test loss:  0.5331258795306678\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.152484301407454\n",
      "Average test loss:  0.5336933499108433\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13420668965489033\n",
      "Average test loss:  0.5363067364649851\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.11888553534460507\n",
      "Average test loss:  0.5404626628934115\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.10593574991127154\n",
      "Average test loss:  0.5461823737434545\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.09489721257900667\n",
      "Average test loss:  0.5529092965328662\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.08544205478439271\n",
      "Average test loss:  0.5606997181645352\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07726524751578956\n",
      "Average test loss:  0.5690595391028113\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.07016509774092312\n",
      "Average test loss:  0.5780438816770518\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.06395492243085986\n",
      "Average test loss:  0.587451740785337\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.058499813665619425\n",
      "Average test loss:  0.597263926870896\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.05368568820783854\n",
      "Average test loss:  0.6074219139128916\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04942735624516447\n",
      "Average test loss:  0.6177306357492679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.04563581980789825\n",
      "Average test loss:  0.6281541404477611\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.04225779888029099\n",
      "Average test loss:  0.6385707192709594\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6918445345141816\n",
      "Average test loss:  0.6926966211142854\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.6675\n",
      "Average test accuracy:  0.51125\n",
      "\n",
      "Average train loss:  0.6889437882769563\n",
      "Average test loss:  0.6917002961216148\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.765\n",
      "Average test accuracy:  0.545\n",
      "\n",
      "Average train loss:  0.6821000073696074\n",
      "Average test loss:  0.6893786253997228\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.893125\n",
      "Average test accuracy:  0.6625\n",
      "\n",
      "Average train loss:  0.6682688167054028\n",
      "Average test loss:  0.6846309410495103\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.916875\n",
      "Average test accuracy:  0.70375\n",
      "\n",
      "Average train loss:  0.6429710285309925\n",
      "Average test loss:  0.6759983060185397\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.6010066195744731\n",
      "Average test loss:  0.6614342089866709\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.5402209349171236\n",
      "Average test loss:  0.6403678822166038\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.46704754975198903\n",
      "Average test loss:  0.6152701954917852\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.39364671287295794\n",
      "Average test loss:  0.590517597645031\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.958125\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.32832049158353854\n",
      "Average test loss:  0.5699724822004916\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.27399953928886916\n",
      "Average test loss:  0.5546001615338616\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.23017199113765033\n",
      "Average test loss:  0.5447377616831804\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1951008047816387\n",
      "Average test loss:  0.5393543172690173\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.16690102639682733\n",
      "Average test loss:  0.537406693626208\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.14403348018877044\n",
      "Average test loss:  0.5380048508867019\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.12531936595042464\n",
      "Average test loss:  0.5412516496558729\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.10986955498980182\n",
      "Average test loss:  0.546422158798182\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.09697889523013105\n",
      "Average test loss:  0.5528356059478224\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.08612462057862615\n",
      "Average test loss:  0.560640035318746\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.07691529020222759\n",
      "Average test loss:  0.5694571010793208\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06905170508122098\n",
      "Average test loss:  0.5787527927039251\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.06227520765343129\n",
      "Average test loss:  0.5889068774308565\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.056415305456207376\n",
      "Average test loss:  0.5992657091435999\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.051320930439738455\n",
      "Average test loss:  0.6101737013515016\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.04686204191786747\n",
      "Average test loss:  0.6207533361930812\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.04295078784522984\n",
      "Average test loss:  0.6323144589068858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.03949186522328221\n",
      "Average test loss:  0.6435022448585611\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.03642820447823579\n",
      "Average test loss:  0.6549492091461674\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.033692559127882715\n",
      "Average test loss:  0.6663914255014699\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.03124273818490068\n",
      "Average test loss:  0.6777326433273521\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.769375\n",
      "Average test accuracy:  0.55875\n",
      "\n",
      "Average train loss:  0.692133956899204\n",
      "Average test loss:  0.6927941982269417\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.925\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.6898169166558082\n",
      "Average test loss:  0.691992729293038\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.929375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.6839923510451255\n",
      "Average test loss:  0.6899824905825728\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.6712298977862452\n",
      "Average test loss:  0.6855546426323039\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.645569966568775\n",
      "Average test loss:  0.6765495352106187\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.6003571390452239\n",
      "Average test loss:  0.6605869987884484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5333288332219727\n",
      "Average test loss:  0.636794195714084\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.4541103156936434\n",
      "Average test loss:  0.6091920246734697\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.3769322819732033\n",
      "Average test loss:  0.5831074817829359\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3099371448585546\n",
      "Average test loss:  0.5625418054568979\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.2555374449566536\n",
      "Average test loss:  0.5482963184766413\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.21250661644020918\n",
      "Average test loss:  0.5398277740101369\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.17860931420703718\n",
      "Average test loss:  0.5361593266745082\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1517356518758805\n",
      "Average test loss:  0.5362930073281843\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.13018018135219833\n",
      "Average test loss:  0.5390959685317509\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.11271991755496054\n",
      "Average test loss:  0.544283923572383\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.09841553582769014\n",
      "Average test loss:  0.5513912385765876\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08658307722539227\n",
      "Average test loss:  0.5597155218875499\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07667340751407871\n",
      "Average test loss:  0.5695312150943693\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06831493844571505\n",
      "Average test loss:  0.5797919035923841\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06119563676724064\n",
      "Average test loss:  0.5906935495973376\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.055100865058372306\n",
      "Average test loss:  0.6022508510068594\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.04983397782281218\n",
      "Average test loss:  0.6139480173920924\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.045262380747296466\n",
      "Average test loss:  0.6259967938345605\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.041260383037496386\n",
      "Average test loss:  0.6383294611759057\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.03774430859696105\n",
      "Average test loss:  0.6508817508829333\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.03463501076266826\n",
      "Average test loss:  0.6630852201223111\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.031875452743986274\n",
      "Average test loss:  0.6756486153489476\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.02941174999901118\n",
      "Average test loss:  0.6881024285307532\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.02721083469299142\n",
      "Average test loss:  0.7007420413823476\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.692980732489812\n",
      "Average test loss:  0.6937196964012599\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.8775\n",
      "Average test accuracy:  0.69125\n",
      "\n",
      "Average train loss:  0.6900398574315743\n",
      "Average test loss:  0.6920713913275641\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.676875\n",
      "Average test accuracy:  0.55125\n",
      "\n",
      "Average train loss:  0.6868749000023548\n",
      "Average test loss:  0.6909770866572389\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.723125\n",
      "Average test accuracy:  0.56375\n",
      "\n",
      "Average train loss:  0.6812390745393415\n",
      "Average test loss:  0.6890157721546405\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.81125\n",
      "Average test accuracy:  0.6175\n",
      "\n",
      "Average train loss:  0.6709023681297889\n",
      "Average test loss:  0.6853864521983493\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.869375\n",
      "Average test accuracy:  0.6675\n",
      "\n",
      "Average train loss:  0.6515029122245043\n",
      "Average test loss:  0.6785100421571834\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9225\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.6167251886728752\n",
      "Average test loss:  0.6659604812948164\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.940625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.5620473042689565\n",
      "Average test loss:  0.6462132897195275\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.4924078227958442\n",
      "Average test loss:  0.6212393198093702\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.4188932586967138\n",
      "Average test loss:  0.5956403539296639\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.3511975229168389\n",
      "Average test loss:  0.5734931941047757\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.29359419259391034\n",
      "Average test loss:  0.5566292663741431\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2463820602161546\n",
      "Average test loss:  0.5452883876299026\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.20827630427992516\n",
      "Average test loss:  0.5386369877221694\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1775822794966836\n",
      "Average test loss:  0.5358208477172112\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.15273393519220826\n",
      "Average test loss:  0.536049366706456\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13245399068270677\n",
      "Average test loss:  0.5388956838129201\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.11576511164529805\n",
      "Average test loss:  0.5438504274747692\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10189921934315672\n",
      "Average test loss:  0.5503728834451288\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.09027321600820354\n",
      "Average test loss:  0.5578170361173304\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08045574793709032\n",
      "Average test loss:  0.5666659867716715\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07209165236165056\n",
      "Average test loss:  0.5761305762886663\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.06491228587963958\n",
      "Average test loss:  0.586190403345442\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.058703341396581094\n",
      "Average test loss:  0.5969017007846968\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.053309309539179915\n",
      "Average test loss:  0.607773319089148\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.048598064525578126\n",
      "Average test loss:  0.6188650775085486\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.044455985964157424\n",
      "Average test loss:  0.6304728382083263\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.04079312829824754\n",
      "Average test loss:  0.6420672257015775\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.0375408265869649\n",
      "Average test loss:  0.6536569389295717\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.03463777593431328\n",
      "Average test loss:  0.6654363263450227\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6921269213218696\n",
      "Average test loss:  0.6931937519588338\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.654375\n",
      "Average test accuracy:  0.5475\n",
      "\n",
      "Average train loss:  0.6884462747574375\n",
      "Average test loss:  0.691524648751901\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.719375\n",
      "Average test accuracy:  0.56875\n",
      "\n",
      "Average train loss:  0.6826829437638934\n",
      "Average test loss:  0.6895333649308579\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.87625\n",
      "Average test accuracy:  0.67875\n",
      "\n",
      "Average train loss:  0.671216437447952\n",
      "Average test loss:  0.6855129838852702\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.904375\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.6495897749473747\n",
      "Average test loss:  0.6779112255429088\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.6113116059131661\n",
      "Average test loss:  0.6643354276321219\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.5507172998374957\n",
      "Average test loss:  0.6428203873567703\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.4711840384815909\n",
      "Average test loss:  0.6148898708243009\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3875697207371594\n",
      "Average test loss:  0.5866950722194874\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.3133643067613362\n",
      "Average test loss:  0.5638688064734007\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.966875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.25348149794102887\n",
      "Average test loss:  0.5482372374229061\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.20714225506278747\n",
      "Average test loss:  0.5396820005026809\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.17150086767090253\n",
      "Average test loss:  0.5363763603067682\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.14388269119155506\n",
      "Average test loss:  0.5377200176770303\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.12217944297166193\n",
      "Average test loss:  0.5418480450618678\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.10489777941397443\n",
      "Average test loss:  0.5482694365493911\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09093606344902716\n",
      "Average test loss:  0.5569507835224244\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07951364616690336\n",
      "Average test loss:  0.5667683743065554\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07005670757540124\n",
      "Average test loss:  0.5777153335901898\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06213574849441688\n",
      "Average test loss:  0.5891943372905645\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.05544399570631491\n",
      "Average test loss:  0.6012724373460744\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.049739466950639626\n",
      "Average test loss:  0.6141448369142201\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.04484032678555216\n",
      "Average test loss:  0.6270486674322261\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.04059977957689967\n",
      "Average test loss:  0.6400837906274988\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.036904682095223205\n",
      "Average test loss:  0.6534070413764117\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.03367580275934945\n",
      "Average test loss:  0.6670208125610539\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.030826515722794125\n",
      "Average test loss:  0.6801872760436529\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.02830012408553643\n",
      "Average test loss:  0.6936206629261367\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.02605596118991921\n",
      "Average test loss:  0.7068928817813053\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.024049627851834107\n",
      "Average test loss:  0.7204317227505431\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6983591276490478\n",
      "Average test loss:  0.6989767055657164\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.50625\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6897232002318526\n",
      "Average test loss:  0.6919927929365123\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.620625\n",
      "Average test accuracy:  0.53125\n",
      "\n",
      "Average train loss:  0.6858701097878533\n",
      "Average test loss:  0.6906412786726954\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.701875\n",
      "Average test accuracy:  0.5525\n",
      "\n",
      "Average train loss:  0.6793461322039461\n",
      "Average test loss:  0.6883788005510872\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.8075\n",
      "Average test accuracy:  0.61625\n",
      "\n",
      "Average train loss:  0.6677899091239666\n",
      "Average test loss:  0.6843262764790436\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.881875\n",
      "Average test accuracy:  0.67375\n",
      "\n",
      "Average train loss:  0.6477692678310989\n",
      "Average test loss:  0.6772132549966039\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.914375\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.6145555103738106\n",
      "Average test loss:  0.6652885972294614\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.5650506899964342\n",
      "Average test loss:  0.6474195491572498\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5013229563238263\n",
      "Average test loss:  0.624537479739654\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.43067128922546144\n",
      "Average test loss:  0.5998238924845191\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3621392915693751\n",
      "Average test loss:  0.5771184518591359\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.30191393127098615\n",
      "Average test loss:  0.5591840212273556\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.2518402625256591\n",
      "Average test loss:  0.5466519499639526\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.21128639821136286\n",
      "Average test loss:  0.5391299005470781\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.17877360220542027\n",
      "Average test loss:  0.5359617824656515\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1526419886502932\n",
      "Average test loss:  0.5361625506145778\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.13150696216432523\n",
      "Average test loss:  0.539381946281348\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.11426427723212897\n",
      "Average test loss:  0.5443901104374517\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.10005783862610497\n",
      "Average test loss:  0.5513898600486823\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.08824797954063131\n",
      "Average test loss:  0.559643899150498\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.07832433729958317\n",
      "Average test loss:  0.5687852054548321\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.06992415238930404\n",
      "Average test loss:  0.578784643558197\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.06275794565191198\n",
      "Average test loss:  0.589381766932297\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.05659150111913783\n",
      "Average test loss:  0.6004755634467908\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.051256580078129686\n",
      "Average test loss:  0.6121674687669328\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.04660194866139659\n",
      "Average test loss:  0.6239465925760198\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.04252817931432095\n",
      "Average test loss:  0.6359830571102991\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.03893459591356004\n",
      "Average test loss:  0.6479542638942928\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.035755324401244244\n",
      "Average test loss:  0.6601956497200826\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.032932306795535556\n",
      "Average test loss:  0.6726133408057131\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6922373466932004\n",
      "Average test loss:  0.6928391995455213\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.715\n",
      "Average test accuracy:  0.51375\n",
      "\n",
      "Average train loss:  0.6906280830204835\n",
      "Average test loss:  0.6922845601530437\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.936875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6866730056139717\n",
      "Average test loss:  0.690907911442013\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6760117702238896\n",
      "Average test loss:  0.6871997179781615\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6476687241111924\n",
      "Average test loss:  0.6772686437783694\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5838106189852666\n",
      "Average test loss:  0.654826948511329\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.48305870991598354\n",
      "Average test loss:  0.6196533229437075\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.37574145415245747\n",
      "Average test loss:  0.5840623885332573\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.28838989126097775\n",
      "Average test loss:  0.5578849994476771\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.22467242192037232\n",
      "Average test loss:  0.5429814274515841\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.17885168162624418\n",
      "Average test loss:  0.5375568990464996\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1454035791293249\n",
      "Average test loss:  0.5381060665737349\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.12036683631290224\n",
      "Average test loss:  0.5431568686731886\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.10119942969800978\n",
      "Average test loss:  0.5512679231919199\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08621339216528563\n",
      "Average test loss:  0.5613497889865782\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.07426988044513187\n",
      "Average test loss:  0.5726630738771522\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06463475529297678\n",
      "Average test loss:  0.5858579366549233\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.05670673244739812\n",
      "Average test loss:  0.5993325084029141\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.050139175990440855\n",
      "Average test loss:  0.6140849538717239\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04461684196940477\n",
      "Average test loss:  0.6285078620046646\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.03994406995829266\n",
      "Average test loss:  0.6433865943255075\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.03595824136167972\n",
      "Average test loss:  0.6584015191179393\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.03251573566663646\n",
      "Average test loss:  0.6731301785774004\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.02952320979101238\n",
      "Average test loss:  0.6882464612351634\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.026910818942625512\n",
      "Average test loss:  0.703238339418931\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.024606379995431\n",
      "Average test loss:  0.7178546680970855\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.02256162888997117\n",
      "Average test loss:  0.7329525149476246\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.020752396950828856\n",
      "Average test loss:  0.7472525161058464\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.01913233927303251\n",
      "Average test loss:  0.7618294071261106\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  5\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.017700153158125443\n",
      "Average test loss:  0.7760883189697534\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5225\n",
      "Average test accuracy:  0.50375\n",
      "\n",
      "Average train loss:  0.6914079089558139\n",
      "Average test loss:  0.6925414482971094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.928125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.6886799214404896\n",
      "Average test loss:  0.6915971732427665\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.8975\n",
      "Average test accuracy:  0.67875\n",
      "\n",
      "Average train loss:  0.6833363031875012\n",
      "Average test loss:  0.68976326801532\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.888125\n",
      "Average test accuracy:  0.65375\n",
      "\n",
      "Average train loss:  0.6729031290905764\n",
      "Average test loss:  0.6862014325429886\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.881875\n",
      "Average test accuracy:  0.64125\n",
      "\n",
      "Average train loss:  0.6545306637830297\n",
      "Average test loss:  0.6799702733270726\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.889375\n",
      "Average test accuracy:  0.65375\n",
      "\n",
      "Average train loss:  0.6264137816679395\n",
      "Average test loss:  0.670477926707656\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.901875\n",
      "Average test accuracy:  0.67625\n",
      "\n",
      "Average train loss:  0.5893806130754787\n",
      "Average test loss:  0.657968925022178\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.92375\n",
      "Average test accuracy:  0.705\n",
      "\n",
      "Average train loss:  0.5465306668879819\n",
      "Average test loss:  0.6434238375139132\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.5018502615155017\n",
      "Average test loss:  0.6280140104322598\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.45850192045057847\n",
      "Average test loss:  0.6129553891358176\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.41810965654797866\n",
      "Average test loss:  0.5991319907793925\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.38133220289977615\n",
      "Average test loss:  0.5869427294439858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3482846265403767\n",
      "Average test loss:  0.5762312544728639\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.31881870199567125\n",
      "Average test loss:  0.5672063558608149\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2925849977758073\n",
      "Average test loss:  0.5602837528101094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2692025928771884\n",
      "Average test loss:  0.5545133370775926\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.9825\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.24835624852847127\n",
      "Average test loss:  0.5502232403300104\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2296963534438918\n",
      "Average test loss:  0.5469231434288064\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.21295623903641167\n",
      "Average test loss:  0.544894791917094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.19789661024510383\n",
      "Average test loss:  0.5442394283262101\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.18429668858397916\n",
      "Average test loss:  0.5441498870933322\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.1719904758086337\n",
      "Average test loss:  0.5448682099594366\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.16081957534009098\n",
      "Average test loss:  0.5464263213001055\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.15064956941753044\n",
      "Average test loss:  0.5484350163784494\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.14136487235260076\n",
      "Average test loss:  0.5512881118415924\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.13286377028053245\n",
      "Average test loss:  0.5546817921716997\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.12506251866854864\n",
      "Average test loss:  0.5582652942117862\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.1178790209402309\n",
      "Average test loss:  0.5623764780532718\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.11126143788051997\n",
      "Average test loss:  0.5669271971076579\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.10515588157492499\n",
      "Average test loss:  0.5715624425251221\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6932536666401895\n",
      "Average test loss:  0.6941871040218494\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6895272911606186\n",
      "Average test loss:  0.6919439120365913\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.926875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6852161538678359\n",
      "Average test loss:  0.6903942564382399\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.676794405872993\n",
      "Average test loss:  0.6874470733417485\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.6601067364847873\n",
      "Average test loss:  0.6815787397905666\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.6293762371632287\n",
      "Average test loss:  0.6707636004981664\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.5818477734580809\n",
      "Average test loss:  0.6540856235635545\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.5226682625411385\n",
      "Average test loss:  0.6332010967826841\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.4605752152593306\n",
      "Average test loss:  0.6114736729849587\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.40239988442852637\n",
      "Average test loss:  0.5915161649529361\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.3510858034410262\n",
      "Average test loss:  0.5748202568941532\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3070836901677675\n",
      "Average test loss:  0.5613224349330524\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2698582051712131\n",
      "Average test loss:  0.5513438259924267\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.23839994920025942\n",
      "Average test loss:  0.5442145974193449\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2117571095525972\n",
      "Average test loss:  0.5396700704736795\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.18907533057163525\n",
      "Average test loss:  0.5371043979040829\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.16966437590166072\n",
      "Average test loss:  0.5367521169066948\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.15295256963672582\n",
      "Average test loss:  0.5377610249020407\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.13847573506123587\n",
      "Average test loss:  0.5401866296287859\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1258609260604253\n",
      "Average test loss:  0.5436466852581184\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.11481978269197059\n",
      "Average test loss:  0.548127860239268\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.10510876392665841\n",
      "Average test loss:  0.5534291982393175\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09652572744853698\n",
      "Average test loss:  0.5593989349636223\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08891079242967782\n",
      "Average test loss:  0.5660748329831616\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.08211672900293658\n",
      "Average test loss:  0.5729566682680338\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.076048581512752\n",
      "Average test loss:  0.5802998450817705\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.07060284469656142\n",
      "Average test loss:  0.5880922786328644\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.0657097715291552\n",
      "Average test loss:  0.5962824325254448\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06129871674314033\n",
      "Average test loss:  0.6043575394175311\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.05732026174973078\n",
      "Average test loss:  0.6127480314600064\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6963996134983231\n",
      "Average test loss:  0.6971495002457098\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6907021844733189\n",
      "Average test loss:  0.6925444081783055\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.908125\n",
      "Average test accuracy:  0.65875\n",
      "\n",
      "Average train loss:  0.6871158883964229\n",
      "Average test loss:  0.691076613373807\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.920625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.6804277560475028\n",
      "Average test loss:  0.688739391022084\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.92375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6665206673833396\n",
      "Average test loss:  0.6838657501393719\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6390085456520155\n",
      "Average test loss:  0.6741431296002603\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5918922318333962\n",
      "Average test loss:  0.6573141390784384\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.5269483735552688\n",
      "Average test loss:  0.6340982750979957\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.45481277212503807\n",
      "Average test loss:  0.60853259256958\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.386667702913603\n",
      "Average test loss:  0.5852441219529575\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3278967852862124\n",
      "Average test loss:  0.5661590311557787\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.27925807282883164\n",
      "Average test loss:  0.5524535391570696\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.23953381594971782\n",
      "Average test loss:  0.5430331746869719\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.20713173321863695\n",
      "Average test loss:  0.5371945144232378\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.18052504450815712\n",
      "Average test loss:  0.5345843399413567\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.15848718578846868\n",
      "Average test loss:  0.5346449615208004\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.14009620735662812\n",
      "Average test loss:  0.5367040446631833\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.12459567847904014\n",
      "Average test loss:  0.5403555842289592\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.11144437614515675\n",
      "Average test loss:  0.5454525125262857\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.10018516878637627\n",
      "Average test loss:  0.5517530912749061\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.09048814534163126\n",
      "Average test loss:  0.5590317463281815\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.08208103810948798\n",
      "Average test loss:  0.5665982173616939\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07475448118820761\n",
      "Average test loss:  0.5749072787011028\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.06832953773104375\n",
      "Average test loss:  0.583829936422784\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.06267533100707501\n",
      "Average test loss:  0.5932272663637933\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.05767869955198407\n",
      "Average test loss:  0.6027995026261692\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.053249039598604796\n",
      "Average test loss:  0.61258744848179\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.04930295594010945\n",
      "Average test loss:  0.6225776493728883\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.045785137470391084\n",
      "Average test loss:  0.6324216792904066\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.042636015538976335\n",
      "Average test loss:  0.6424955596317834\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6996146716658833\n",
      "Average test loss:  0.7003890676903856\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6897769629914042\n",
      "Average test loss:  0.6922222691751934\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.92375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6850021690264759\n",
      "Average test loss:  0.6902781609253297\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.845625\n",
      "Average test accuracy:  0.60625\n",
      "\n",
      "Average train loss:  0.6775510610589416\n",
      "Average test loss:  0.687778401152085\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.889375\n",
      "Average test accuracy:  0.655\n",
      "\n",
      "Average train loss:  0.6641930715500015\n",
      "Average test loss:  0.683244864612916\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.91375\n",
      "Average test accuracy:  0.6975\n",
      "\n",
      "Average train loss:  0.6410942795116241\n",
      "Average test loss:  0.6753696644492888\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.930625\n",
      "Average test accuracy:  0.71375\n",
      "\n",
      "Average train loss:  0.6037796036405074\n",
      "Average test loss:  0.6625981590633444\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.938125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.550276407526077\n",
      "Average test loss:  0.6441606322003669\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.48516393002961583\n",
      "Average test loss:  0.6215223419109613\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.4172020171068101\n",
      "Average test loss:  0.598418424909602\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.35406596539396423\n",
      "Average test loss:  0.5776153272879466\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.29951901087100824\n",
      "Average test loss:  0.5612650672976919\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.2542102868082194\n",
      "Average test loss:  0.5493499268075704\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2171468334655754\n",
      "Average test loss:  0.5419088962543759\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.18688671328318543\n",
      "Average test loss:  0.5382009795480726\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1620772811051573\n",
      "Average test loss:  0.5370011158964965\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.9825\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.14161136140656608\n",
      "Average test loss:  0.5386159225516046\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.12459207414132188\n",
      "Average test loss:  0.5416921181144615\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.1103176414042919\n",
      "Average test loss:  0.5467765161342634\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.09823959663034916\n",
      "Average test loss:  0.5531461861157521\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.08794365277243232\n",
      "Average test loss:  0.5601796002867871\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07911628259374087\n",
      "Average test loss:  0.5681086330844058\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.07149138497870895\n",
      "Average test loss:  0.5771416862551185\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.06486396746233741\n",
      "Average test loss:  0.5866083907607171\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.05908882568209656\n",
      "Average test loss:  0.5963551304459961\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.054027176282913175\n",
      "Average test loss:  0.6061262119355896\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04957959828803726\n",
      "Average test loss:  0.6163063028571644\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04564830895783605\n",
      "Average test loss:  0.6266880778540131\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.042165584007153735\n",
      "Average test loss:  0.6371271061137179\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.03906812738214891\n",
      "Average test loss:  0.6475330503189177\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6918167103862122\n",
      "Average test loss:  0.6927432509652989\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.75375\n",
      "Average test accuracy:  0.55\n",
      "\n",
      "Average train loss:  0.6892028580907158\n",
      "Average test loss:  0.691771861635726\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.835\n",
      "Average test accuracy:  0.5875\n",
      "\n",
      "Average train loss:  0.6837530602770155\n",
      "Average test loss:  0.6899122606567337\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.879375\n",
      "Average test accuracy:  0.62625\n",
      "\n",
      "Average train loss:  0.6711176722305021\n",
      "Average test loss:  0.6856207102930557\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.898125\n",
      "Average test accuracy:  0.67\n",
      "\n",
      "Average train loss:  0.6430211111403513\n",
      "Average test loss:  0.676116938340301\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9275\n",
      "Average test accuracy:  0.70875\n",
      "\n",
      "Average train loss:  0.5898807311967144\n",
      "Average test loss:  0.6580275860434766\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.5137216111384003\n",
      "Average test loss:  0.6320458118806146\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.4294960413834388\n",
      "Average test loss:  0.6035682768048244\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3526171440065835\n",
      "Average test loss:  0.5788143161018411\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.75875\n",
      "\n",
      "Average train loss:  0.2893675145613085\n",
      "Average test loss:  0.5607263359480306\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.23934589115094793\n",
      "Average test loss:  0.5486315506212822\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.20013460125140195\n",
      "Average test loss:  0.5424090608579638\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.16928295787711697\n",
      "Average test loss:  0.5400350656752538\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.14473557788387012\n",
      "Average test loss:  0.5414453743568295\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.12494000500602907\n",
      "Average test loss:  0.545430015794706\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.10879326882019498\n",
      "Average test loss:  0.5513198606735742\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09547500470180809\n",
      "Average test loss:  0.5587373112045825\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08437571008442157\n",
      "Average test loss:  0.5673037421998427\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.07504435199452361\n",
      "Average test loss:  0.5770992675737782\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06712160053286316\n",
      "Average test loss:  0.5873645506165999\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06036706859933532\n",
      "Average test loss:  0.5980226820165103\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.05457928462286956\n",
      "Average test loss:  0.6095126060267796\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.049571676635969925\n",
      "Average test loss:  0.6210521307155091\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.045233703005404025\n",
      "Average test loss:  0.6330041852967976\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.04144836042989588\n",
      "Average test loss:  0.6444460443515688\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.03812558154251706\n",
      "Average test loss:  0.656176925780231\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.03520723074405877\n",
      "Average test loss:  0.6680293520438778\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.03261414535980648\n",
      "Average test loss:  0.6799625158018424\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.030301298094808055\n",
      "Average test loss:  0.6915531308131889\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.028220013498559907\n",
      "Average test loss:  0.7032094967367518\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7199897587990577\n",
      "Average test loss:  0.7211405417198941\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6936559462592994\n",
      "Average test loss:  0.6964832630704079\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6853608083526818\n",
      "Average test loss:  0.6906184690010675\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.915625\n",
      "Average test accuracy:  0.71125\n",
      "\n",
      "Average train loss:  0.6793534489598904\n",
      "Average test loss:  0.6882196096554273\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.92625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.670584781634433\n",
      "Average test loss:  0.6851966223201877\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6558137218229185\n",
      "Average test loss:  0.6800824986884147\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.94375\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.6298732344611628\n",
      "Average test loss:  0.6710066473174652\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.5855988898814303\n",
      "Average test loss:  0.6553133873987712\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.5209224352793181\n",
      "Average test loss:  0.6320459811901836\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.4450123080871953\n",
      "Average test loss:  0.6048659860839932\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.37098776693628793\n",
      "Average test loss:  0.5790726543525578\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.30702890583189885\n",
      "Average test loss:  0.5584533396959248\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.25506798456396307\n",
      "Average test loss:  0.5439530469106743\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.2137649623203345\n",
      "Average test loss:  0.5350273387680532\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.18101579277989233\n",
      "Average test loss:  0.530810469844977\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.15485930335058676\n",
      "Average test loss:  0.5304330937030964\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13374231607803125\n",
      "Average test loss:  0.5328774263829225\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.11651641823662033\n",
      "Average test loss:  0.5371570817583817\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.10230624383621074\n",
      "Average test loss:  0.5439578793771127\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.09046837760592302\n",
      "Average test loss:  0.5513013887227868\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.08050226238646814\n",
      "Average test loss:  0.5602982904615451\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.07204248979649468\n",
      "Average test loss:  0.5700257103441494\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.715\n",
      "\n",
      "Average train loss:  0.06479253368550598\n",
      "Average test loss:  0.5804612132169897\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.715\n",
      "\n",
      "Average train loss:  0.05853393408466412\n",
      "Average test loss:  0.5914374315030992\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.053094517592980596\n",
      "Average test loss:  0.6027645491612985\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.71125\n",
      "\n",
      "Average train loss:  0.04834238964037385\n",
      "Average test loss:  0.6142738253573369\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.715\n",
      "\n",
      "Average train loss:  0.04415623829830063\n",
      "Average test loss:  0.6260070619996335\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.04046892670807549\n",
      "Average test loss:  0.6379612508667628\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.037202443432802684\n",
      "Average test loss:  0.6501729535930916\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.0343058082580519\n",
      "Average test loss:  0.6619906157783827\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.695900613523127\n",
      "Average test loss:  0.6968103832441624\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6898746812555432\n",
      "Average test loss:  0.6920678889327515\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.93375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6860957664894421\n",
      "Average test loss:  0.6907157742441731\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6778671994827526\n",
      "Average test loss:  0.6878402901370079\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6592544758552611\n",
      "Average test loss:  0.6813172223251779\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9475\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.6202074492759292\n",
      "Average test loss:  0.667558245249748\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9475\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.5514004457848364\n",
      "Average test loss:  0.6433760466197515\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.4597478046809085\n",
      "Average test loss:  0.6114789939082761\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.3682810121285161\n",
      "Average test loss:  0.5809617837277803\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.292371386233705\n",
      "Average test loss:  0.5582382780259921\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.23430269161141157\n",
      "Average test loss:  0.544565887469775\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.19068998875050625\n",
      "Average test loss:  0.5377729317909448\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.15765480158031409\n",
      "Average test loss:  0.5364912649184403\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1322448094722661\n",
      "Average test loss:  0.5395216980649952\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.11237842056386803\n",
      "Average test loss:  0.5453232409031838\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09656571169984973\n",
      "Average test loss:  0.5535528199172645\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08380152196482726\n",
      "Average test loss:  0.5630090493144211\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07334187087341809\n",
      "Average test loss:  0.5740719652498777\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06468531573638836\n",
      "Average test loss:  0.58583656936354\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.05744172571679138\n",
      "Average test loss:  0.5981577094360039\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.05133841408430262\n",
      "Average test loss:  0.6110428626460762\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.04613809473475772\n",
      "Average test loss:  0.6243296268690436\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.04169365288764803\n",
      "Average test loss:  0.6377221077846723\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.03785312032543051\n",
      "Average test loss:  0.6512194337404358\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.034519795366339846\n",
      "Average test loss:  0.66459749421209\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.03159650005690943\n",
      "Average test loss:  0.6780428986105099\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.029008496732677993\n",
      "Average test loss:  0.6911625441721018\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.02669887389792758\n",
      "Average test loss:  0.7046344009282537\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.024616483523390548\n",
      "Average test loss:  0.7179287646700366\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.022740527938489297\n",
      "Average test loss:  0.7311779103461497\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6920253672860412\n",
      "Average test loss:  0.6928200038858435\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.875\n",
      "Average test accuracy:  0.68625\n",
      "\n",
      "Average train loss:  0.6897485703279015\n",
      "Average test loss:  0.6919563119370489\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.6841038050452477\n",
      "Average test loss:  0.6900066932672235\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6689247942413576\n",
      "Average test loss:  0.6847367171944042\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.6318538181291125\n",
      "Average test loss:  0.6718471637136054\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.94125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5584036541864555\n",
      "Average test loss:  0.6462991916380926\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.45652068019754516\n",
      "Average test loss:  0.6112158397937616\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3569593880603798\n",
      "Average test loss:  0.5788805401459943\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.2778264859468702\n",
      "Average test loss:  0.556029680340202\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.21946637096823626\n",
      "Average test loss:  0.5434788907454617\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.17676560446687176\n",
      "Average test loss:  0.5388575473895557\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1450197278953088\n",
      "Average test loss:  0.5397237831699832\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9825\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.12091043911534383\n",
      "Average test loss:  0.5444102783259377\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.1022205817104591\n",
      "Average test loss:  0.5518704969803979\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.0874602160708668\n",
      "Average test loss:  0.5615966786726712\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.07560435563244929\n",
      "Average test loss:  0.5729593785362641\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0659690864338779\n",
      "Average test loss:  0.5853400416145176\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.05803199982740437\n",
      "Average test loss:  0.5983175660433195\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.05141382454199766\n",
      "Average test loss:  0.6124543917829948\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.045849728130832\n",
      "Average test loss:  0.6261999231915945\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04113385275868511\n",
      "Average test loss:  0.6406129476337978\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.03709683714610456\n",
      "Average test loss:  0.6551389519952058\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.03360867238833599\n",
      "Average test loss:  0.6693428137852515\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.03056604885467597\n",
      "Average test loss:  0.6837226162762119\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.027890583684648\n",
      "Average test loss:  0.6979330773987864\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.02551578583811262\n",
      "Average test loss:  0.7125869904978818\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.02339884099790172\n",
      "Average test loss:  0.7268669190148133\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.021516754926041007\n",
      "Average test loss:  0.7405443008925654\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.019843773093454555\n",
      "Average test loss:  0.7548701829724344\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.018365445331963885\n",
      "Average test loss:  0.7681981276438771\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6953554627873727\n",
      "Average test loss:  0.6966225717307056\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.76125\n",
      "Average test accuracy:  0.57375\n",
      "\n",
      "Average train loss:  0.6876048127938041\n",
      "Average test loss:  0.6911669604740996\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.860625\n",
      "Average test accuracy:  0.65375\n",
      "\n",
      "Average train loss:  0.6822888388815608\n",
      "Average test loss:  0.6893469073107656\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.8925\n",
      "Average test accuracy:  0.67875\n",
      "\n",
      "Average train loss:  0.6729082565894012\n",
      "Average test loss:  0.6861483038465673\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.919375\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.6555950917710269\n",
      "Average test loss:  0.6802215603172524\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.623971429322758\n",
      "Average test loss:  0.6693409601096314\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5699751954721795\n",
      "Average test loss:  0.650573519304333\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.945625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.4918832336783289\n",
      "Average test loss:  0.6232506892512995\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.40283484472032566\n",
      "Average test loss:  0.5928252484897952\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.958125\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.3212592173895202\n",
      "Average test loss:  0.5666742248306585\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.2559917316347764\n",
      "Average test loss:  0.5490090119682534\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.2064274808306186\n",
      "Average test loss:  0.5392947978240673\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.16909858701791047\n",
      "Average test loss:  0.5353155750411318\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.14067755062190762\n",
      "Average test loss:  0.5365150340979478\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.11867623406324697\n",
      "Average test loss:  0.5411000151681132\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10133308657822071\n",
      "Average test loss:  0.5484537844982406\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08745355105468815\n",
      "Average test loss:  0.5570819285415202\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.0761822880009884\n",
      "Average test loss:  0.5681186094906567\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.066890429040578\n",
      "Average test loss:  0.5794077090635327\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.05916138791579834\n",
      "Average test loss:  0.5916891377504516\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.05267051248572389\n",
      "Average test loss:  0.6045869376241552\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.04714978179203281\n",
      "Average test loss:  0.6178026481817396\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.0424440064059974\n",
      "Average test loss:  0.6312810375136692\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.03838483506841822\n",
      "Average test loss:  0.6450830918350262\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.034879196590615676\n",
      "Average test loss:  0.6589049966749464\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.031820890102340425\n",
      "Average test loss:  0.6729357948435543\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.029143774152302824\n",
      "Average test loss:  0.6865468007564791\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.02678943141937162\n",
      "Average test loss:  0.7000434344985988\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.02470475547378644\n",
      "Average test loss:  0.7137860819153666\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.0228477906045836\n",
      "Average test loss:  0.7274409005633582\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5025\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6915995703844285\n",
      "Average test loss:  0.6926071812187112\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.866875\n",
      "Average test accuracy:  0.63375\n",
      "\n",
      "Average train loss:  0.6873639328516328\n",
      "Average test loss:  0.6911411642823159\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.91625\n",
      "Average test accuracy:  0.7075\n",
      "\n",
      "Average train loss:  0.6755541759167935\n",
      "Average test loss:  0.6870620742963128\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.929375\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.6488219510981034\n",
      "Average test loss:  0.6778363387323325\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.5953513249188882\n",
      "Average test loss:  0.6593061888959592\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.945625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.5091907774165046\n",
      "Average test loss:  0.6295695987120499\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.4064290519910149\n",
      "Average test loss:  0.5955111186227103\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.31386217216655504\n",
      "Average test loss:  0.5665176583494755\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.24282219117445794\n",
      "Average test loss:  0.5494640444029378\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.19112167473092703\n",
      "Average test loss:  0.5415698784416692\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.15346817788010902\n",
      "Average test loss:  0.5399848129742649\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1255943256042847\n",
      "Average test loss:  0.5443546438320911\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10450025921995172\n",
      "Average test loss:  0.5519894255968234\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.0882189838294808\n",
      "Average test loss:  0.5622408923539647\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.07537949721398324\n",
      "Average test loss:  0.5741968580722875\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06510671067591743\n",
      "Average test loss:  0.5876213595164376\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.05675284487797555\n",
      "Average test loss:  0.6013505021387885\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.04987778236245613\n",
      "Average test loss:  0.6164813859058719\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.044148850964295334\n",
      "Average test loss:  0.6316716512474025\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.03933986403168457\n",
      "Average test loss:  0.6471084310688108\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.03524564144341356\n",
      "Average test loss:  0.6624543067675358\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.03173523478538104\n",
      "Average test loss:  0.6785622788340904\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.028684377659557638\n",
      "Average test loss:  0.6937068021171827\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.026029852669324866\n",
      "Average test loss:  0.7092917479408491\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.023689417117100712\n",
      "Average test loss:  0.7246614462304155\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.02164200236210882\n",
      "Average test loss:  0.7397338112348898\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.019840062990286757\n",
      "Average test loss:  0.7555415345291255\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.01825653957740977\n",
      "Average test loss:  0.7701403071503515\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.0168617847393158\n",
      "Average test loss:  0.7846985408347363\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  6\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.015622507237109557\n",
      "Average test loss:  0.7994987147778194\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7335402110742875\n",
      "Average test loss:  0.7342555737091961\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7099042742331543\n",
      "Average test loss:  0.7114781505995315\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6970628222995038\n",
      "Average test loss:  0.6996641665305803\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6902828765805907\n",
      "Average test loss:  0.6941157736890112\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6857267642135456\n",
      "Average test loss:  0.6912740684435125\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6808894529686018\n",
      "Average test loss:  0.6891250922970754\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.71875\n",
      "Average test accuracy:  0.515\n",
      "\n",
      "Average train loss:  0.6735012238083491\n",
      "Average test loss:  0.6863481666390935\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.870625\n",
      "Average test accuracy:  0.62625\n",
      "\n",
      "Average train loss:  0.6606931563080977\n",
      "Average test loss:  0.6817144235250368\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.91375\n",
      "Average test accuracy:  0.7025\n",
      "\n",
      "Average train loss:  0.6398495940394283\n",
      "Average test loss:  0.6741543371266419\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.6098118340457338\n",
      "Average test loss:  0.6630882130221486\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.5711997450458518\n",
      "Average test loss:  0.6486656446675435\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5268390541711728\n",
      "Average test loss:  0.6318931250241795\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.48081703502622347\n",
      "Average test loss:  0.6145204644341388\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.43655756523424577\n",
      "Average test loss:  0.5979834719851526\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3959402537530799\n",
      "Average test loss:  0.5831897577308686\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.3596181520643517\n",
      "Average test loss:  0.5704305936803821\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3274921860521764\n",
      "Average test loss:  0.5598403567921676\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.29920490939313416\n",
      "Average test loss:  0.5514304450084836\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.27427452048697915\n",
      "Average test loss:  0.5448764926146467\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.2522440913895722\n",
      "Average test loss:  0.5399673280398899\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.23271722641105227\n",
      "Average test loss:  0.5364328701872515\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2153426076556261\n",
      "Average test loss:  0.5342755767635793\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.19982462749664767\n",
      "Average test loss:  0.5331420474109718\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.18590963358329726\n",
      "Average test loss:  0.533136454464796\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.17338630602065228\n",
      "Average test loss:  0.5338882177064598\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.16207221985857198\n",
      "Average test loss:  0.535450389180717\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.15180537341732828\n",
      "Average test loss:  0.5376545742548455\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.1424716278090877\n",
      "Average test loss:  0.5402890548517175\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.13396776927311205\n",
      "Average test loss:  0.5436991401369288\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.12620307834636155\n",
      "Average test loss:  0.5474384976883776\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6940456856720282\n",
      "Average test loss:  0.6958720390897226\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6868842011172281\n",
      "Average test loss:  0.6911443348996813\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6816050739414411\n",
      "Average test loss:  0.6891614529329123\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.91\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.67374194744378\n",
      "Average test loss:  0.6863872662900014\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.915625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.660852043043972\n",
      "Average test loss:  0.6818143503600863\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.6397017895764491\n",
      "Average test loss:  0.6742504054223261\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.607469824770131\n",
      "Average test loss:  0.6626550772857023\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.5636501239136371\n",
      "Average test loss:  0.646756843592127\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5116538625530033\n",
      "Average test loss:  0.6278718238957048\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.4569878584841061\n",
      "Average test loss:  0.6081311491262148\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.40451350594294944\n",
      "Average test loss:  0.5895350693002706\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.966875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.35685999082653524\n",
      "Average test loss:  0.5733491153604894\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.31499317731447934\n",
      "Average test loss:  0.5600292642222269\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2787849048169551\n",
      "Average test loss:  0.5495288650202723\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.2476878032273111\n",
      "Average test loss:  0.5420642404171515\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.22099566736095347\n",
      "Average test loss:  0.5367583167117675\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1980404523928517\n",
      "Average test loss:  0.5336337465349753\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.17821258088551126\n",
      "Average test loss:  0.5323232347511637\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.16103275958514074\n",
      "Average test loss:  0.5326794342554236\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.14608294375240818\n",
      "Average test loss:  0.534312914621177\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.13303171712632852\n",
      "Average test loss:  0.5371753653383903\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.12155782973228042\n",
      "Average test loss:  0.540867030729732\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.11143835309003745\n",
      "Average test loss:  0.5455179371536233\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.1024731574276977\n",
      "Average test loss:  0.5508200250860007\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09450824289127265\n",
      "Average test loss:  0.5566913988198484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08739556543992917\n",
      "Average test loss:  0.5632182046939381\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.081032666781797\n",
      "Average test loss:  0.5701380550305051\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07530904298533345\n",
      "Average test loss:  0.5775082301142515\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.07014788507247023\n",
      "Average test loss:  0.5851777487331374\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.06547052078960436\n",
      "Average test loss:  0.5930599139640375\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.915\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.6915737658731542\n",
      "Average test loss:  0.6926066240590013\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.88625\n",
      "Average test accuracy:  0.69375\n",
      "\n",
      "Average train loss:  0.6884739665589872\n",
      "Average test loss:  0.6915385387063432\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.92125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.6811604153421064\n",
      "Average test loss:  0.6890139910604294\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.92625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.6645661220008122\n",
      "Average test loss:  0.6832528143940032\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6304496941585935\n",
      "Average test loss:  0.6712872223770967\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5723958772661022\n",
      "Average test loss:  0.6506523949895899\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.4984697022952756\n",
      "Average test loss:  0.6244473659003306\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.42401317640825353\n",
      "Average test loss:  0.5984214680385285\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.3579957486452036\n",
      "Average test loss:  0.5760802388997747\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3029276883022508\n",
      "Average test loss:  0.5591552348226233\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2580092966746387\n",
      "Average test loss:  0.5471876020839155\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.22153393432145874\n",
      "Average test loss:  0.5394246180984159\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.19175347879762727\n",
      "Average test loss:  0.5354117206981205\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1672978187869942\n",
      "Average test loss:  0.5341808672045976\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.14702963973649918\n",
      "Average test loss:  0.5354318578033098\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.13008177477548555\n",
      "Average test loss:  0.5385779263164813\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.11578829542747714\n",
      "Average test loss:  0.54345035308614\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.10364010702287187\n",
      "Average test loss:  0.5493267576657909\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.09323953619047821\n",
      "Average test loss:  0.5564596286622427\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.08427641312581725\n",
      "Average test loss:  0.5642257190012393\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07649909679724376\n",
      "Average test loss:  0.5729633994800526\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.06972266970525774\n",
      "Average test loss:  0.5822692834956457\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06377187085910564\n",
      "Average test loss:  0.5916019878162438\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.058548742798739395\n",
      "Average test loss:  0.6016214059769165\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.05393427574378027\n",
      "Average test loss:  0.6115831777151317\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04984892793588467\n",
      "Average test loss:  0.6217188416902096\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.046214972574903944\n",
      "Average test loss:  0.6318176858483642\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.042973005155103085\n",
      "Average test loss:  0.6419758835610135\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04006868840002376\n",
      "Average test loss:  0.6523997283071273\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.03744707855507479\n",
      "Average test loss:  0.6624345782316596\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6919317933135147\n",
      "Average test loss:  0.6927973498373107\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.81375\n",
      "Average test accuracy:  0.62375\n",
      "\n",
      "Average train loss:  0.68946035288459\n",
      "Average test loss:  0.6918619819653345\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.80375\n",
      "Average test accuracy:  0.61875\n",
      "\n",
      "Average train loss:  0.6838346513822197\n",
      "Average test loss:  0.689923098528836\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.854375\n",
      "Average test accuracy:  0.655\n",
      "\n",
      "Average train loss:  0.6709708625046039\n",
      "Average test loss:  0.6854612265269511\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.89\n",
      "Average test accuracy:  0.6875\n",
      "\n",
      "Average train loss:  0.6449989013548434\n",
      "Average test loss:  0.676367435140746\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.91125\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.600596074574383\n",
      "Average test loss:  0.6605801214570665\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.5384868442935993\n",
      "Average test loss:  0.6381686229502775\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.46736436661573105\n",
      "Average test loss:  0.6124547612361929\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.3978550471676347\n",
      "Average test loss:  0.5877322096424987\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.3363158384638069\n",
      "Average test loss:  0.5668987529000509\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.28462027639474513\n",
      "Average test loss:  0.5511413643912292\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.24225417496089863\n",
      "Average test loss:  0.5403637333352982\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2078036338482506\n",
      "Average test loss:  0.5337404086413248\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1796840440809598\n",
      "Average test loss:  0.5308576492548897\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1565865019457154\n",
      "Average test loss:  0.5307671667183774\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.13745440497677788\n",
      "Average test loss:  0.5331493122758026\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.12148936873863649\n",
      "Average test loss:  0.5373778566599127\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.10805328454288608\n",
      "Average test loss:  0.5431080482435935\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.09665978771884741\n",
      "Average test loss:  0.5500596533924904\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.08690700929770002\n",
      "Average test loss:  0.5580924591180213\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.0785072445064836\n",
      "Average test loss:  0.566687048443371\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.07121966517958543\n",
      "Average test loss:  0.5759859481451978\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.0648546413984611\n",
      "Average test loss:  0.585926182275929\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.05925627849222434\n",
      "Average test loss:  0.5963457541508151\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.05430014143113201\n",
      "Average test loss:  0.6070579370997818\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04989662147939088\n",
      "Average test loss:  0.6179864935854971\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.04596244564647437\n",
      "Average test loss:  0.6291292321376379\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.04244335379276854\n",
      "Average test loss:  0.6404989508727783\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.03929865280142784\n",
      "Average test loss:  0.6518486766570016\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.036483002617186094\n",
      "Average test loss:  0.6631616406542437\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.928125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.6913238313058799\n",
      "Average test loss:  0.6925074814737401\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.9275\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.6875957501819339\n",
      "Average test loss:  0.691213939715633\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6781476521854767\n",
      "Average test loss:  0.6879194361607953\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6561035977515391\n",
      "Average test loss:  0.6802269445601747\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6107865453206287\n",
      "Average test loss:  0.6644076139959569\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5366411500994487\n",
      "Average test loss:  0.6384677508780477\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.4475556202172464\n",
      "Average test loss:  0.6076764445570417\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.3637056657673463\n",
      "Average test loss:  0.579876037209128\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.29455085679496656\n",
      "Average test loss:  0.5591096016447001\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.24055368326203422\n",
      "Average test loss:  0.545943305356987\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.19885886535906672\n",
      "Average test loss:  0.5388923157069464\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.16651838222384466\n",
      "Average test loss:  0.5364117148229558\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1411403203926507\n",
      "Average test loss:  0.5376759448665839\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.12089857515239649\n",
      "Average test loss:  0.5419561524571999\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.10457850222280052\n",
      "Average test loss:  0.5485801885583065\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09124906948228269\n",
      "Average test loss:  0.5568786430308345\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08023917939148717\n",
      "Average test loss:  0.5662620211741523\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07103944914365036\n",
      "Average test loss:  0.5766947992130937\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.0633011865452514\n",
      "Average test loss:  0.5877517341356421\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.05673315736874581\n",
      "Average test loss:  0.5997355214189873\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.051122268657103176\n",
      "Average test loss:  0.6116116160721065\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.046296920016444504\n",
      "Average test loss:  0.623922093610897\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04211658925802788\n",
      "Average test loss:  0.6363440415447031\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.038478148094302306\n",
      "Average test loss:  0.6489277880026075\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.03528548700641685\n",
      "Average test loss:  0.6612159711004072\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.032454991671878736\n",
      "Average test loss:  0.6740288317560985\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.029927098531047674\n",
      "Average test loss:  0.686293763472204\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.02764937899642708\n",
      "Average test loss:  0.6991727308006018\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.025585981754722754\n",
      "Average test loss:  0.7114287654136081\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.023724618070369585\n",
      "Average test loss:  0.7238992158979157\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.500625\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6914886164400813\n",
      "Average test loss:  0.6925678344672974\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.85\n",
      "Average test accuracy:  0.655\n",
      "\n",
      "Average train loss:  0.688079971202125\n",
      "Average test loss:  0.6913802991965529\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.8775\n",
      "Average test accuracy:  0.68125\n",
      "\n",
      "Average train loss:  0.6795278242217128\n",
      "Average test loss:  0.6884116229792565\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.911875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.6602168355112612\n",
      "Average test loss:  0.6816600919266348\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.9225\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.622880867602246\n",
      "Average test loss:  0.6685121993927404\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.938125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.5625866563395016\n",
      "Average test loss:  0.6470673395003307\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.48363118779114894\n",
      "Average test loss:  0.6190272266641171\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.40080362362474986\n",
      "Average test loss:  0.5902008775942776\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3269016894777507\n",
      "Average test loss:  0.5661102411059448\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.26670665045134667\n",
      "Average test loss:  0.5489804578191249\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.21947867035799076\n",
      "Average test loss:  0.5385483945420679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.18270403279181371\n",
      "Average test loss:  0.5335583526510603\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.15390180412155383\n",
      "Average test loss:  0.533168997542737\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.13108752388598374\n",
      "Average test loss:  0.5360283826697482\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.11280996889514257\n",
      "Average test loss:  0.5414765072115602\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.09795737673758707\n",
      "Average test loss:  0.5489955127920224\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.08574986143668406\n",
      "Average test loss:  0.5577992609120307\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07561038609041151\n",
      "Average test loss:  0.5680188822220841\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06709530521966861\n",
      "Average test loss:  0.5790572016051064\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.059879211647326125\n",
      "Average test loss:  0.5909222202006098\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.053709149882402905\n",
      "Average test loss:  0.6031590035290043\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.04839860625634282\n",
      "Average test loss:  0.6158924228422772\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.04379667621887091\n",
      "Average test loss:  0.6287853736420311\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.03979093461301095\n",
      "Average test loss:  0.6418488149152193\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.036298229477011584\n",
      "Average test loss:  0.6553153880602102\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.033229089331623336\n",
      "Average test loss:  0.6683441647866956\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.03054145459890124\n",
      "Average test loss:  0.6816037232737729\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.028166448520918697\n",
      "Average test loss:  0.694600735061945\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.026063529085832978\n",
      "Average test loss:  0.7077074291660009\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.02419135991029649\n",
      "Average test loss:  0.7205031041627867\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6958792686437079\n",
      "Average test loss:  0.6966941217581786\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.50375\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6893953627386304\n",
      "Average test loss:  0.6919081117336553\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.845\n",
      "Average test accuracy:  0.655\n",
      "\n",
      "Average train loss:  0.684790724434618\n",
      "Average test loss:  0.6902811041661602\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.895625\n",
      "Average test accuracy:  0.70375\n",
      "\n",
      "Average train loss:  0.6756917645887665\n",
      "Average test loss:  0.6871082782177793\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6572623206908519\n",
      "Average test loss:  0.680637505224631\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.621117088976134\n",
      "Average test loss:  0.6679480608833274\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.5582291073306974\n",
      "Average test loss:  0.6460585369414696\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.47300816602732737\n",
      "Average test loss:  0.6171885234550497\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.3850422684517451\n",
      "Average test loss:  0.5887045381600075\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.30961894671764423\n",
      "Average test loss:  0.566824369990953\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.25041681311707004\n",
      "Average test loss:  0.5525336677934402\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.20513854750538527\n",
      "Average test loss:  0.5456584544631101\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.170471093524972\n",
      "Average test loss:  0.5433778645025212\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1435926822832003\n",
      "Average test loss:  0.5456351230784159\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.12243021241037043\n",
      "Average test loss:  0.5506680608103851\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1055004455083461\n",
      "Average test loss:  0.5583080906201935\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09177426231291601\n",
      "Average test loss:  0.5673561801012323\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08049693741629128\n",
      "Average test loss:  0.5776992057726348\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.07114601001132721\n",
      "Average test loss:  0.5895322380184628\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.06330109308186449\n",
      "Average test loss:  0.6007824243841782\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.05668074062519681\n",
      "Average test loss:  0.6134086716009651\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.051040721755469275\n",
      "Average test loss:  0.6261273245894686\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.046206027874005566\n",
      "Average test loss:  0.6387535885180068\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.042032195514858706\n",
      "Average test loss:  0.6521755192045873\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.038403951875155766\n",
      "Average test loss:  0.6650798772574392\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.035227282363897404\n",
      "Average test loss:  0.6779428463596758\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.03243177024398037\n",
      "Average test loss:  0.6910330668353892\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.029945009111273447\n",
      "Average test loss:  0.7037751040393859\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.027733079932461924\n",
      "Average test loss:  0.7162957669300382\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.02575149625081215\n",
      "Average test loss:  0.7290960668595198\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.553125\n",
      "Average test accuracy:  0.50125\n",
      "\n",
      "Average train loss:  0.691283175144168\n",
      "Average test loss:  0.6924864381356176\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.854375\n",
      "Average test accuracy:  0.605\n",
      "\n",
      "Average train loss:  0.6874952944967476\n",
      "Average test loss:  0.6911806936442488\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.9225\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.6774336842895486\n",
      "Average test loss:  0.6877057259202563\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.6499130227825641\n",
      "Average test loss:  0.6781567291708192\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.5866985389892677\n",
      "Average test loss:  0.6561778435622158\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.48560927041813207\n",
      "Average test loss:  0.621033839784971\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.3784885506564648\n",
      "Average test loss:  0.5851721343729087\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2911996356068102\n",
      "Average test loss:  0.5588148806271919\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.22699031364723873\n",
      "Average test loss:  0.5433348053070963\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.18057433689849656\n",
      "Average test loss:  0.5371506059813187\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1465419820887796\n",
      "Average test loss:  0.5370115414364648\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1210210549734952\n",
      "Average test loss:  0.5411250551081438\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.10147161621257256\n",
      "Average test loss:  0.5493286746384423\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.08620124724111455\n",
      "Average test loss:  0.5592725425132555\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07405375667644548\n",
      "Average test loss:  0.5710493859774574\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.06424710722696968\n",
      "Average test loss:  0.584201647963021\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.056217023565875095\n",
      "Average test loss:  0.598125197431264\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.049569175635509756\n",
      "Average test loss:  0.612219371517802\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.04400961155250038\n",
      "Average test loss:  0.6269408947496125\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.0393155768215564\n",
      "Average test loss:  0.6418514280783555\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.03531069808976887\n",
      "Average test loss:  0.6570454999333856\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.0318784871586778\n",
      "Average test loss:  0.6722355048960704\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.02890657392950535\n",
      "Average test loss:  0.6873426455278498\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.02631835329016999\n",
      "Average test loss:  0.7022011982291025\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.024044050310584954\n",
      "Average test loss:  0.7172164238536705\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.022030904412094297\n",
      "Average test loss:  0.7319761573001832\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.020243016170139464\n",
      "Average test loss:  0.7467586405763962\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.01864758601938239\n",
      "Average test loss:  0.7610185996962778\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.01723488241223836\n",
      "Average test loss:  0.775470349825084\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.015985445649488825\n",
      "Average test loss:  0.7891998288177314\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.509375\n",
      "Average test accuracy:  0.50375\n",
      "\n",
      "Average train loss:  0.6914253669726342\n",
      "Average test loss:  0.6925578384660606\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.8825\n",
      "Average test accuracy:  0.6825\n",
      "\n",
      "Average train loss:  0.6872896118467299\n",
      "Average test loss:  0.6911247785667146\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6759321275507926\n",
      "Average test loss:  0.6871906402234947\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.9325\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.6464024351327019\n",
      "Average test loss:  0.6769886770064679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.5816793213415998\n",
      "Average test loss:  0.654637270484352\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.4813648067595639\n",
      "Average test loss:  0.6203117355784528\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.37499203543602794\n",
      "Average test loss:  0.5857586861571858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.28764011621357566\n",
      "Average test loss:  0.5603371036204066\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.22326166800556133\n",
      "Average test loss:  0.5460099499275912\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.17685103037597535\n",
      "Average test loss:  0.5411011429669951\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.14299274973394857\n",
      "Average test loss:  0.5425341953526814\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.11774666860142664\n",
      "Average test loss:  0.5475676639553638\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.0984874372255405\n",
      "Average test loss:  0.556581242562765\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.0835039571526461\n",
      "Average test loss:  0.5672850044543455\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.0716309792792549\n",
      "Average test loss:  0.5806184666517672\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.062069590116511995\n",
      "Average test loss:  0.5940863855120173\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.054267803193813774\n",
      "Average test loss:  0.608394563785985\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.04783837672733354\n",
      "Average test loss:  0.6231563615098329\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.042472823423716555\n",
      "Average test loss:  0.6385040023708303\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.037947124746889487\n",
      "Average test loss:  0.653744946719555\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.03408837198259906\n",
      "Average test loss:  0.66926526205896\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.030758932269886057\n",
      "Average test loss:  0.6847373562161678\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.027850976975715935\n",
      "Average test loss:  0.7000590104289198\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.02530408371885302\n",
      "Average test loss:  0.715074443509915\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.023063849666905462\n",
      "Average test loss:  0.7302942801952886\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.021102839807949105\n",
      "Average test loss:  0.7451667635406064\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.019379816853758492\n",
      "Average test loss:  0.7600528097682059\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.017877982253633132\n",
      "Average test loss:  0.774343361905196\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.016552557033204844\n",
      "Average test loss:  0.7890904051157737\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.01536661826735354\n",
      "Average test loss:  0.8029891720930533\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6912519037794077\n",
      "Average test loss:  0.6925319302671454\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.88875\n",
      "Average test accuracy:  0.69375\n",
      "\n",
      "Average train loss:  0.6874302335324783\n",
      "Average test loss:  0.6911809423763912\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6779434971939908\n",
      "Average test loss:  0.6878976478954981\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6561430527473301\n",
      "Average test loss:  0.6803355169277113\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6114808808118097\n",
      "Average test loss:  0.6648736958360743\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5350034988459923\n",
      "Average test loss:  0.6383603351526185\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.4344595627456947\n",
      "Average test loss:  0.6043773426805303\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.958125\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.335675748064404\n",
      "Average test loss:  0.5729846565113478\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.2567058075438094\n",
      "Average test loss:  0.5517933313354926\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.19917319496787925\n",
      "Average test loss:  0.5420283579026804\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.15793463712364433\n",
      "Average test loss:  0.5397974138744733\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1278539209124098\n",
      "Average test loss:  0.543392203502617\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.105448486365241\n",
      "Average test loss:  0.5514282570457325\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.0883829871865121\n",
      "Average test loss:  0.5622338740252583\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07506350239077297\n",
      "Average test loss:  0.5745603150239238\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.06451909284900927\n",
      "Average test loss:  0.5886538646074356\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.05601592678411218\n",
      "Average test loss:  0.603393643626538\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04907530870250578\n",
      "Average test loss:  0.6185001121778745\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.043332933137121575\n",
      "Average test loss:  0.634214147635567\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.038530776719670416\n",
      "Average test loss:  0.6502199755549339\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.0344822482635266\n",
      "Average test loss:  0.6659461982678896\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.03100992294554254\n",
      "Average test loss:  0.6821256397812894\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.02800508344813334\n",
      "Average test loss:  0.6983877582849822\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.025391538251479513\n",
      "Average test loss:  0.7137539743116198\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.02309356653030539\n",
      "Average test loss:  0.7293066543312611\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.021072077680939123\n",
      "Average test loss:  0.7450408313501254\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.019302474670905276\n",
      "Average test loss:  0.7603991267924686\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.017762347753020987\n",
      "Average test loss:  0.7754874897125147\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.016402256423568327\n",
      "Average test loss:  0.7903740215480743\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  7\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.015203642999840311\n",
      "Average test loss:  0.8051517038883564\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6914910619806794\n",
      "Average test loss:  0.6925894120241791\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.9225\n",
      "Average test accuracy:  0.7075\n",
      "\n",
      "Average train loss:  0.6886303122977422\n",
      "Average test loss:  0.6915957089803881\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.85125\n",
      "Average test accuracy:  0.6\n",
      "\n",
      "Average train loss:  0.6826684750570898\n",
      "Average test loss:  0.6895596619869439\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.85\n",
      "Average test accuracy:  0.60375\n",
      "\n",
      "Average train loss:  0.6707911010690722\n",
      "Average test loss:  0.6855160665220662\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.83875\n",
      "Average test accuracy:  0.58625\n",
      "\n",
      "Average train loss:  0.6495890290875966\n",
      "Average test loss:  0.6784972120111178\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.870625\n",
      "Average test accuracy:  0.62375\n",
      "\n",
      "Average train loss:  0.6167592556872411\n",
      "Average test loss:  0.6675866751491925\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.89625\n",
      "Average test accuracy:  0.6725\n",
      "\n",
      "Average train loss:  0.574300427060004\n",
      "Average test loss:  0.6533202237167278\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.92375\n",
      "Average test accuracy:  0.705\n",
      "\n",
      "Average train loss:  0.5269139823670596\n",
      "Average test loss:  0.637161052445558\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.715\n",
      "\n",
      "Average train loss:  0.47950607486074753\n",
      "Average test loss:  0.6209632187724067\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.4350560517180215\n",
      "Average test loss:  0.6059157910664476\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.39478571036704074\n",
      "Average test loss:  0.5924094932140894\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.966875\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.35891729538376543\n",
      "Average test loss:  0.580941015308284\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3271999045308578\n",
      "Average test loss:  0.5711490367639386\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.2992220832446894\n",
      "Average test loss:  0.5634747493257851\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.2744888277440279\n",
      "Average test loss:  0.5571014923217072\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.2525871555196859\n",
      "Average test loss:  0.5529021593449074\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.23311465062103012\n",
      "Average test loss:  0.5496515409775329\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.21574278889488382\n",
      "Average test loss:  0.5478456169724653\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.2001926003353661\n",
      "Average test loss:  0.5471139914292463\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.18620834379771514\n",
      "Average test loss:  0.5472049251347643\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.1736092616097199\n",
      "Average test loss:  0.5483693596513115\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.16220215719593883\n",
      "Average test loss:  0.5499271029900815\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.15185042985981756\n",
      "Average test loss:  0.5524738983736037\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.1424217656647868\n",
      "Average test loss:  0.5554173568183365\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.1338085592786895\n",
      "Average test loss:  0.5590689664221662\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.1259221702448605\n",
      "Average test loss:  0.5633294303364688\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.11867223690381079\n",
      "Average test loss:  0.5676764458782503\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.11200806803648074\n",
      "Average test loss:  0.5724813428384721\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10587078026741753\n",
      "Average test loss:  0.5773151705031386\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10022112667860084\n",
      "Average test loss:  0.5825737783285364\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6953674930384669\n",
      "Average test loss:  0.6964238106065759\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6896069806311624\n",
      "Average test loss:  0.6921376869068597\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.921875\n",
      "Average test accuracy:  0.6975\n",
      "\n",
      "Average train loss:  0.6845995101171306\n",
      "Average test loss:  0.6902290009245918\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6745209472130173\n",
      "Average test loss:  0.6867122797285922\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.653417904187572\n",
      "Average test loss:  0.6793236286297697\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.6143996871492287\n",
      "Average test loss:  0.6655725166774457\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5560692855613165\n",
      "Average test loss:  0.6446989722500469\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.4877766635293179\n",
      "Average test loss:  0.6201709630176627\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.4209319554245922\n",
      "Average test loss:  0.5963244533502734\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3620859332520716\n",
      "Average test loss:  0.5758981695710466\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.31256954156252625\n",
      "Average test loss:  0.5596696100797346\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2715410543022794\n",
      "Average test loss:  0.5478134132749058\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.23753722662660523\n",
      "Average test loss:  0.5395616251356196\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2092261091318511\n",
      "Average test loss:  0.5341990167415339\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.185489390026931\n",
      "Average test loss:  0.5315983577187796\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.16544085661120578\n",
      "Average test loss:  0.531230149708258\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.14838418389953514\n",
      "Average test loss:  0.532486556071522\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.13376926126262476\n",
      "Average test loss:  0.535246907235611\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.1211446000877509\n",
      "Average test loss:  0.5392106981101552\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.11019022875022137\n",
      "Average test loss:  0.5441403053651099\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.1006075498505589\n",
      "Average test loss:  0.5500681454735273\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.09220563666627683\n",
      "Average test loss:  0.5564845110866727\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08478865541011377\n",
      "Average test loss:  0.5637439658041795\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07820732344442097\n",
      "Average test loss:  0.5713051442077398\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07234320904740711\n",
      "Average test loss:  0.5795860998589042\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06709288651453067\n",
      "Average test loss:  0.587865111767161\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06238022028144541\n",
      "Average test loss:  0.5963892165741734\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.058139799101159705\n",
      "Average test loss:  0.6053216872828976\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.0543195853431833\n",
      "Average test loss:  0.6141957627546114\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.05086698872877726\n",
      "Average test loss:  0.6230672055905048\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7089257613158457\n",
      "Average test loss:  0.7097506054152346\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.695142752836606\n",
      "Average test loss:  0.6967997604490588\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6895954773445615\n",
      "Average test loss:  0.692465935878969\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.501875\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6857397669098647\n",
      "Average test loss:  0.6905991564728088\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.834375\n",
      "Average test accuracy:  0.62875\n",
      "\n",
      "Average train loss:  0.6802510591970244\n",
      "Average test loss:  0.6886349604468679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.916875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.670058233326874\n",
      "Average test loss:  0.6850964587650434\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6505174470316154\n",
      "Average test loss:  0.6782406017227735\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6158477951960681\n",
      "Average test loss:  0.6658218014743144\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5635931698780713\n",
      "Average test loss:  0.646653672002342\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.4978635348219702\n",
      "Average test loss:  0.6221131791412996\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.4276697177107341\n",
      "Average test loss:  0.595926089620225\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.36326319044005234\n",
      "Average test loss:  0.5726124012170594\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.30918585657247627\n",
      "Average test loss:  0.5545302869167038\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2651172509862172\n",
      "Average test loss:  0.5415679303912753\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2292424633603982\n",
      "Average test loss:  0.5333249249912734\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.19987350894069736\n",
      "Average test loss:  0.5287224333308699\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.17562257458609223\n",
      "Average test loss:  0.5272332908470369\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.15541809290240577\n",
      "Average test loss:  0.5281181729906463\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.1384318092440395\n",
      "Average test loss:  0.5308722327780355\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.1240212841454688\n",
      "Average test loss:  0.5350599097330219\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.11171701525447364\n",
      "Average test loss:  0.5407677670607393\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.10113259152622821\n",
      "Average test loss:  0.5472486087218872\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.09196798168580189\n",
      "Average test loss:  0.5546761733545966\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.08398514142091355\n",
      "Average test loss:  0.5625255349845119\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07699924541113447\n",
      "Average test loss:  0.5710967840524631\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07084343440806294\n",
      "Average test loss:  0.5801579796669251\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06537908925069641\n",
      "Average test loss:  0.5894747047881929\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06050265973741937\n",
      "Average test loss:  0.5991574469919314\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.056125725188382485\n",
      "Average test loss:  0.6089705268770755\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.05216531556528109\n",
      "Average test loss:  0.6190224254491486\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6910146742102005\n",
      "Average test loss:  0.6925021428955432\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.928125\n",
      "Average test accuracy:  0.7125\n",
      "\n",
      "Average train loss:  0.6872475324971842\n",
      "Average test loss:  0.6910987681177464\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.931875\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.6794954839143451\n",
      "Average test loss:  0.6884033760333491\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.662494066925694\n",
      "Average test loss:  0.6824767630924705\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.6270175090632768\n",
      "Average test loss:  0.6700713361428509\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.5641748443727167\n",
      "Average test loss:  0.6480813904915246\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.4805825619641902\n",
      "Average test loss:  0.6190204061591668\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.39639543150027495\n",
      "Average test loss:  0.5904907429648082\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.3244361227659496\n",
      "Average test loss:  0.5678261913096109\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.26702219605495175\n",
      "Average test loss:  0.552439460806462\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2221903538285499\n",
      "Average test loss:  0.5426949794739727\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.1870774581518672\n",
      "Average test loss:  0.5382292127377872\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.1592907781789151\n",
      "Average test loss:  0.537553194055345\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.13703608140365053\n",
      "Average test loss:  0.5401899857307196\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1189729118589105\n",
      "Average test loss:  0.5446196258757073\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10414667707988723\n",
      "Average test loss:  0.5512385327913806\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.09184857785521605\n",
      "Average test loss:  0.5595087387507307\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08154557475985615\n",
      "Average test loss:  0.5686000281735324\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.07284403603512608\n",
      "Average test loss:  0.5786553313724765\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.06545101040207199\n",
      "Average test loss:  0.5889458760335005\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.05911317935705982\n",
      "Average test loss:  0.6001828867098541\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.05365579533798074\n",
      "Average test loss:  0.6116061367822163\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.0489363167500582\n",
      "Average test loss:  0.623196919684319\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.04482642387838285\n",
      "Average test loss:  0.6348769712441237\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.041235600761252496\n",
      "Average test loss:  0.64641594831993\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.038071786841870375\n",
      "Average test loss:  0.6580501077460846\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.035273914600514704\n",
      "Average test loss:  0.6697707189253216\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.03278200809777961\n",
      "Average test loss:  0.6813790568439712\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.030549499924589472\n",
      "Average test loss:  0.6927905052811861\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.028531856456265173\n",
      "Average test loss:  0.7045138825219657\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7557162832066756\n",
      "Average test loss:  0.7566795327591395\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7157233809841657\n",
      "Average test loss:  0.7176709237519899\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.696868014905939\n",
      "Average test loss:  0.6999699790585723\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6881448499433495\n",
      "Average test loss:  0.6928552692327671\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6825003020935778\n",
      "Average test loss:  0.6897019546548343\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.891875\n",
      "Average test accuracy:  0.61\n",
      "\n",
      "Average train loss:  0.6758225176242517\n",
      "Average test loss:  0.6870613357078511\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.951875\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.6654425383991596\n",
      "Average test loss:  0.6832480487784386\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6482618746161947\n",
      "Average test loss:  0.6769817298793758\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.6189392291467796\n",
      "Average test loss:  0.666234070137871\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.5714068008084773\n",
      "Average test loss:  0.6488459499197197\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.955625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.5059727326617468\n",
      "Average test loss:  0.625109532720963\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.4324818401674866\n",
      "Average test loss:  0.5991869026891448\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.36243235527393675\n",
      "Average test loss:  0.5757976901571967\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.30238747596252713\n",
      "Average test loss:  0.5578373766913388\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.25344763751746835\n",
      "Average test loss:  0.5457056418327483\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.979375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.21429429376424078\n",
      "Average test loss:  0.5386748088813648\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.1829414545431579\n",
      "Average test loss:  0.5360055736776257\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.15767234458539509\n",
      "Average test loss:  0.53653738197146\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13712332121946155\n",
      "Average test loss:  0.539440062005467\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1202223503482474\n",
      "Average test loss:  0.5444121101933859\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.10617864036549896\n",
      "Average test loss:  0.5508581155177676\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.09441413847976188\n",
      "Average test loss:  0.558737603133766\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.08444882724221851\n",
      "Average test loss:  0.5674297940072858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.07595114534331973\n",
      "Average test loss:  0.5768214812617006\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.06864669712139704\n",
      "Average test loss:  0.5869297470618392\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.06232912025715403\n",
      "Average test loss:  0.597433739060214\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.056837825508581054\n",
      "Average test loss:  0.608037573129426\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.05204096554548502\n",
      "Average test loss:  0.6187480487078135\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.0478267529622499\n",
      "Average test loss:  0.629806759850393\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.04411934318728541\n",
      "Average test loss:  0.6409643566322187\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.838125\n",
      "Average test accuracy:  0.59625\n",
      "\n",
      "Average train loss:  0.6917728743400189\n",
      "Average test loss:  0.6926765020702725\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.905\n",
      "Average test accuracy:  0.69\n",
      "\n",
      "Average train loss:  0.6881151947527112\n",
      "Average test loss:  0.6914195631689447\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6768751819505531\n",
      "Average test loss:  0.6875254548424139\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6481608464349954\n",
      "Average test loss:  0.6775725909196709\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5889003807717891\n",
      "Average test loss:  0.6568095624496904\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.4997192344983438\n",
      "Average test loss:  0.6254490136131688\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.40202946174553017\n",
      "Average test loss:  0.5916172984188063\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.31764120549793357\n",
      "Average test loss:  0.5645080924110655\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.2523686959992195\n",
      "Average test loss:  0.5471927917711686\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.2035077436443907\n",
      "Average test loss:  0.5377149569256635\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.16684002807316403\n",
      "Average test loss:  0.5344417215249181\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.13883979795489212\n",
      "Average test loss:  0.5360596401247996\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.11710800085390465\n",
      "Average test loss:  0.5411015867622793\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.09997360613204163\n",
      "Average test loss:  0.5489450445997828\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08625063025091458\n",
      "Average test loss:  0.5583191763072904\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07509364781552565\n",
      "Average test loss:  0.5696426705283861\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.06590778109981471\n",
      "Average test loss:  0.5815683622958145\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.058270637000906324\n",
      "Average test loss:  0.5947151763068038\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.05185280001267262\n",
      "Average test loss:  0.6078103370448199\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04642309562679628\n",
      "Average test loss:  0.6215421432784681\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04179658536741888\n",
      "Average test loss:  0.6353064646377088\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.0378123624282282\n",
      "Average test loss:  0.6490225078275004\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.03437016471251064\n",
      "Average test loss:  0.6632206749808661\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.031366404372192395\n",
      "Average test loss:  0.6766980368875104\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.028733454591823412\n",
      "Average test loss:  0.6905477857184726\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.026422521084349216\n",
      "Average test loss:  0.7042788587582162\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.024394160754176608\n",
      "Average test loss:  0.7176859482906094\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.022595734807967695\n",
      "Average test loss:  0.7311024840957773\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.02099914133321634\n",
      "Average test loss:  0.7445425043041999\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.01955899031255347\n",
      "Average test loss:  0.7570662957098128\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6920322221833879\n",
      "Average test loss:  0.6928635524195511\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.79625\n",
      "Average test accuracy:  0.63125\n",
      "\n",
      "Average train loss:  0.6894354682138855\n",
      "Average test loss:  0.6918718361548987\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.88625\n",
      "Average test accuracy:  0.68125\n",
      "\n",
      "Average train loss:  0.6830841888069189\n",
      "Average test loss:  0.689659409809467\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.66563228128374\n",
      "Average test loss:  0.6835464544068929\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.944375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6232238020160973\n",
      "Average test loss:  0.668650168105307\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5444155419611202\n",
      "Average test loss:  0.641011880244628\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.44251766160454786\n",
      "Average test loss:  0.6061916162934095\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.3472837328325642\n",
      "Average test loss:  0.5757510453493858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.27238839409316146\n",
      "Average test loss:  0.5550351010319794\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.21672568226137687\n",
      "Average test loss:  0.544145263122028\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.17550113125990552\n",
      "Average test loss:  0.53997915452785\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.1445629488962997\n",
      "Average test loss:  0.5410564347752045\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.12091816273781135\n",
      "Average test loss:  0.5465620478152816\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10251273700568757\n",
      "Average test loss:  0.5542329812555046\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08792101041125089\n",
      "Average test loss:  0.5645791963175509\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07617205310687791\n",
      "Average test loss:  0.5758523468755062\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.06658756345600357\n",
      "Average test loss:  0.5884950536815453\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.05868493413187647\n",
      "Average test loss:  0.6014655544084082\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.05210651510125361\n",
      "Average test loss:  0.6151210991416248\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.04656452166937733\n",
      "Average test loss:  0.6288470593232073\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.04187211712985431\n",
      "Average test loss:  0.6429020297820554\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.03785193691595609\n",
      "Average test loss:  0.6571242155801773\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.034386203770405216\n",
      "Average test loss:  0.6711368050050538\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.03136484959915967\n",
      "Average test loss:  0.6852338778075926\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.02868897050143977\n",
      "Average test loss:  0.6992550451533012\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.02630691532488641\n",
      "Average test loss:  0.713153166817284\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.024157827405384375\n",
      "Average test loss:  0.7269377994746383\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.022212161999312956\n",
      "Average test loss:  0.7409391091924933\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.020480518016681715\n",
      "Average test loss:  0.754149693130031\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.01895060819924974\n",
      "Average test loss:  0.7675962938514668\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6913045695237477\n",
      "Average test loss:  0.6925935112074016\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.920625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.6876418794349677\n",
      "Average test loss:  0.6912672420299065\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6789733206618163\n",
      "Average test loss:  0.6882778210931176\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6570316507711919\n",
      "Average test loss:  0.6806734976192997\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.94375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6049333281884739\n",
      "Average test loss:  0.6625295714623943\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.5112649451198287\n",
      "Average test loss:  0.6298445973649215\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.4003232240061993\n",
      "Average test loss:  0.591833952656248\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3055832777438446\n",
      "Average test loss:  0.5627746508647905\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.96625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.2356619898673448\n",
      "Average test loss:  0.5452564067515718\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.18565534408803086\n",
      "Average test loss:  0.5380468083229624\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.14946019134247743\n",
      "Average test loss:  0.5373582907341287\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.12263175000768413\n",
      "Average test loss:  0.541625833254937\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10229732952611122\n",
      "Average test loss:  0.5500379779939472\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.08651793679515636\n",
      "Average test loss:  0.5604291685984407\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07409044122399987\n",
      "Average test loss:  0.5725715949420679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0640948562731881\n",
      "Average test loss:  0.5861660324441882\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0559593326626698\n",
      "Average test loss:  0.6005111242048949\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04925413133865545\n",
      "Average test loss:  0.6149887694568319\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.04366342327113004\n",
      "Average test loss:  0.6303652729135696\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.038960811522173906\n",
      "Average test loss:  0.6452201996084026\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.03496782401346656\n",
      "Average test loss:  0.6610939393427491\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.031542011659561414\n",
      "Average test loss:  0.6762600124575541\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.028580232972959575\n",
      "Average test loss:  0.6916019231011927\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.02599970900760336\n",
      "Average test loss:  0.706801176742517\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.02372668172181244\n",
      "Average test loss:  0.7215847737749161\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.02171775730914946\n",
      "Average test loss:  0.7365700059650971\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.019934767080781655\n",
      "Average test loss:  0.7511391991123125\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.018352570843432534\n",
      "Average test loss:  0.7656803016918028\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.01695351074527385\n",
      "Average test loss:  0.779985588836575\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.015725315071513393\n",
      "Average test loss:  0.7943179963248417\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.926875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.6918643469191593\n",
      "Average test loss:  0.692699594649207\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.928125\n",
      "Average test accuracy:  0.7125\n",
      "\n",
      "Average train loss:  0.6882059015953254\n",
      "Average test loss:  0.6914340938096548\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.924375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.676175637538491\n",
      "Average test loss:  0.6872516002325716\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.6422122393151409\n",
      "Average test loss:  0.6753802279834084\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5652091598171055\n",
      "Average test loss:  0.6484303845590581\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.950625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.45058262200326477\n",
      "Average test loss:  0.6083178947406909\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.3400639670554426\n",
      "Average test loss:  0.5721527786816419\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.25682784691841953\n",
      "Average test loss:  0.549276974724954\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.19835652085293068\n",
      "Average test loss:  0.5378235953270085\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.15709375196851458\n",
      "Average test loss:  0.5354509583018193\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.1271946208119839\n",
      "Average test loss:  0.5393474055319104\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.10491775048582914\n",
      "Average test loss:  0.5467890903058846\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08791780801498929\n",
      "Average test loss:  0.5575478083871056\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07467284691657512\n",
      "Average test loss:  0.5700324984647024\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06414863741983547\n",
      "Average test loss:  0.5841585187265349\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.055654427207649855\n",
      "Average test loss:  0.5985187706842376\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.04870165821920833\n",
      "Average test loss:  0.6146785127760453\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.04295217204596844\n",
      "Average test loss:  0.6305539977304785\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.03814439706809169\n",
      "Average test loss:  0.6463734948392124\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.03408205771735057\n",
      "Average test loss:  0.6626896688328185\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.030614343320930996\n",
      "Average test loss:  0.6787794207660722\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.027640745375835576\n",
      "Average test loss:  0.6948859317089386\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.025068543807821586\n",
      "Average test loss:  0.7110887914381152\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.022819109534010257\n",
      "Average test loss:  0.7268597536490967\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.020835275986004573\n",
      "Average test loss:  0.7418869623854135\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.019083265142689744\n",
      "Average test loss:  0.757627119846124\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.017538200820272697\n",
      "Average test loss:  0.7726312772957117\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.016180234877157893\n",
      "Average test loss:  0.7879563693804729\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.014996763467907855\n",
      "Average test loss:  0.8022176978265945\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.013956728710895315\n",
      "Average test loss:  0.816489665634606\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.509375\n",
      "Average test accuracy:  0.50125\n",
      "\n",
      "Average train loss:  0.6910645226536092\n",
      "Average test loss:  0.6924013468366111\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.690625\n",
      "Average test accuracy:  0.51875\n",
      "\n",
      "Average train loss:  0.6869504124014602\n",
      "Average test loss:  0.6910040978464943\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.841875\n",
      "Average test accuracy:  0.58625\n",
      "\n",
      "Average train loss:  0.6774453415152449\n",
      "Average test loss:  0.6877860885491721\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.91875\n",
      "Average test accuracy:  0.7025\n",
      "\n",
      "Average train loss:  0.6562638974441596\n",
      "Average test loss:  0.6805528752286247\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.931875\n",
      "Average test accuracy:  0.71\n",
      "\n",
      "Average train loss:  0.6129387810665828\n",
      "Average test loss:  0.6659281683083051\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9425\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.5383486666870478\n",
      "Average test loss:  0.6404826291016202\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.4407499489975469\n",
      "Average test loss:  0.6079022632962386\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.955\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.3449862030990956\n",
      "Average test loss:  0.57724340563052\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.26811961783803384\n",
      "Average test loss:  0.5562441587095374\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.21125596338686314\n",
      "Average test loss:  0.5443046229844226\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1695618213511484\n",
      "Average test loss:  0.5399698585504474\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.13859162394817018\n",
      "Average test loss:  0.541236537912623\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.1151598295600475\n",
      "Average test loss:  0.5471671552103449\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.09703766490850883\n",
      "Average test loss:  0.5551935466003561\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.0827969394241423\n",
      "Average test loss:  0.5657046224139006\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07139325674109574\n",
      "Average test loss:  0.577739114907101\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06215294872092919\n",
      "Average test loss:  0.5904274240784112\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.054545519425742296\n",
      "Average test loss:  0.6040681039091346\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.04823142047536538\n",
      "Average test loss:  0.6183833270435501\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.04293458887215205\n",
      "Average test loss:  0.6329831455948868\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.03845889752764028\n",
      "Average test loss:  0.6481473198427011\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.03463650358940427\n",
      "Average test loss:  0.6627724122590668\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.03134302816954918\n",
      "Average test loss:  0.6779587140749529\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.028484128263794862\n",
      "Average test loss:  0.6925345133266227\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.02598335550756037\n",
      "Average test loss:  0.7075056164513215\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.023773184982295182\n",
      "Average test loss:  0.7220251486592865\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.021818563923236983\n",
      "Average test loss:  0.7367481125843144\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.020084450286465605\n",
      "Average test loss:  0.7510139708065333\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.018532102095705\n",
      "Average test loss:  0.7654425291867653\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  8\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.01715816593517814\n",
      "Average test loss:  0.7794744898648142\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.8010071627180739\n",
      "Average test loss:  0.802055598682422\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7607233664784459\n",
      "Average test loss:  0.7624096328977631\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7366451213414088\n",
      "Average test loss:  0.7387477279478549\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7215388996745364\n",
      "Average test loss:  0.7239436985050455\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.711555556467141\n",
      "Average test loss:  0.7142259904268412\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7045272427513284\n",
      "Average test loss:  0.7074987047868353\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6992770556338015\n",
      "Average test loss:  0.7026692066518619\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6949950856285024\n",
      "Average test loss:  0.6990315512861679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6910537039025689\n",
      "Average test loss:  0.696129755599776\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6867677771364685\n",
      "Average test loss:  0.6935923423958309\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6810563381389909\n",
      "Average test loss:  0.6908773548577054\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6721446919389064\n",
      "Average test loss:  0.6872382719540638\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6571019088101722\n",
      "Average test loss:  0.6814174959800635\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.70375\n",
      "Average test accuracy:  0.56125\n",
      "\n",
      "Average train loss:  0.6323064958556192\n",
      "Average test loss:  0.6717065194332518\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.911875\n",
      "Average test accuracy:  0.685\n",
      "\n",
      "Average train loss:  0.5958067186807267\n",
      "Average test loss:  0.6571286561646669\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5493982010553068\n",
      "Average test loss:  0.6384456395625389\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.959375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.49828106963726154\n",
      "Average test loss:  0.6178797668158227\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.4482535834761956\n",
      "Average test loss:  0.5980622529920808\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.4028717844330994\n",
      "Average test loss:  0.5806445249138316\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.9725\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.36317724046282507\n",
      "Average test loss:  0.5662684058835065\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.32885884602857424\n",
      "Average test loss:  0.5548650937241315\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.29923799829300635\n",
      "Average test loss:  0.5460290078205093\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.27355107404183526\n",
      "Average test loss:  0.5395562238353041\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.25116145537616114\n",
      "Average test loss:  0.535018206984837\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.23152369934074948\n",
      "Average test loss:  0.5320419890794904\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.21419335883730972\n",
      "Average test loss:  0.5303894890129252\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.19880420234487964\n",
      "Average test loss:  0.529851213536344\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.18505740072630392\n",
      "Average test loss:  0.5302117359243691\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.17272505183098616\n",
      "Average test loss:  0.5313204939869662\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.16161302376200984\n",
      "Average test loss:  0.5331396991150151\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6912930671125063\n",
      "Average test loss:  0.6925327517170626\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.9075\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.6882092852800934\n",
      "Average test loss:  0.691421124726023\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.91625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.6819756602433658\n",
      "Average test loss:  0.689224775189231\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.6693746995155495\n",
      "Average test loss:  0.6847746242719716\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.938125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6450674874785189\n",
      "Average test loss:  0.6761637342742407\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.6027659654430518\n",
      "Average test loss:  0.6611601877624291\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.94125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.5427029237950275\n",
      "Average test loss:  0.6399148900843173\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.4756306413199514\n",
      "Average test loss:  0.6160724959136232\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.958125\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.4118559388049989\n",
      "Average test loss:  0.5936618936107495\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.35615592491859394\n",
      "Average test loss:  0.575137773267053\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3092103928664838\n",
      "Average test loss:  0.5605829081920676\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.975\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.2700713627867943\n",
      "Average test loss:  0.5499684473592978\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.23744956894210945\n",
      "Average test loss:  0.5426372549204345\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.2101496374384698\n",
      "Average test loss:  0.5382692347043467\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.18715023876735104\n",
      "Average test loss:  0.5365362140759686\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.16763697598045427\n",
      "Average test loss:  0.536559921238409\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1509400615985153\n",
      "Average test loss:  0.5382976033165138\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.13656951587505575\n",
      "Average test loss:  0.5417491059925904\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.12410196915929024\n",
      "Average test loss:  0.5461599687553952\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.11324464167268718\n",
      "Average test loss:  0.5514322570258267\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.10372293526137337\n",
      "Average test loss:  0.5574514222685613\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09532835120687379\n",
      "Average test loss:  0.564356735616334\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08789127157234859\n",
      "Average test loss:  0.5717913884014793\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08127886064756722\n",
      "Average test loss:  0.579626020927395\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.0753674158242075\n",
      "Average test loss:  0.5876004271914868\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.07007899502712112\n",
      "Average test loss:  0.5959241041072395\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.06533726979286028\n",
      "Average test loss:  0.6044840907579473\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.06107040532537331\n",
      "Average test loss:  0.6131983131779792\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.05722097484418468\n",
      "Average test loss:  0.6220127425019265\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.0537256029900459\n",
      "Average test loss:  0.6306153132372607\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6913874926353175\n",
      "Average test loss:  0.6925443440799212\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.66375\n",
      "Average test accuracy:  0.5075\n",
      "\n",
      "Average train loss:  0.6884641887535764\n",
      "Average test loss:  0.6915370539419786\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.683125\n",
      "Average test accuracy:  0.51125\n",
      "\n",
      "Average train loss:  0.683243733446225\n",
      "Average test loss:  0.68980365621884\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.865625\n",
      "Average test accuracy:  0.5975\n",
      "\n",
      "Average train loss:  0.6723352226476141\n",
      "Average test loss:  0.6860964879763752\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.898125\n",
      "Average test accuracy:  0.65875\n",
      "\n",
      "Average train loss:  0.6489942711704576\n",
      "Average test loss:  0.6782629962806923\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.925625\n",
      "Average test accuracy:  0.705\n",
      "\n",
      "Average train loss:  0.6052940162300136\n",
      "Average test loss:  0.6633434636123313\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9375\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.541228749451086\n",
      "Average test loss:  0.6413340625727872\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.4677877977201634\n",
      "Average test loss:  0.6162721097200542\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.39751784488876724\n",
      "Average test loss:  0.5927205421478428\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.33680929723452907\n",
      "Average test loss:  0.5731979886130426\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.2865296761364646\n",
      "Average test loss:  0.5587940295061341\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.24546810954502077\n",
      "Average test loss:  0.5489622138405567\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.21194901507662064\n",
      "Average test loss:  0.5428195264465926\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.18445134399875465\n",
      "Average test loss:  0.5396865233321521\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.16173429131544356\n",
      "Average test loss:  0.5395942669957333\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.14279082394595957\n",
      "Average test loss:  0.5414365325985738\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.12683606542155082\n",
      "Average test loss:  0.5453113093760679\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.11331639743978093\n",
      "Average test loss:  0.5502154724825621\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.10175570423052423\n",
      "Average test loss:  0.5567399295449991\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.0918181679777484\n",
      "Average test loss:  0.5637919694495364\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.08320983401179079\n",
      "Average test loss:  0.571722624782503\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0757256872581798\n",
      "Average test loss:  0.5802253325855585\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06918447843923047\n",
      "Average test loss:  0.5892572066447211\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06344902765403655\n",
      "Average test loss:  0.5983093419483465\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.058399956676387976\n",
      "Average test loss:  0.6077807787378703\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.053939346557449565\n",
      "Average test loss:  0.6172677413145623\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.049981380150667554\n",
      "Average test loss:  0.6273506176051686\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.04646265869387569\n",
      "Average test loss:  0.6370685244664566\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.04331099549607451\n",
      "Average test loss:  0.6469092279262783\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04048863516799759\n",
      "Average test loss:  0.6568025801608748\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7000372280605576\n",
      "Average test loss:  0.7005204526140208\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6917081001874879\n",
      "Average test loss:  0.6930373090114857\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.641875\n",
      "Average test accuracy:  0.53625\n",
      "\n",
      "Average train loss:  0.6883896890397314\n",
      "Average test loss:  0.6914762031317035\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.9\n",
      "Average test accuracy:  0.7025\n",
      "\n",
      "Average train loss:  0.6830317520481018\n",
      "Average test loss:  0.6896115278345495\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.928125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.6714551250194329\n",
      "Average test loss:  0.6855911210739419\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.6453320390021956\n",
      "Average test loss:  0.6764103867203692\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.940625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.592865480399448\n",
      "Average test loss:  0.6578181688297381\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.5113923647501107\n",
      "Average test loss:  0.628898470099115\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.75375\n",
      "\n",
      "Average train loss:  0.4203034319273069\n",
      "Average test loss:  0.5971748832668914\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.34039294011321886\n",
      "Average test loss:  0.5708752443903123\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2773046808071639\n",
      "Average test loss:  0.5529833566394847\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.22885091226620577\n",
      "Average test loss:  0.541541019312136\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1915649502759952\n",
      "Average test loss:  0.5364948014483791\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.16248902938863222\n",
      "Average test loss:  0.5357511432594927\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.985625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.13943210011441384\n",
      "Average test loss:  0.5384132584418921\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.12089253524815202\n",
      "Average test loss:  0.5433391802633221\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.10576097223523688\n",
      "Average test loss:  0.5499690457304944\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.09324760294241226\n",
      "Average test loss:  0.5588325261718279\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08280621351922536\n",
      "Average test loss:  0.5680198126742274\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.07398376793564064\n",
      "Average test loss:  0.5782319122770856\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.06649858220174844\n",
      "Average test loss:  0.5894929648206785\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.06009573081001938\n",
      "Average test loss:  0.6006899682534211\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.05458888019809941\n",
      "Average test loss:  0.6121902611267815\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.04983404017589271\n",
      "Average test loss:  0.6238062774898905\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.045696669737225394\n",
      "Average test loss:  0.6355472895228704\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.042087863032587575\n",
      "Average test loss:  0.64734724704399\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.038916625455974296\n",
      "Average test loss:  0.6587031959930009\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.036113838327400886\n",
      "Average test loss:  0.6704122932552599\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.033622356851139686\n",
      "Average test loss:  0.6817235120619204\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.031404140066803955\n",
      "Average test loss:  0.6933375809599807\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.696212375551785\n",
      "Average test loss:  0.697311639340397\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6892719938078732\n",
      "Average test loss:  0.6919025642214504\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.93\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.6851744612855448\n",
      "Average test loss:  0.6904004891796425\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.89625\n",
      "Average test accuracy:  0.7\n",
      "\n",
      "Average train loss:  0.6780539397186273\n",
      "Average test loss:  0.6879116456869231\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.91625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.6639880454752533\n",
      "Average test loss:  0.6829616029324314\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9325\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.636002876002296\n",
      "Average test loss:  0.6730411893616002\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.5841980682673934\n",
      "Average test loss:  0.6545173462194283\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5044095905935495\n",
      "Average test loss:  0.625908785976442\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.4130742281802026\n",
      "Average test loss:  0.5936435150307148\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3314146811115266\n",
      "Average test loss:  0.5665352684203208\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.968125\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.2668725060467954\n",
      "Average test loss:  0.5478157947928236\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.21788418285130676\n",
      "Average test loss:  0.5369679559074809\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.1805867760885664\n",
      "Average test loss:  0.5324664328379834\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.15179474811481672\n",
      "Average test loss:  0.5324426073121288\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.12921423693555525\n",
      "Average test loss:  0.5357395862582502\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.11123401693196122\n",
      "Average test loss:  0.5421480070106587\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.0967185309241038\n",
      "Average test loss:  0.5501124309515845\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.08482695595962152\n",
      "Average test loss:  0.5594848422351567\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.07496692996873065\n",
      "Average test loss:  0.570039432331077\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.06670549221070741\n",
      "Average test loss:  0.5813968398227646\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.059722717138352165\n",
      "Average test loss:  0.5932882853830314\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.0537532993999329\n",
      "Average test loss:  0.6061860768040762\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0486250959021243\n",
      "Average test loss:  0.618266065962461\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04418541152419685\n",
      "Average test loss:  0.6312189079135447\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.040313032240760105\n",
      "Average test loss:  0.6439476546582386\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0369174306204808\n",
      "Average test loss:  0.6566747016873934\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.033904357889689714\n",
      "Average test loss:  0.6692152804531358\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.031234625334190688\n",
      "Average test loss:  0.6819571503807514\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.028876603966829336\n",
      "Average test loss:  0.6947456361387098\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.026790976280505807\n",
      "Average test loss:  0.7070997756863925\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.93125\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.6907992025976165\n",
      "Average test loss:  0.692328940912801\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.78625\n",
      "Average test accuracy:  0.55\n",
      "\n",
      "Average train loss:  0.6864066230658784\n",
      "Average test loss:  0.6908294972733735\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.88625\n",
      "Average test accuracy:  0.64125\n",
      "\n",
      "Average train loss:  0.6755981747992664\n",
      "Average test loss:  0.6871352667948543\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.925625\n",
      "Average test accuracy:  0.705\n",
      "\n",
      "Average train loss:  0.6491715187489726\n",
      "Average test loss:  0.6780957028652658\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.5921236802010738\n",
      "Average test loss:  0.6585423135918537\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.94375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.500501534756045\n",
      "Average test loss:  0.6274570938163658\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.3989625692298892\n",
      "Average test loss:  0.5934852910866539\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.755\n",
      "\n",
      "Average train loss:  0.31295725719677076\n",
      "Average test loss:  0.5674026866734123\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.24748351404066926\n",
      "Average test loss:  0.5501796172949894\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1989239094279137\n",
      "Average test loss:  0.5417096427992804\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.16268820363602635\n",
      "Average test loss:  0.5390995511525783\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9825\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.13516782348765624\n",
      "Average test loss:  0.5418822406403055\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.11388062290377561\n",
      "Average test loss:  0.5475477695772476\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09711198588399632\n",
      "Average test loss:  0.5554667415189432\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.08370093587613454\n",
      "Average test loss:  0.566287798601029\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.07281798793217707\n",
      "Average test loss:  0.5774954761419832\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06389515001913638\n",
      "Average test loss:  0.5894782183056764\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.05650228653363687\n",
      "Average test loss:  0.6023743033234585\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.050324201993073546\n",
      "Average test loss:  0.6160464809350744\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.04511731867629679\n",
      "Average test loss:  0.6295016881188115\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04068846192103182\n",
      "Average test loss:  0.6431744078340816\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.03689495533315503\n",
      "Average test loss:  0.6571448898654954\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.03360680277091425\n",
      "Average test loss:  0.6708981486187598\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.030725452635804163\n",
      "Average test loss:  0.6847058911818391\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.028169840980771396\n",
      "Average test loss:  0.6980636314698739\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.02587266162551392\n",
      "Average test loss:  0.7116480844983446\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.02378721776628398\n",
      "Average test loss:  0.7251064356952015\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.021899894813852863\n",
      "Average test loss:  0.7385596577424182\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.020204149870994524\n",
      "Average test loss:  0.7519622539247476\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.018699445753609573\n",
      "Average test loss:  0.7652100538129303\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7073965693855873\n",
      "Average test loss:  0.7084999498357059\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6917957575264424\n",
      "Average test loss:  0.69414606782006\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6869578296954245\n",
      "Average test loss:  0.6911322133158041\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.6819858071049677\n",
      "Average test loss:  0.6892427002387679\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.6728914929595459\n",
      "Average test loss:  0.6859984974266382\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.9475\n",
      "Average test accuracy:  0.75625\n",
      "\n",
      "Average train loss:  0.6541619621619862\n",
      "Average test loss:  0.6793161719263784\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9475\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.6160306820531928\n",
      "Average test loss:  0.6656551400083344\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.95125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5501934917231704\n",
      "Average test loss:  0.642066214383358\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.955\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.4637468659722878\n",
      "Average test loss:  0.6117763019041172\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3762087825673793\n",
      "Average test loss:  0.5827135695348253\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.30162091471940533\n",
      "Average test loss:  0.5605932163413364\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.24310415081193415\n",
      "Average test loss:  0.5467609149472393\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.19846514824680686\n",
      "Average test loss:  0.539975391124726\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.1643859935341974\n",
      "Average test loss:  0.5384096328126097\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.13805221727703765\n",
      "Average test loss:  0.5413140965364663\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.11743663691368988\n",
      "Average test loss:  0.5470723853335636\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.10102561968575892\n",
      "Average test loss:  0.555012950006336\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.08775457279942676\n",
      "Average test loss:  0.5644716928995531\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.07690218107388751\n",
      "Average test loss:  0.5754689291774381\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.06791752325236451\n",
      "Average test loss:  0.5869311861762471\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.060421448535024784\n",
      "Average test loss:  0.5993485502614969\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.05408814058905193\n",
      "Average test loss:  0.6120087384651042\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.04870874966510364\n",
      "Average test loss:  0.6248411278465352\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.04411091888597338\n",
      "Average test loss:  0.6379320879697811\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.040144905992485706\n",
      "Average test loss:  0.6512559749058219\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.03670788405740844\n",
      "Average test loss:  0.6643100727193559\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.03370937661316215\n",
      "Average test loss:  0.6774508217680011\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.03107581592294852\n",
      "Average test loss:  0.6902516672501927\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.028738223772075425\n",
      "Average test loss:  0.70303854547269\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.026654238251782966\n",
      "Average test loss:  0.7154933621279698\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6987834900541792\n",
      "Average test loss:  0.699457433478766\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6897885922738806\n",
      "Average test loss:  0.6920250249078196\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.84875\n",
      "Average test accuracy:  0.6475\n",
      "\n",
      "Average train loss:  0.6857954160208918\n",
      "Average test loss:  0.6905588233790975\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.86875\n",
      "Average test accuracy:  0.645\n",
      "\n",
      "Average train loss:  0.678918711335258\n",
      "Average test loss:  0.6882034377690642\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.90625\n",
      "Average test accuracy:  0.68875\n",
      "\n",
      "Average train loss:  0.6648341376604728\n",
      "Average test loss:  0.6833728341242228\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.6348138769598742\n",
      "Average test loss:  0.6728412116858985\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.945\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.5753972201090466\n",
      "Average test loss:  0.6518924303362011\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.48089444840656465\n",
      "Average test loss:  0.6179967044454076\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.37539017800118524\n",
      "Average test loss:  0.5811376687728437\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.28756801072726473\n",
      "Average test loss:  0.5538227118122859\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.970625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.22327439168710417\n",
      "Average test loss:  0.5377968752395811\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.17728427358110668\n",
      "Average test loss:  0.5315420027099361\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1438812427914747\n",
      "Average test loss:  0.5323262187386203\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.985\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.11903035584096455\n",
      "Average test loss:  0.5374493404602028\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.10007327087480584\n",
      "Average test loss:  0.5458616368295727\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08528608810242887\n",
      "Average test loss:  0.5567402181515745\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07351971339607676\n",
      "Average test loss:  0.5692868840445102\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06400735570431476\n",
      "Average test loss:  0.5825322948983543\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.05618155345142936\n",
      "Average test loss:  0.5967776146944762\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.04968358768353328\n",
      "Average test loss:  0.6118433867216888\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.0442183920870751\n",
      "Average test loss:  0.6269640179143888\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.03958291649251281\n",
      "Average test loss:  0.6420394517904932\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.03564258250858121\n",
      "Average test loss:  0.6571318865715855\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.03225925275691267\n",
      "Average test loss:  0.6724425632091114\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.029344121613127102\n",
      "Average test loss:  0.6873074943660079\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.71625\n",
      "\n",
      "Average train loss:  0.02683167661106588\n",
      "Average test loss:  0.7020237552580819\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.024649537505287825\n",
      "Average test loss:  0.7167243897095882\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.02274368208773873\n",
      "Average test loss:  0.7308773841155144\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.021072248152328346\n",
      "Average test loss:  0.7453126963166827\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.019599539101574377\n",
      "Average test loss:  0.7591995803896511\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.885\n",
      "Average test accuracy:  0.70875\n",
      "\n",
      "Average train loss:  0.6918147752315886\n",
      "Average test loss:  0.6926799021694946\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.716875\n",
      "Average test accuracy:  0.56625\n",
      "\n",
      "Average train loss:  0.6875668794059163\n",
      "Average test loss:  0.6912107256196411\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.818125\n",
      "Average test accuracy:  0.63375\n",
      "\n",
      "Average train loss:  0.6742433921749628\n",
      "Average test loss:  0.68660647969525\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.890625\n",
      "Average test accuracy:  0.6925\n",
      "\n",
      "Average train loss:  0.6386101681026582\n",
      "Average test loss:  0.6741933082394481\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.5584617307284572\n",
      "Average test loss:  0.6459388051541506\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.44173152804859445\n",
      "Average test loss:  0.6047963082455808\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.3335556329750769\n",
      "Average test loss:  0.5689136447210102\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2530180044392763\n",
      "Average test loss:  0.546284689452197\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.97125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.1963694769354871\n",
      "Average test loss:  0.5357326712739027\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.15615830233257644\n",
      "Average test loss:  0.5334913236799191\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.984375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.12685581411453675\n",
      "Average test loss:  0.5372058907060264\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1049429115504601\n",
      "Average test loss:  0.5448633434351301\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.08815949072542795\n",
      "Average test loss:  0.5554911269371662\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0750263995992515\n",
      "Average test loss:  0.5680282461935704\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.06457029361877899\n",
      "Average test loss:  0.5823667773808406\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.056082821472613426\n",
      "Average test loss:  0.5968545386213227\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04911140833632799\n",
      "Average test loss:  0.6127590155043062\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04332822870567086\n",
      "Average test loss:  0.6286998496947707\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.03848160405230167\n",
      "Average test loss:  0.6451615039268032\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.0344039397205719\n",
      "Average test loss:  0.6613985905119018\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.030942091972081382\n",
      "Average test loss:  0.6777944069430496\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.027986769571662323\n",
      "Average test loss:  0.6940760475483231\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.025447231025219424\n",
      "Average test loss:  0.7096200055304903\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.02325501487021994\n",
      "Average test loss:  0.7261234763458911\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72\n",
      "\n",
      "Average train loss:  0.021322662211454485\n",
      "Average test loss:  0.7412491158617996\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.01961550935118204\n",
      "Average test loss:  0.7563135108477287\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.01807810732072307\n",
      "Average test loss:  0.7717005043854531\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.016685767749812674\n",
      "Average test loss:  0.7866964503541641\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.71875\n",
      "\n",
      "Average train loss:  0.01541826409688421\n",
      "Average test loss:  0.8011554125515722\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.014287286221289835\n",
      "Average test loss:  0.8160569091391686\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.92\n",
      "Average test accuracy:  0.67875\n",
      "\n",
      "Average train loss:  0.6903299811560909\n",
      "Average test loss:  0.6921730653826265\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.705625\n",
      "Average test accuracy:  0.56375\n",
      "\n",
      "Average train loss:  0.6850249250925953\n",
      "Average test loss:  0.6903488910707402\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.865625\n",
      "Average test accuracy:  0.6675\n",
      "\n",
      "Average train loss:  0.6727852664870889\n",
      "Average test loss:  0.6860961460169964\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6452670178583669\n",
      "Average test loss:  0.6764625439466757\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.945625\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5913661391051863\n",
      "Average test loss:  0.6576081023577692\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5055033921046296\n",
      "Average test loss:  0.6277672301154663\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.75\n",
      "\n",
      "Average train loss:  0.40250689942061224\n",
      "Average test loss:  0.5934684369858303\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.963125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.3087838100733658\n",
      "Average test loss:  0.5652536455638674\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.2368955395875064\n",
      "Average test loss:  0.5477264736113684\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.18500336108718107\n",
      "Average test loss:  0.5409526795986641\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.978125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.14756331886791624\n",
      "Average test loss:  0.5407794688626043\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.12008656149592534\n",
      "Average test loss:  0.5460223623717056\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.09943704043171371\n",
      "Average test loss:  0.5548456933702447\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.08357672191340156\n",
      "Average test loss:  0.5664150313793004\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.07117274043036105\n",
      "Average test loss:  0.5791989046895943\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.06130635273260473\n",
      "Average test loss:  0.5940158646973647\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.053305882259069244\n",
      "Average test loss:  0.6083525853178648\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.04675976559691156\n",
      "Average test loss:  0.6242711439584833\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.04132048299760266\n",
      "Average test loss:  0.6402479913327827\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.03674683569252677\n",
      "Average test loss:  0.6560736328428004\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.032864431818983915\n",
      "Average test loss:  0.6720883633133347\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.029522558350902728\n",
      "Average test loss:  0.6882182769686608\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.02663692861277057\n",
      "Average test loss:  0.7041237404860858\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.024129282634592446\n",
      "Average test loss:  0.7199320312064682\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.021935885214809863\n",
      "Average test loss:  0.7357197364473539\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.020030988731195562\n",
      "Average test loss:  0.7511489516931776\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.018369901486204508\n",
      "Average test loss:  0.7662521227750441\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.016905313924647836\n",
      "Average test loss:  0.781756416385211\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.015613141621221889\n",
      "Average test loss:  0.7965524179332554\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  9\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.01445677948986604\n",
      "Average test loss:  0.811321020506525\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7741889412058112\n",
      "Average test loss:  0.774677223263092\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7506714940401938\n",
      "Average test loss:  0.7512740725442821\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7331065271868343\n",
      "Average test loss:  0.7337624918163456\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7163671801838657\n",
      "Average test loss:  0.7174464884427452\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7021634024519319\n",
      "Average test loss:  0.7042276698442876\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6928983706903348\n",
      "Average test loss:  0.6964508461415847\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6853161820344577\n",
      "Average test loss:  0.6918281368970641\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6735328512087587\n",
      "Average test loss:  0.6868967941475819\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.774375\n",
      "Average test accuracy:  0.54125\n",
      "\n",
      "Average train loss:  0.6527858509722196\n",
      "Average test loss:  0.6788947121374459\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9325\n",
      "Average test accuracy:  0.715\n",
      "\n",
      "Average train loss:  0.6226555543352993\n",
      "Average test loss:  0.6670322193576889\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.956875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.5838309208007498\n",
      "Average test loss:  0.6517409211993278\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.96\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.5379301246761279\n",
      "Average test loss:  0.6337423980806243\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.48895935758624764\n",
      "Average test loss:  0.6147199877439555\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.96875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.44150761030248115\n",
      "Average test loss:  0.5964894985864165\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.3984595724975524\n",
      "Average test loss:  0.5806342820300431\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.9775\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.36060832052194874\n",
      "Average test loss:  0.5674218415873641\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3276917285478756\n",
      "Average test loss:  0.5568735389707417\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.2990814701858259\n",
      "Average test loss:  0.5485613569837242\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.2741526279604443\n",
      "Average test loss:  0.5423110526066562\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2523166704918651\n",
      "Average test loss:  0.5379774477199704\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2330947230678071\n",
      "Average test loss:  0.5352791957345033\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.21607699711060838\n",
      "Average test loss:  0.5335943826180292\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.20091862956157483\n",
      "Average test loss:  0.5329596345457495\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.18734468136988622\n",
      "Average test loss:  0.5335662197697139\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.17512732577600768\n",
      "Average test loss:  0.5347877532470772\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1640979203217888\n",
      "Average test loss:  0.5366145506814628\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1541065206807358\n",
      "Average test loss:  0.5393029035903664\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.14503830944136717\n",
      "Average test loss:  0.5425292980330377\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.13677628040419032\n",
      "Average test loss:  0.5460036053543594\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  2\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.12923105587339911\n",
      "Average test loss:  0.549935343722907\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7531567193131044\n",
      "Average test loss:  0.7543692738138006\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.7170307550958871\n",
      "Average test loss:  0.7190513120089747\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6981796526883709\n",
      "Average test loss:  0.7016387835395991\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6885271548664887\n",
      "Average test loss:  0.69386714406291\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6824488792185436\n",
      "Average test loss:  0.6901870408671612\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.515\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6763953232945822\n",
      "Average test loss:  0.6875515929555917\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.7975\n",
      "Average test accuracy:  0.54375\n",
      "\n",
      "Average train loss:  0.6679120068685842\n",
      "Average test loss:  0.6843940013102636\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.881875\n",
      "Average test accuracy:  0.6325\n",
      "\n",
      "Average train loss:  0.6542733339429732\n",
      "Average test loss:  0.6795019129350965\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9075\n",
      "Average test accuracy:  0.68875\n",
      "\n",
      "Average train loss:  0.6314944622197226\n",
      "Average test loss:  0.6714419222062444\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9225\n",
      "Average test accuracy:  0.70875\n",
      "\n",
      "Average train loss:  0.5954950066440206\n",
      "Average test loss:  0.6587082449610239\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.5460862472280321\n",
      "Average test loss:  0.6411351100043494\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.95625\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.4887315466965047\n",
      "Average test loss:  0.6205933672428973\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.4308345532648418\n",
      "Average test loss:  0.6003451953050686\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.37750129199581334\n",
      "Average test loss:  0.5820949347643195\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3308318516817231\n",
      "Average test loss:  0.5673224640046549\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.29094096989871926\n",
      "Average test loss:  0.555823652350962\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.25713306936554947\n",
      "Average test loss:  0.5475647194382182\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.22847820146275274\n",
      "Average test loss:  0.5419893431141256\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.2041305201612623\n",
      "Average test loss:  0.5390081519836291\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.18332029518487838\n",
      "Average test loss:  0.5380702597008128\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.16543887570304167\n",
      "Average test loss:  0.5386978006169958\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1499817255903397\n",
      "Average test loss:  0.5407731429596584\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.1365168127869885\n",
      "Average test loss:  0.5439285581161891\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.12475613569518677\n",
      "Average test loss:  0.5484415228266352\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.11440650434993886\n",
      "Average test loss:  0.5533491334990474\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.10526596721933895\n",
      "Average test loss:  0.5590840358710419\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.09714941748636986\n",
      "Average test loss:  0.5654878853098676\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.08991794351973882\n",
      "Average test loss:  0.5725294326917397\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.08343615273012228\n",
      "Average test loss:  0.5797443254764064\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  3\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.07762131752560862\n",
      "Average test loss:  0.5874715567699522\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6977804895962337\n",
      "Average test loss:  0.6990682077639464\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.688832342764958\n",
      "Average test loss:  0.691940895868921\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.861875\n",
      "Average test accuracy:  0.65875\n",
      "\n",
      "Average train loss:  0.6838697280304366\n",
      "Average test loss:  0.6898888246717507\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.935625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.6757892520535284\n",
      "Average test loss:  0.6871077842554526\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.93375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6582209811712872\n",
      "Average test loss:  0.6810590852557047\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.620769599440265\n",
      "Average test loss:  0.6679579742428284\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.943125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.5568896714713473\n",
      "Average test loss:  0.6450514949463368\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.94875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.47716370059841795\n",
      "Average test loss:  0.6160755892230552\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.954375\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3991155360773863\n",
      "Average test loss:  0.5881396048978779\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.96375\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.33258085555187605\n",
      "Average test loss:  0.5658176742395851\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.2788640917378609\n",
      "Average test loss:  0.5497342745310649\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.23610732495026668\n",
      "Average test loss:  0.5393058392028102\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.2019836560106637\n",
      "Average test loss:  0.5334869386195774\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.980625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.17447951357615113\n",
      "Average test loss:  0.5314370720500111\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.15208207037926094\n",
      "Average test loss:  0.5320815570367705\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.13362551509182838\n",
      "Average test loss:  0.5351659854503366\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.11826802223746403\n",
      "Average test loss:  0.540215147783389\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.10535557469602168\n",
      "Average test loss:  0.5465144639995253\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.09441878769178176\n",
      "Average test loss:  0.5539928694097177\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.08506196077991644\n",
      "Average test loss:  0.5621367761851067\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07701110713678537\n",
      "Average test loss:  0.571501288796285\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.07002822395948119\n",
      "Average test loss:  0.5810189068432932\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.06393516805944348\n",
      "Average test loss:  0.5909867133426335\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.058593925728895914\n",
      "Average test loss:  0.6012930764346297\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.053906445344980104\n",
      "Average test loss:  0.6116650507859954\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04977245487895334\n",
      "Average test loss:  0.6220317482308958\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.046115803697539516\n",
      "Average test loss:  0.6326302426704261\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.04286057414671477\n",
      "Average test loss:  0.6430817251787001\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.0399498592977315\n",
      "Average test loss:  0.6536197108338938\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  4\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.037328620541667766\n",
      "Average test loss:  0.6639753741874034\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.83\n",
      "Average test accuracy:  0.6325\n",
      "\n",
      "Average train loss:  0.691334405973865\n",
      "Average test loss:  0.6925193535276115\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.903125\n",
      "Average test accuracy:  0.685\n",
      "\n",
      "Average train loss:  0.6879218339102419\n",
      "Average test loss:  0.6913405406636747\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6799411278476226\n",
      "Average test loss:  0.6885789224738427\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.931875\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.65974918022391\n",
      "Average test loss:  0.6815432437252239\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.94125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6131257377784504\n",
      "Average test loss:  0.6651155775016524\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.946875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.5322830821076381\n",
      "Average test loss:  0.636166902585854\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9525\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.4376955332775791\n",
      "Average test loss:  0.6022250103435157\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.961875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.35340438305289906\n",
      "Average test loss:  0.5731845297330237\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.969375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2867804715110856\n",
      "Average test loss:  0.5527714598903025\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.97375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.23573063352840604\n",
      "Average test loss:  0.5398426447998632\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.19656492148442353\n",
      "Average test loss:  0.5333795762326231\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.1660677997137754\n",
      "Average test loss:  0.5318111518468421\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.14193142217257174\n",
      "Average test loss:  0.5337401633150276\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.12259476765242465\n",
      "Average test loss:  0.5385200578817421\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.10687863057313333\n",
      "Average test loss:  0.5451200701871329\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.09394523886386219\n",
      "Average test loss:  0.553769634062892\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.991875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.08318064003265709\n",
      "Average test loss:  0.5635332386616893\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07413551468597775\n",
      "Average test loss:  0.5741179164956955\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.06647257131548612\n",
      "Average test loss:  0.5853239065216118\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.05991539636776518\n",
      "Average test loss:  0.5969262459131454\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.05428872553464185\n",
      "Average test loss:  0.6090309363849676\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.9975\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.04941793555543974\n",
      "Average test loss:  0.6211519051620176\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.045192391966971286\n",
      "Average test loss:  0.6333733103386062\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.04150975576149602\n",
      "Average test loss:  0.6456487105401855\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.03825443974096824\n",
      "Average test loss:  0.6575025714370335\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.03536276192868041\n",
      "Average test loss:  0.6696897525287748\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.03275831012921252\n",
      "Average test loss:  0.6814810514239001\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.030383526482242008\n",
      "Average test loss:  0.6935100747154607\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.02821877169244383\n",
      "Average test loss:  0.7055759797717066\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  5\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.026285604222728895\n",
      "Average test loss:  0.7176075954809308\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6915660062127778\n",
      "Average test loss:  0.6925983437637018\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.829375\n",
      "Average test accuracy:  0.59\n",
      "\n",
      "Average train loss:  0.6877659201673504\n",
      "Average test loss:  0.691271017810069\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.930625\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.677749573402115\n",
      "Average test loss:  0.6878038226276241\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.933125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6524369433051248\n",
      "Average test loss:  0.6790440076052491\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.941875\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.5960797892029667\n",
      "Average test loss:  0.6594020468242987\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5039832559595598\n",
      "Average test loss:  0.6268713470221762\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.40288198113066515\n",
      "Average test loss:  0.592057551434898\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.960625\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.31753251353140216\n",
      "Average test loss:  0.5647360671395577\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.75125\n",
      "\n",
      "Average train loss:  0.25275371407258795\n",
      "Average test loss:  0.5474215613126603\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.974375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.2045421136732872\n",
      "Average test loss:  0.5377530484722436\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.168328906137673\n",
      "Average test loss:  0.5349739961882763\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.14062955027445243\n",
      "Average test loss:  0.5366489655160288\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.11905710311767947\n",
      "Average test loss:  0.5413307169401103\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.10195284500615698\n",
      "Average test loss:  0.5490238829751317\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.08821121025272348\n",
      "Average test loss:  0.5585125691193086\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.07700947406369246\n",
      "Average test loss:  0.5690165817236118\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.06776436971443654\n",
      "Average test loss:  0.5805618031380742\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.0600608922547903\n",
      "Average test loss:  0.5933455518704688\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.05359935563994883\n",
      "Average test loss:  0.6061907758259967\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.04812676811305788\n",
      "Average test loss:  0.6199097957446195\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.043468256069369764\n",
      "Average test loss:  0.6327797270622543\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.039470250075213716\n",
      "Average test loss:  0.646043694528862\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.03600558481514226\n",
      "Average test loss:  0.6592275632225522\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.03297790022993606\n",
      "Average test loss:  0.6728388994672855\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.03029682947893254\n",
      "Average test loss:  0.6857308871337162\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.027910777744424787\n",
      "Average test loss:  0.6985032373874566\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.025786418118611376\n",
      "Average test loss:  0.7118043553748366\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.02390414030435828\n",
      "Average test loss:  0.724730891016899\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.02223902664466176\n",
      "Average test loss:  0.7372953299506183\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  6\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.02076411343094349\n",
      "Average test loss:  0.7496574839606683\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.89375\n",
      "Average test accuracy:  0.6675\n",
      "\n",
      "Average train loss:  0.6902400660440323\n",
      "Average test loss:  0.6921229541654906\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.876875\n",
      "Average test accuracy:  0.68625\n",
      "\n",
      "Average train loss:  0.6839349456022047\n",
      "Average test loss:  0.6899349041388317\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.938125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.6669328687617044\n",
      "Average test loss:  0.6840006229697212\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.938125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.6265741840450928\n",
      "Average test loss:  0.6699010681521361\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.94125\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5509662472645388\n",
      "Average test loss:  0.6434769289643341\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.45179982628364024\n",
      "Average test loss:  0.6097947998169925\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.7525\n",
      "\n",
      "Average train loss:  0.35636160800539357\n",
      "Average test loss:  0.5793889634560344\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.965625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.27977269135818816\n",
      "Average test loss:  0.5573593337668293\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.22230905137431103\n",
      "Average test loss:  0.5448607115112295\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.976875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.17955133954067304\n",
      "Average test loss:  0.5397316409574952\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.9825\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1474335444341569\n",
      "Average test loss:  0.5402467634739513\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.1229095000924928\n",
      "Average test loss:  0.5446625438348746\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.989375\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.10383244999172525\n",
      "Average test loss:  0.552181007841484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08875257554577333\n",
      "Average test loss:  0.5619663054906358\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.07665612518215427\n",
      "Average test loss:  0.5732450739182989\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.06681563584813123\n",
      "Average test loss:  0.5852954585133331\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.05873292345821534\n",
      "Average test loss:  0.5983522300739685\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.05201699887989373\n",
      "Average test loss:  0.611946756530898\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.04638368618011333\n",
      "Average test loss:  0.6260105255728049\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.04161943909145878\n",
      "Average test loss:  0.6402535845574066\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.03753898088054721\n",
      "Average test loss:  0.6543594913514426\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.03400693477818612\n",
      "Average test loss:  0.6686116389922226\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.030910755986718847\n",
      "Average test loss:  0.6824344172420579\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.028154387140563092\n",
      "Average test loss:  0.6967003991560681\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.02569987091173456\n",
      "Average test loss:  0.710865671816209\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.023530538356297412\n",
      "Average test loss:  0.7245046917945862\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.021628148217388867\n",
      "Average test loss:  0.7382273772101078\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.019968546319135697\n",
      "Average test loss:  0.7518567305205526\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.018512466268121437\n",
      "Average test loss:  0.7654958223450358\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  7\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.017222245319956527\n",
      "Average test loss:  0.778312324940277\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.646875\n",
      "Average test accuracy:  0.51125\n",
      "\n",
      "Average train loss:  0.6918403115272896\n",
      "Average test loss:  0.6926927996256057\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.9325\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.687903754482829\n",
      "Average test loss:  0.6913302580534753\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.923125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.6751484049241826\n",
      "Average test loss:  0.6868957034819774\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.94\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.640412969852735\n",
      "Average test loss:  0.6747421197617484\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.94375\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.5651720381671854\n",
      "Average test loss:  0.6482258972871559\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.949375\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.4565411268181627\n",
      "Average test loss:  0.6106680603929868\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.95875\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.3518900188705792\n",
      "Average test loss:  0.5761576952074782\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.965\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2703751748948196\n",
      "Average test loss:  0.553066671105542\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.74\n",
      "\n",
      "Average train loss:  0.21124787860737237\n",
      "Average test loss:  0.5411635731955162\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.97625\n",
      "Average test accuracy:  0.7425\n",
      "\n",
      "Average train loss:  0.16853462352986817\n",
      "Average test loss:  0.5372684652701805\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.981875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.13708720451158815\n",
      "Average test loss:  0.539088168360616\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.98625\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.11347368541955412\n",
      "Average test loss:  0.5456099181690538\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.98875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.09532665896966852\n",
      "Average test loss:  0.5547574285018927\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08113780261832045\n",
      "Average test loss:  0.5661883571197884\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.06983478160055095\n",
      "Average test loss:  0.578905617301725\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.060703104799298656\n",
      "Average test loss:  0.5928087070573794\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.05323457673934926\n",
      "Average test loss:  0.607383305819461\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.04705633102943563\n",
      "Average test loss:  0.6220183203618895\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.04189224038043388\n",
      "Average test loss:  0.6372331710401368\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.03752767186757663\n",
      "Average test loss:  0.6523532084414195\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.033793743965627274\n",
      "Average test loss:  0.6673826486906235\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.030562726736307427\n",
      "Average test loss:  0.6826235121842101\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.027732851418894616\n",
      "Average test loss:  0.6972595615717644\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.02524193566153819\n",
      "Average test loss:  0.7123158921998806\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.023031510264960826\n",
      "Average test loss:  0.7270145706773796\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.021087290882613494\n",
      "Average test loss:  0.7422270587983332\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.01936905139889084\n",
      "Average test loss:  0.7563057248455752\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.01787326244828478\n",
      "Average test loss:  0.7707737850602179\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.01656241671882557\n",
      "Average test loss:  0.7842791316404073\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  8\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.015410383789758819\n",
      "Average test loss:  0.7981881305821598\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.651875\n",
      "Average test accuracy:  0.54125\n",
      "\n",
      "Average train loss:  0.690194640282232\n",
      "Average test loss:  0.6921295304697175\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.936875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6835247981263314\n",
      "Average test loss:  0.6898264080657345\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.935\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.6651353697582879\n",
      "Average test loss:  0.6834679232145596\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.620763632594071\n",
      "Average test loss:  0.6681847280366534\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.5358204396594619\n",
      "Average test loss:  0.6393785145154346\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.95\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.4254620227204158\n",
      "Average test loss:  0.6030061708092376\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.9575\n",
      "Average test accuracy:  0.74875\n",
      "\n",
      "Average train loss:  0.3246241201164138\n",
      "Average test loss:  0.5722866043634065\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.964375\n",
      "Average test accuracy:  0.74375\n",
      "\n",
      "Average train loss:  0.2484493997184132\n",
      "Average test loss:  0.5541884821598546\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.971875\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.19372283476634203\n",
      "Average test loss:  0.5455688165532137\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.1544158008499589\n",
      "Average test loss:  0.5443089889388187\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.98375\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.1255783659161572\n",
      "Average test loss:  0.5490790471376629\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.10393619097395912\n",
      "Average test loss:  0.5570930973440267\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.08731963727085545\n",
      "Average test loss:  0.568219861207436\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.07431745444848199\n",
      "Average test loss:  0.5809723012779991\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.06397449137377699\n",
      "Average test loss:  0.5950262231472188\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.0556267619519464\n",
      "Average test loss:  0.6095114671278243\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.048786653540206705\n",
      "Average test loss:  0.6246092028660467\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.04311997648321064\n",
      "Average test loss:  0.6413443620662541\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.03837760237465753\n",
      "Average test loss:  0.6564242531494896\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.03435839222234959\n",
      "Average test loss:  0.6719712906841663\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.03091051690840134\n",
      "Average test loss:  0.6876986217864056\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.02792765575119061\n",
      "Average test loss:  0.7037223348200335\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.025327684247595256\n",
      "Average test loss:  0.7191983860158118\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.02305200592255686\n",
      "Average test loss:  0.7341276278797998\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.021058166956172398\n",
      "Average test loss:  0.7497232008349579\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.01931517475628769\n",
      "Average test loss:  0.7646120979206424\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.01778660860625035\n",
      "Average test loss:  0.7792271598526724\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.016422306420772675\n",
      "Average test loss:  0.7938027382667657\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.01519553496419527\n",
      "Average test loss:  0.8084247862703128\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  9\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.014074811842885638\n",
      "Average test loss:  0.8219846699348694\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.5\n",
      "Average test accuracy:  0.5\n",
      "\n",
      "Average train loss:  0.6913848646383344\n",
      "Average test loss:  0.6928267528811866\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.60875\n",
      "Average test accuracy:  0.53\n",
      "\n",
      "Average train loss:  0.6868873201295664\n",
      "Average test loss:  0.6910035334482368\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.770625\n",
      "Average test accuracy:  0.6\n",
      "\n",
      "Average train loss:  0.678935603028021\n",
      "Average test loss:  0.688236105842115\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.86625\n",
      "Average test accuracy:  0.66875\n",
      "\n",
      "Average train loss:  0.6619078226349836\n",
      "Average test loss:  0.6822554891192295\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.91875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.6272506882207983\n",
      "Average test loss:  0.6699310514114676\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.939375\n",
      "Average test accuracy:  0.73\n",
      "\n",
      "Average train loss:  0.5649780466679492\n",
      "Average test loss:  0.647758068738513\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.948125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.4762475099383803\n",
      "Average test loss:  0.6166192664937759\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.953125\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.3811356285958829\n",
      "Average test loss:  0.5850372387107633\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.9625\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.29884295621958656\n",
      "Average test loss:  0.5608578526786033\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.9675\n",
      "Average test accuracy:  0.74625\n",
      "\n",
      "Average train loss:  0.235323118017714\n",
      "Average test loss:  0.5460935839561015\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.973125\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.18801104708874483\n",
      "Average test loss:  0.5396248418622887\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.97875\n",
      "Average test accuracy:  0.745\n",
      "\n",
      "Average train loss:  0.15284225318497932\n",
      "Average test loss:  0.5396565710344384\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.983125\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.12626372823429452\n",
      "Average test loss:  0.5437723766828394\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1058654442177801\n",
      "Average test loss:  0.5512560255901825\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.08991695434753955\n",
      "Average test loss:  0.5609398493437087\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.990625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.07724890055432729\n",
      "Average test loss:  0.5721654720370034\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.06702060286469928\n",
      "Average test loss:  0.5851590304041737\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.993125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.058655407364565613\n",
      "Average test loss:  0.5986737729849056\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.994375\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.051733460503270406\n",
      "Average test loss:  0.6125279411763428\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.995\n",
      "Average test accuracy:  0.73625\n",
      "\n",
      "Average train loss:  0.045947417314277476\n",
      "Average test loss:  0.6271150343845744\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.99625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.04104426232240263\n",
      "Average test loss:  0.6415311092231386\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.03686400086343324\n",
      "Average test loss:  0.6562794434172879\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.03326634595275732\n",
      "Average test loss:  0.671248275857602\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.030134077459048846\n",
      "Average test loss:  0.6859841067885428\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.027392308122508983\n",
      "Average test loss:  0.7005723461157549\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.024980051200927073\n",
      "Average test loss:  0.7151627443568483\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.02285471312326606\n",
      "Average test loss:  0.729637859028715\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72875\n",
      "\n",
      "Average train loss:  0.020980702941024266\n",
      "Average test loss:  0.7438528357399172\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.019327259639881245\n",
      "Average test loss:  0.7581489794059236\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  10\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.01785850340593904\n",
      "Average test loss:  0.7722965596360045\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  0\n",
      "\n",
      "Average train accuracy:  0.930625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.6898233922125718\n",
      "Average test loss:  0.6919957612997522\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  1\n",
      "\n",
      "Average train accuracy:  0.9\n",
      "Average test accuracy:  0.7175\n",
      "\n",
      "Average train loss:  0.6810801109643229\n",
      "Average test loss:  0.6889890905066793\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  2\n",
      "\n",
      "Average train accuracy:  0.934375\n",
      "Average test accuracy:  0.735\n",
      "\n",
      "Average train loss:  0.6560608514567288\n",
      "Average test loss:  0.6803707339363706\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  3\n",
      "\n",
      "Average train accuracy:  0.93875\n",
      "Average test accuracy:  0.73875\n",
      "\n",
      "Average train loss:  0.5962152771643247\n",
      "Average test loss:  0.659697718646542\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  4\n",
      "\n",
      "Average train accuracy:  0.94625\n",
      "Average test accuracy:  0.7475\n",
      "\n",
      "Average train loss:  0.49214167689284133\n",
      "Average test loss:  0.6238769592075942\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  5\n",
      "\n",
      "Average train accuracy:  0.95375\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.37282580678272065\n",
      "Average test loss:  0.5841706729547426\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  6\n",
      "\n",
      "Average train accuracy:  0.96125\n",
      "Average test accuracy:  0.74125\n",
      "\n",
      "Average train loss:  0.2743368774557093\n",
      "Average test loss:  0.5561481186365453\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  7\n",
      "\n",
      "Average train accuracy:  0.97\n",
      "Average test accuracy:  0.7375\n",
      "\n",
      "Average train loss:  0.20496067150593567\n",
      "Average test loss:  0.5418334685736043\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  8\n",
      "\n",
      "Average train accuracy:  0.975625\n",
      "Average test accuracy:  0.73375\n",
      "\n",
      "Average train loss:  0.1573788181828434\n",
      "Average test loss:  0.5388479458385266\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  9\n",
      "\n",
      "Average train accuracy:  0.98\n",
      "Average test accuracy:  0.7325\n",
      "\n",
      "Average train loss:  0.12411177450965664\n",
      "Average test loss:  0.54279023995305\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  10\n",
      "\n",
      "Average train accuracy:  0.986875\n",
      "Average test accuracy:  0.73125\n",
      "\n",
      "Average train loss:  0.10016134435741862\n",
      "Average test loss:  0.5522865560276459\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  11\n",
      "\n",
      "Average train accuracy:  0.988125\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.08241872293161791\n",
      "Average test loss:  0.5648292134538812\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  12\n",
      "\n",
      "Average train accuracy:  0.99\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.06892078151311487\n",
      "Average test loss:  0.5795757455071247\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  13\n",
      "\n",
      "Average train accuracy:  0.9925\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.05843490318879648\n",
      "Average test loss:  0.5956477762149083\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  14\n",
      "\n",
      "Average train accuracy:  0.99375\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.050152913505295584\n",
      "Average test loss:  0.6128690267361033\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  15\n",
      "\n",
      "Average train accuracy:  0.995625\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.043461717577530055\n",
      "Average test loss:  0.6299642044408275\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  16\n",
      "\n",
      "Average train accuracy:  0.996875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.03801297557024683\n",
      "Average test loss:  0.6480769996366003\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  17\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.03349342726817636\n",
      "Average test loss:  0.6659230223232778\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  18\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.029706191012159988\n",
      "Average test loss:  0.6839125861080771\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  19\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.02651169634616861\n",
      "Average test loss:  0.7015751642170973\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  20\n",
      "\n",
      "Average train accuracy:  0.998125\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.02377437338179787\n",
      "Average test loss:  0.718804420597457\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  21\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.02142825595289437\n",
      "Average test loss:  0.7368503711118825\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  22\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72125\n",
      "\n",
      "Average train loss:  0.01942220325785207\n",
      "Average test loss:  0.7533260720670004\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  23\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.017702221304744456\n",
      "Average test loss:  0.7700229780027588\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  24\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7225\n",
      "\n",
      "Average train loss:  0.016217470245262607\n",
      "Average test loss:  0.7867554305278276\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  25\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72375\n",
      "\n",
      "Average train loss:  0.014921883254150661\n",
      "Average test loss:  0.802740653964907\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  26\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.013786399605503569\n",
      "Average test loss:  0.8184525048545245\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  27\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.7275\n",
      "\n",
      "Average train loss:  0.012775076456510331\n",
      "Average test loss:  0.833486272861491\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  28\n",
      "\n",
      "Average train accuracy:  0.99875\n",
      "Average test accuracy:  0.72625\n",
      "\n",
      "Average train loss:  0.011864850613481368\n",
      "Average test loss:  0.8488255047319586\n",
      "------------------------------------------------\n",
      "\n",
      "For layers:  10\n",
      "For neurons:  11\n",
      "For iteration  29\n",
      "\n",
      "Average train accuracy:  0.999375\n",
      "Average test accuracy:  0.725\n",
      "\n",
      "Average train loss:  0.01103171680583856\n",
      "Average test loss:  0.8638588774973764\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_range = 20\n",
    "model_list = []\n",
    "aver_train_score = []\n",
    "aver_test_score = []\n",
    "aver_train_loss = []\n",
    "aver_test_loss = []\n",
    "\n",
    "\n",
    "for t in range(10):\n",
    "    for i in range(10):\n",
    "        for iteration in range(30):\n",
    "            k = 3\n",
    "            kfold = KFold(n_splits=k)\n",
    "\n",
    "            train_scores = []\n",
    "            test_scores = []\n",
    "            train_loss = []\n",
    "            test_loss = []\n",
    "\n",
    "            model = MLPClassifier(hidden_layer_sizes=(t+1,i+2), \n",
    "                            activation='logistic',\n",
    "                            solver='adam',\n",
    "                            alpha=0.0001,\n",
    "                            max_iter=(iteration+1)*10, tol=1e-6,\n",
    "                            random_state=1)\n",
    "            for train_idx, test_idx in kfold.split(X):\n",
    "                X_train, X_test = X[train_idx,:], X[test_idx,:]\n",
    "                y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "                pred_train = model.predict_proba(X_train)\n",
    "                pred_test = model.predict_proba(X_test)\n",
    "\n",
    "                # Score\n",
    "                score_train = model.score(X_train, y_train)\n",
    "                score_test = model.score(X_test, y_test)\n",
    "        #         print(\"Train score: \", score_train)\n",
    "        #         print(\"Test score: \", score_test)\n",
    "                train_scores.append(score_train)\n",
    "                test_scores.append(score_test)\n",
    "\n",
    "                # Log loss\n",
    "                log_loss_train = sklearn.metrics.log_loss(y_train,pred_train)\n",
    "                log_loss_test = sklearn.metrics.log_loss(y_test,pred_test)\n",
    "\n",
    "        #         print(\"Train loss: \", log_loss_train)\n",
    "        #         print(\"Test loss: \", log_loss_test)\n",
    "                train_loss.append(log_loss_train)\n",
    "                test_loss.append(log_loss_test)\n",
    "\n",
    "        #         with warnings.catch_warnings(record=True) as warn_list:\n",
    "        #             print('finished LBFGS run :loss %.3f' % (\n",
    "        #              model.loss_))\n",
    "\n",
    "\n",
    "            print(\"For layers: \", t+1)\n",
    "            print(\"For neurons: \", i+2)\n",
    "            print(\"For iteration \", iteration)\n",
    "            print(\"\\nAverage train accuracy: \", np.average(score_train))\n",
    "            print(\"Average test accuracy: \", np.average(score_test))\n",
    "            print(\"\\nAverage train loss: \", np.average(train_loss))\n",
    "            print(\"Average test loss: \", np.average(test_loss))\n",
    "\n",
    "            print('------------------------------------------------\\n')\n",
    "\n",
    "            model_list.append(model)\n",
    "            aver_train_score.append(np.average(score_train))\n",
    "            aver_test_score.append(np.average(score_test))\n",
    "            aver_train_loss.append(np.average(train_loss))\n",
    "            aver_test_loss.append(np.average(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "effective-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = min(aver_test_loss)\n",
    "index_N2 = aver_test_loss.index(min_loss)\n",
    "index_N2\n",
    "# best_C =  C_grid[index_N2]\n",
    "best_model = model_list[index_N2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-livestock",
   "metadata": {},
   "source": [
    "## change  layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "integrated-cycling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aver_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "adolescent-still",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6408158740067246,\n",
       " 0.6517178224419076,\n",
       " 0.5972639876942311,\n",
       " 0.5388847531879326,\n",
       " 0.5458810473191039,\n",
       " 0.5371043979040829,\n",
       " 0.5367583167117675,\n",
       " 0.531230149708258,\n",
       " 0.536559921238409,\n",
       " 0.555823652350962]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_layer_index = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "y_layer_averloss_train = [aver_train_loss[(i-1)*300+45] for i in x_layer_index]\n",
    "y_layer_averloss_test =  [aver_test_loss[(i-1)*300+45] for i in x_layer_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "turned-poetry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('layer number i');\n",
    "plt.ylabel('logistic loss');\n",
    "plt.ylim([0.0, 1]);\n",
    "\n",
    "sns.lineplot(x = x_layer_index, y = y_layer_averloss_train, label = \"Train Loss\", color = \"red\", marker='o')\n",
    "sns.lineplot(x = x_layer_index, y = y_layer_averloss_test,label = \"Test Loss\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Test/Train loss on changing layers')\n",
    "plt.show()\n",
    "\n",
    "# print(\"Best C-value for LR: %.3f\" % best_C) \n",
    "# print(\"Test set log-loss at best C-value: %.4f\" % min_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-casino",
   "metadata": {},
   "source": [
    "## change neuron per layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "certified-hudson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5529021593449074,\n",
       " 0.531230149708258,\n",
       " 0.5287224333308699,\n",
       " 0.5512385327913806,\n",
       " 0.5386748088813648,\n",
       " 0.5696426705283861,\n",
       " 0.5758523468755062,\n",
       " 0.5861660324441882,\n",
       " 0.5985187706842376,\n",
       " 0.577739114907101]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_neuron_index = np.array([2,3,4,5,6,7,8,9,10,11])\n",
    "y_neuron_averloss_train = [aver_train_loss[2115+30*(i-2)] for i in x_neuron_index]\n",
    "y_neuron_averloss_test =  [aver_test_loss[2115+30*(i-2)] for i in x_neuron_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "distant-floating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('neuron per layer');\n",
    "plt.ylabel('logistic loss');\n",
    "plt.ylim([0.0, 1]);\n",
    "\n",
    "sns.lineplot(x = x_neuron_index, y = y_neuron_averloss_train, label = \"Train Loss\", color = \"red\", marker='o')\n",
    "sns.lineplot(x = x_neuron_index, y = y_neuron_averloss_test, label = \"Test Loss\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Test/Train loss on changing neuron per layer')\n",
    "plt.show()\n",
    "\n",
    "# print(\"Best C-value for LR: %.3f\" % best_C) \n",
    "# print(\"Test set log-loss at best C-value: %.4f\" % min_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-abuse",
   "metadata": {},
   "source": [
    "## change iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "sweet-maria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7097506054152346"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_iteration_index = np.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30])\n",
    "y_iteration_averloss_train = [aver_train_loss[2130+i] for i in x_iteration_index]\n",
    "y_iteration_averloss_test =  [aver_test_loss[2130+i] for i in x_iteration_index]\n",
    "y_iteration_averloss_test[29]\n",
    "# y_iteration_averloss_train[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "empty-economy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('neuron per layer');\n",
    "plt.ylabel('logistic loss');\n",
    "plt.ylim([0.0, 1]);\n",
    "\n",
    "sns.lineplot(x = x_iteration_index, y = y_iteration_averloss_train, label = \"Train Loss\", color = \"red\", marker='o')\n",
    "sns.lineplot(x = x_iteration_index, y = y_iteration_averloss_test, label = \"Test Loss\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Test/Train loss on changing max iteration')\n",
    "plt.show()\n",
    "\n",
    "# print(\"Best C-value for LR: %.3f\" % best_C) \n",
    "# print(\"Test set log-loss at best C-value: %.4f\" % min_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "laden-yukon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i_range = [2,3,4,5,6,7,8,9,10,11]\n",
    "layer_range = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "\n",
    "for i in i_range:\n",
    "    for l in layer_range:\n",
    "        x_i = \n",
    "plt.xlabel('Neuron number i');\n",
    "plt.ylabel('logistic loss');\n",
    "plt.ylim([0.0, 1]);\n",
    "\n",
    "sns.lineplot(x = i_range, y = aver_train_loss, label = \"Train Loss\", color = \"red\", marker='o')\n",
    "sns.lineplot(x = i_range, y = aver_test_loss,label = \"Test Loss\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Best number of neuron in 1 layer')\n",
    "plt.show()\n",
    "\n",
    "# print(\"Best C-value for LR: %.3f\" % best_C) \n",
    "# print(\"Test set log-loss at best C-value: %.4f\" % min_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-capability",
   "metadata": {},
   "source": [
    "## Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "swiss-expense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i_range = [2,3,4,5,6,7,8,9,10,11]\n",
    "layer_range = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "\n",
    "for i in i_range:\n",
    "    for l in layer_range:\n",
    "        x_i = \n",
    "plt.xlabel('Neuron number i');\n",
    "plt.ylabel('logistic loss');\n",
    "plt.ylim([0.0, 1]);\n",
    "\n",
    "sns.lineplot(x = i_range, y = aver_train_loss, label = \"Train Loss\", color = \"red\", marker='o')\n",
    "sns.lineplot(x = i_range, y = aver_test_loss,label = \"Test Loss\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Best number of neuron in 1 layer')\n",
    "plt.show()\n",
    "\n",
    "# print(\"Best C-value for LR: %.3f\" % best_C) \n",
    "# print(\"Test set log-loss at best C-value: %.4f\" % min_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_range = 20\n",
    "model_list = []\n",
    "aver_train_score = []\n",
    "aver_test_score = []\n",
    "aver_train_loss = []\n",
    "aver_test_loss = []\n",
    "\n",
    "\n",
    "for t in range(10):\n",
    "    for i in range(10):\n",
    "        for iteration in range(30):\n",
    "            k = 3\n",
    "            kfold = KFold(n_splits=k)\n",
    "\n",
    "            train_scores = []\n",
    "            test_scores = []\n",
    "            train_loss = []\n",
    "            test_loss = []\n",
    "\n",
    "            model = MLPClassifier(hidden_layer_sizes=(t+1,i+2), \n",
    "                            activation='relu',\n",
    "                            solver='adam',\n",
    "                            alpha=0.0001,\n",
    "                            max_iter=(iteration+1)*10, tol=1e-6,\n",
    "                            random_state=1)\n",
    "            for train_idx, test_idx in kfold.split(X):\n",
    "                X_train, X_test = X[train_idx,:], X[test_idx,:]\n",
    "                y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "                pred_train = model.predict_proba(X_train)\n",
    "                pred_test = model.predict_proba(X_test)\n",
    "\n",
    "                # Score\n",
    "                score_train = model.score(X_train, y_train)\n",
    "                score_test = model.score(X_test, y_test)\n",
    "        #         print(\"Train score: \", score_train)\n",
    "        #         print(\"Test score: \", score_test)\n",
    "                train_scores.append(score_train)\n",
    "                test_scores.append(score_test)\n",
    "\n",
    "                # Log loss\n",
    "                log_loss_train = sklearn.metrics.log_loss(y_train,pred_train)\n",
    "                log_loss_test = sklearn.metrics.log_loss(y_test,pred_test)\n",
    "\n",
    "        #         print(\"Train loss: \", log_loss_train)\n",
    "        #         print(\"Test loss: \", log_loss_test)\n",
    "                train_loss.append(log_loss_train)\n",
    "                test_loss.append(log_loss_test)\n",
    "\n",
    "        #         with warnings.catch_warnings(record=True) as warn_list:\n",
    "        #             print('finished LBFGS run :loss %.3f' % (\n",
    "        #              model.loss_))\n",
    "\n",
    "\n",
    "            print(\"For layers: \", t+1)\n",
    "            print(\"For neurons: \", i+2)\n",
    "            print(\"For iteration \", iteration)\n",
    "            print(\"\\nAverage train accuracy: \", np.average(score_train))\n",
    "            print(\"Average test accuracy: \", np.average(score_test))\n",
    "            print(\"\\nAverage train loss: \", np.average(train_loss))\n",
    "            print(\"Average test loss: \", np.average(test_loss))\n",
    "\n",
    "            print('------------------------------------------------\\n')\n",
    "\n",
    "            model_list.append(model)\n",
    "            aver_train_score.append(np.average(score_train))\n",
    "            aver_test_score.append(np.average(score_test))\n",
    "            aver_train_loss.append(np.average(train_loss))\n",
    "            aver_test_loss.append(np.average(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-marriage",
   "metadata": {},
   "source": [
    "# Cross Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-audit",
   "metadata": {},
   "source": [
    "### stability over k folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "written-orlando",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Classify with base data, 5 folds\n",
      "-----------------\n",
      "\n",
      "Average train accuracy:  0.9108333333333334\n",
      "Average test accuracy:  0.8933333333333333\n",
      "Average train loss:  0.2855729771739258\n",
      "Average test loss:  0.29108663560482273\n",
      "\n",
      "Average train accuracy:  0.8975\n",
      "Average test accuracy:  0.91125\n",
      "Average train loss:  0.28926782520393757\n",
      "Average test loss:  0.2864537687602477\n",
      "\n",
      "Average train accuracy:  0.9\n",
      "Average test accuracy:  0.9083333333333333\n",
      "Average train loss:  0.2871247872285715\n",
      "Average test loss:  0.29194486387178264\n",
      "\n",
      "Average train accuracy:  0.9046875\n",
      "Average test accuracy:  0.8916666666666667\n",
      "Average train loss:  0.2880740786474457\n",
      "Average test loss:  0.2893527173570883\n",
      "\n",
      "Average train accuracy:  0.9047619047619048\n",
      "Average test accuracy:  0.8833333333333333\n",
      "Average train loss:  0.2880419294442421\n",
      "Average test loss:  0.29034494500529956\n",
      "\n",
      "Average train accuracy:  0.9013888888888889\n",
      "Average test accuracy:  0.9083333333333333\n",
      "Average train loss:  0.2887668867616243\n",
      "Average test loss:  0.2843960830391238\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------\\nClassify with base data, 5 folds\\n-----------------\")\n",
    "\n",
    "K = [2,3,4,5,8,10]\n",
    "K_train_loss = []\n",
    "K_test_loss = []\n",
    "for k in K:\n",
    "    kfold = KFold(n_splits=k)\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    \n",
    "    for train_idx, test_idx in kfold.split(X):\n",
    "        shuffler = np.random.permutation(len(X))\n",
    "        X_shuffled = X[shuffler]\n",
    "        y_shuffled = y[shuffler]\n",
    "        X_train, X_test = X_shuffled[train_idx,:], X_shuffled[test_idx,:]\n",
    "        y_train, y_test = y_shuffled[train_idx], y_shuffled[test_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = best_model.predict_proba(X_train)\n",
    "        pred_test = best_model.predict_proba(X_test)\n",
    "\n",
    "        score_train = best_model.score(X_train, y_train)\n",
    "        score_test = best_model.score(X_test, y_test)\n",
    "        train_scores.append(score_train)\n",
    "        test_scores.append(score_test)\n",
    "        \n",
    "        log_loss_train = sklearn.metrics.log_loss(y_train,pred_train)\n",
    "        log_loss_test = sklearn.metrics.log_loss(y_test,pred_test)\n",
    "        \n",
    "        train_loss.append(log_loss_train)\n",
    "        test_loss.append(log_loss_test)\n",
    "\n",
    "    print(\"\\nAverage train accuracy: \", np.average(score_train))\n",
    "    print(\"Average test accuracy: \", np.average(score_test))\n",
    "    print(\"Average train loss: \", np.average(train_loss))\n",
    "    print(\"Average test loss: \", np.average(test_loss))\n",
    "    \n",
    "    K_train_loss.append(np.average(train_loss))\n",
    "    K_test_loss.append(np.average(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ranging-geology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard deviation for training set: 0.001  \n",
      "standard deviation for testing set: 0.003  \n"
     ]
    }
   ],
   "source": [
    "plt.xlabel('K fold values');\n",
    "plt.ylabel('logistic loss');\n",
    "\n",
    "sns.lineplot(x = K, y = K_train_loss, label = \"Train Loss\", color = \"red\", marker='o')\n",
    "sns.lineplot(x = K, y = K_test_loss, label = \"Test Loss\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Log loss across K values')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('standard deviation for training set: %.3f  ' %np.std(K_train_loss))\n",
    "print('standard deviation for testing set: %.3f  ' %np.std(K_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-procurement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beginning-sally",
   "metadata": {},
   "source": [
    "### CV with the best C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the results in clear tabular format\n",
    "pd.DataFrame(np.transpose([aver_train_score, aver_test_score, aver_train_loss, aver_test_loss]), columns=['train accuracy', 'test accuracy', 'train loss', 'test loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-quest",
   "metadata": {},
   "source": [
    "#### Best Log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = min(aver_test_loss)\n",
    "index_N2 = aver_test_loss.index(min_loss)\n",
    "best_C =  C_grid[index_N2]\n",
    "best_model = model_list[index_N2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-monday",
   "metadata": {},
   "source": [
    "#### stability across Kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-senior",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------\\nClassify with base data, 5 folds\\n-----------------\")\n",
    "\n",
    "K = [2,3,4,5,6,7,8,9,10,11,12]\n",
    "K_train_loss = []\n",
    "K_test_loss = []\n",
    "for k in K:\n",
    "    kfold = KFold(n_splits=k)\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    \n",
    "    for train_idx, test_idx in kfold.split(X):\n",
    "        shuffler = np.random.permutation(len(X))\n",
    "        X_shuffled = X[shuffler]\n",
    "        y_shuffled = y[shuffler]\n",
    "        X_train, X_test = X_shuffled[train_idx,:], X_shuffled[test_idx,:]\n",
    "        y_train, y_test = y_shuffled[train_idx], y_shuffled[test_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = best_model.predict_proba(X_train)\n",
    "        pred_test = best_model.predict_proba(X_test)\n",
    "\n",
    "        score_train = best_model.score(X_train, y_train)\n",
    "        score_test = best_model.score(X_test, y_test)\n",
    "        train_scores.append(score_train)\n",
    "        test_scores.append(score_test)\n",
    "        \n",
    "        log_loss_train = sklearn.metrics.log_loss(y_train,pred_train)\n",
    "        log_loss_test = sklearn.metrics.log_loss(y_test,pred_test)\n",
    "        \n",
    "        train_loss.append(log_loss_train)\n",
    "        test_loss.append(log_loss_test)\n",
    "\n",
    "    print(\"\\nAverage train accuracy: \", np.average(score_train))\n",
    "    print(\"Average test accuracy: \", np.average(score_test))\n",
    "    print(\"Average train loss: \", np.average(train_loss))\n",
    "    print(\"Average test loss: \", np.average(test_loss))\n",
    "    \n",
    "    K_train_loss.append(np.average(train_loss))\n",
    "    K_test_loss.append(np.average(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('K from 2 to 12');\n",
    "plt.ylabel('logistic loss');\n",
    "\n",
    "sns.lineplot(x = K, y = K_train_loss, label = \"Train Loss\", color = \"red\", marker='o')\n",
    "sns.lineplot(x = K, y = K_test_loss, label = \"Test Loss\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Log loss across K values')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('standard deviation for training set: %.3f  ' %np.std(K_train_loss))\n",
    "print('standard deviation for testing set: %.3f  ' %np.std(K_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('log10(C)');\n",
    "plt.ylabel('logistic loss');\n",
    "plt.ylim([0.0, 1]);\n",
    "\n",
    "sns.lineplot(x = np.log10(C_grid), y = aver_train_loss, label = \"Train Loss\", color = \"red\", marker='o')\n",
    "sns.lineplot(x = np.log10(C_grid), y = aver_test_loss,label = \"Test Loss\", color = \"blue\", marker='o')\n",
    "\n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "plt.title('Logistic loss on C-grid')\n",
    "plt.show()\n",
    "\n",
    "print(\"Best C-value for LR: %.3f\" % best_C) \n",
    "print(\"Test set log-loss at best C-value: %.4f\" % min_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-satin",
   "metadata": {},
   "source": [
    "#### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "judicial-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "yproba1_test = best_model.predict_proba(x_te)[:, 1] \n",
    "np.savetxt('yproba1_test.txt', yproba1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-circuit",
   "metadata": {},
   "source": [
    "# Neuronetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from MLPClassifierWithSolverLBFGS import MLPClassifierLBFGS\n",
    "\n",
    "from viz_tools_for_binary_classifier import plot_pretty_probabilities_for_clf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 16\n",
    "tr_classifierLBFS = list()\n",
    "\n",
    "for i in range(n_runs):\n",
    "    start_time_sec = time.time()\n",
    "    mlp_lbfgs = MLPClassifier(\n",
    "        hidden_layer_sizes=[2],\n",
    "        activation='relu',\n",
    "        alpha=0.0001,\n",
    "        max_iter=200, tol=1e-6,\n",
    "        random_state=i,\n",
    "        )\n",
    "    with warnings.catch_warnings(record=True) as warn_list:\n",
    "        clf = mlp_lbfgs.fit(x_tr_N2, y_tr_N)\n",
    "    elapsed_time_sec = time.time() - start_time_sec\n",
    "    print('finished LBFGS run %2d/%d after %6.1f sec | %3d iters | %s | loss %.3f' % (\n",
    "        i+1, n_runs, elapsed_time_sec,\n",
    "        len(mlp_lbfgs.loss_curve_),\n",
    "        'converged   ' if mlp_lbfgs.did_converge else 'NOT converged',\n",
    "        mlp_lbfgs.loss_))\n",
    "        \n",
    "    tr_classifierLBFS.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-commodity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
